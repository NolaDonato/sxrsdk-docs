{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":".md-flex a { color: white; } .md-flex a:hover { text-decoration: none; } .md-nav a { color: black; } .md-nav a:hover { text-decoration: none; } .md-footer a { color: white; } .md-footer a:hover { text-decoration: none; } /* Tooltip container */ .tooltip { position: relative; display: inline-block; } /* Tooltip text */ .tooltip .tooltiptext { visibility: hidden; width: 200px; background-color: black; color: #fff; text-align: center; padding: 5px 0; border-radius: 6px; /* Position the tooltip text - see examples below! */ position: absolute; z-index: 1; bottom: 110%; left: 50%; margin-left: -100px; /* Use half of the width (120/2 = 60), to center the tooltip */ } /* Show the tooltip text when you mouse over the tooltip container */ .tooltip:hover .tooltiptext { visibility: visible; } .centered { display: block; margin-right: auto; margin-left: auto; text-align:center; } .intro_item { float: left; width: 20%; } /*Clear fix*/ .group:after { content: \"\"; display: table; clear: both; } /*Sections*/ .section { height: 400px; } .section h1 { color: #ffffff; font-weight: bold; } .item { padding-top: 30px; padding-bottom: 20px; } .center_parent { position: relative; } .center_child { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); } .brand_title { position: absolute; top: 80%; left: 50%; transform: translate(-50%, -50%); } .background_brand { background:url('images/gear-vr_phoneplus_new_vr_img.png'); background-repeat: no-repeat; background-position: center; background-size: 300px 120px; position: relative; } .background_cta { background:url('images/gear_vr_cta.png'); background-repeat: no-repeat; background-position: left; background-color: #c0c0c0; position: relative; } .background_grey { background-color: #f7f7f7; } .layer { background-color: rgba(0, 0, 0, 0.4); position: absolute; top: 0; left: 0; width: 100%; height: 100%; } .btn_red { display:inline-block; text-decoration:none; background-color:#f9443e; color:white; cursor:pointer; font-family:Helvetica,Arial,sans-serif; font-size:20px; line-height:50px; text-align:center; margin:0; height:50px; padding:0px 33px; border-radius:15px; max-width:100%; white-space:nowrap; overflow:hidden; text-overflow:ellipsis; font-weight:bold; -webkit-font-smoothing:antialiased; -moz-osx-font-smoothing:grayscale; } .btn_blue { display:inline-block; text-decoration:none; background-color:#267DDD; color:white; cursor:pointer; font-family:Helvetica,Arial,sans-serif; font-size:20px; line-height:50px; text-align:center; margin:0; height:50px; padding:0px 33px; border-radius:15px; max-width:100%; white-space:nowrap; overflow:hidden; text-overflow:ellipsis; font-weight:bold; -webkit-font-smoothing:antialiased; -moz-osx-font-smoothing:grayscale; } .sample_card { height: 380px; box-shadow: 0px 2px 4px -1px rgba(0, 0, 0, 0.2), 0px 4px 5px 0px rgba(0, 0, 0, 0.14), 0px 1px 10px 0px rgba(0, 0, 0, 0.12); transition: box-shadow 0.28s cubic-bezier(0.4, 0, 0.2, 1); } /*Small devices (landscape phones, 576px and up)*/ @media (min-width: 576px) { } /*Medium devices (tablets, 768px and up)*/ @media (min-width: 768px) { .item { height: 400px; padding-top: 50px; padding-bottom: 0px; } .background_brand { background:url('images/gear-vr_phoneplus_new_vr_img.png'); background-repeat: no-repeat; background-position: center; background-size: 740px 298px; position: relative; } .brand_title { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); } } /*Large devices (desktops, 992px and up)*/ @media (min-width: 992px) { } /*/Extra large devices (large desktops, 1200px and up)*/ @media (min-width: 1200px) { } POWERFUL XR SDK FOR MOBILE Simple Simple API enables rapid prototyping Powerful XR-specific rendering optimizations Mobile Centric Built with focus on mobile performance Open Source No licensing fees or royalties ever Cross Platform Write code once and works for Gear VR, Daydream, and AR Applications Getting Started Android Unity Sample Highlights 360 Photo A minimal sample showing how to display an equirectangular (360) photo. Source 360 Video A minimal sample showing how to display an equirectangular (360) video. Source 3D Cursor A simplified version of the sxr-3dcursor sample that shows how to use the 3DCursor plugin. Source Accessibility Shows how to use SXR's accessibility classes. For example: InvertedColors, TextToSpeech, and Zoom. Source Controller A simple sample that demostrates how to use VR controller. Source Solar System A sample that shows both heirarchy and animation. Source Immersivepedia A larger sample that shows a concept of an immersive virtual museum. Source Javascript A minimal example showing how an application can be written with Javascript. Source (function() { var qs,js,q,s,d=document, gi=d.getElementById, ce=d.createElement, gt=d.getElementsByTagName, id=\"typef_orm_share\", b=\"https://embed.typeform.com/\"; if(!gi.call(d,id)){ js=ce.call(d,\"script\"); js.id=id; js.src=b+\"embed.js\"; q=gt.call(d,\"script\")[0]; q.parentNode.insertBefore(js,q) } })()","title":"Home"},{"location":"api_reference/","text":"Online SXR API Reference ( http://docs.samsungxr.com )","title":"API Reference"},{"location":"community/","text":"SXR Community Report Issues Leave Feedback (function() { var qs,js,q,s,d=document, gi=d.getElementById, ce=d.createElement, gt=d.getElementsByTagName, id=\"typef_orm_share\", b=\"<a href=\"https://embed.typeform.com/\">https://embed.typeform.com/</a>\"; if(!gi.call(d,id)){ js=ce.call(d,\"script\"); js.id=id; js.src=b+\"embed.js\"; q=gt.call(d,\"script\")[0]; q.parentNode.insertBefore(js,q) } })()","title":"Community"},{"location":"getting_started/","text":"Software Requirements Before starting to use the SXR SDK, make sure you download the following SDKs Android Studio JDK 1.7 or above Oculus Mobile SDK (If developing for Samsung GearVR) Google VR SDK (If developing for Google DayDream) Hardware Requirements SXR SDK supports following devices Gear VR compatible Samsung phone: Note 9 Galaxy S9+ Galaxy S9 Note 8 Galaxy S8 Galaxy S8+ Galaxy S7 Galaxy S7 Edge Note 5 Galaxy S6 Galaxy S6 Edge Galaxy S6+ Samsung Gear VR headset Daydream-ready phone Google Daydream View VR headset Project Aurora AR headset Getting Started Getting started with the SXR SDK in few simple steps Download the template project Rename your project by changine the folder name Open the project with Android Studio Rename your Android App by updating app_name field of app/src/main/res/values/strings.xml (For Gear VR only) Make sure to download your Oculus signature file and copy it under app\\src\\main\\assets folder (For DayDream only) remove following code in app/build.gradle compile \"com.samsungxr:backend_oculus:$gearvrfVersion\" in AndroidManifest.xml meta-data android:name=\"com.samsung.android.vr.application.mode\" android:value=\"vr_only\"/ (For DayDream only) add following code (read more) in AndroidManifest.xml intent-filter action android:name=\"android.intent.action.MAIN\" / !-- intent-filter for DayDream-- category android:name=\"com.google.intent.category.DAYDREAM\"/ !-- End intent-filter for DayDream-- /intent-filter Update the applicationID in app/build.gradle to avoid conflict between other SXR apps. Click Run button and put on your XR device Device Setup Gear VR After you build the application, click Start and your device will install Oculus automatically. Note You can test VR apps without a VR headset, by enabling Samsung VR service developer mode. Settings Apps manage applications Gear VR Service Storage Manage Storage - press the \"VR Service Version\" 6 times. After that a 'You are a developer' message will appear. Note Make sure to install your VR app with a valid oculus signature on the device first. Otherwise you'll see a 'You are not a developer' message. Warning Screen will start blinking after you turn on the developer mode DayDream Enable Google VR Service from \"Settings\" = \"Apps\" = \"Google VR Service\" make sure it has the permission it required to run. Project Aurora","title":"Getting Started"},{"location":"getting_started/#software-requirements","text":"Before starting to use the SXR SDK, make sure you download the following SDKs Android Studio JDK 1.7 or above Oculus Mobile SDK (If developing for Samsung GearVR) Google VR SDK (If developing for Google DayDream)","title":"Software Requirements"},{"location":"getting_started/#hardware-requirements","text":"SXR SDK supports following devices Gear VR compatible Samsung phone: Note 9 Galaxy S9+ Galaxy S9 Note 8 Galaxy S8 Galaxy S8+ Galaxy S7 Galaxy S7 Edge Note 5 Galaxy S6 Galaxy S6 Edge Galaxy S6+ Samsung Gear VR headset Daydream-ready phone Google Daydream View VR headset Project Aurora AR headset","title":"Hardware Requirements"},{"location":"getting_started/#getting-started","text":"Getting started with the SXR SDK in few simple steps Download the template project Rename your project by changine the folder name Open the project with Android Studio Rename your Android App by updating app_name field of app/src/main/res/values/strings.xml (For Gear VR only) Make sure to download your Oculus signature file and copy it under app\\src\\main\\assets folder (For DayDream only) remove following code in app/build.gradle compile \"com.samsungxr:backend_oculus:$gearvrfVersion\" in AndroidManifest.xml meta-data android:name=\"com.samsung.android.vr.application.mode\" android:value=\"vr_only\"/ (For DayDream only) add following code (read more) in AndroidManifest.xml intent-filter action android:name=\"android.intent.action.MAIN\" / !-- intent-filter for DayDream-- category android:name=\"com.google.intent.category.DAYDREAM\"/ !-- End intent-filter for DayDream-- /intent-filter Update the applicationID in app/build.gradle to avoid conflict between other SXR apps. Click Run button and put on your XR device","title":"Getting Started"},{"location":"getting_started/#device-setup","text":"","title":"Device Setup"},{"location":"getting_started/#gear-vr","text":"After you build the application, click Start and your device will install Oculus automatically. Note You can test VR apps without a VR headset, by enabling Samsung VR service developer mode. Settings Apps manage applications Gear VR Service Storage Manage Storage - press the \"VR Service Version\" 6 times. After that a 'You are a developer' message will appear. Note Make sure to install your VR app with a valid oculus signature on the device first. Otherwise you'll see a 'You are not a developer' message. Warning Screen will start blinking after you turn on the developer mode","title":"Gear VR"},{"location":"getting_started/#daydream","text":"Enable Google VR Service from \"Settings\" = \"Apps\" = \"Google VR Service\" make sure it has the permission it required to run.","title":"DayDream"},{"location":"getting_started/#project-aurora","text":"","title":"Project Aurora"},{"location":"news/","text":"July 24 2017: Meet with the SXR development and support teams at SIGGRAPH. We are hosting a Mobile VR Birds of a Feather Weds Aug 2, 12pm-1pm in Rm 511A Come share your VR creations, inquiries and ideas. Bring your headsets, demo's, and questions. Whether you are getting started or experienced, come network and collaborate with the VR development community. May 17 2017: Upcoming Galaxy S8 and S8+ support for Daydream announced Support coming this summer, announced at Google I/O: https://www.theverge.com/2017/5/17/1...-s8-lg-2017-io Apr 18 2017: SXR SDK version 3.2 released Download: https://github.com/sxrsdk/sxrsdk/releases Release note summary: -64 bit build support added for Daydream and Oculus -Daydream SDK version updated to 1.30.0 -Oculus SDK version updated to 1.50 -Added Gear VR controller support for the Oculus SDK -SXRRenderData.setAlphaBlendFunc allows you to set the alpha blending function -Asset loader now imports vertex colors from 3D models -Render to Texture support was previously used internally only and has now been exposed to users. -Shadow Mapping now allows the application to have independent control over the near and far planes for each light -SXRContext.getNextMainScene has been deprecated. SXRContext.getMainScene must now be called to get the current scene regardless of whether a splash screen exists. Mar 26 2017: The SXR team will be attending the SVVR Expo Mar 29-31 in San Jose - let us know if you'd like to meet up and chat VR. Feb 26 2017: New controller for Gear VR announced! Support in the SXR SDK coming soon. Read more at: https://www.engadget.com/2017/02/27/...er-first-look/ Feb 14 2017: The SXR team will be attending GDC. Log into your Samsung Developer Account and let us know if you'd like to meet! Jan 4 2017: At CES, Samsung proudly announced that over 5 million Gear VR headsets have been sold! Read more at: http://venturebeat.com/2017/01/04/sa...bile-headsets/ Dec 6 2016: SXR version 3.1 released. -New Physics extension using the Bullet library. -Official support for Google Daydream (previously in beta) -Increased support for X3D file format -Builds now available on Maven Central for easy application integration Dec 2-4 2016: The SXR team sponsored and supported developers at the VR Hackathon in SF. Some cool projects were started in SXR! Read more at: http://vrhackathon.com/ Aug 25 2016: The SXR team presented at SVVR meetup #32 We presented an overview of SXR and partnered with Ximmerse to showcase a live demo of their mobile VR input development kit controllers working with SXR. Read a summary here: https://medium.com/@AlexanderHaque/s...9ac#.ok2727aw9 April 26 2016: SXR SDK at the Samsung Developer Conference (SDC 2016) Tom Flynn's GearVRf session at SDC2016 ( https://www.samsungdevelopers.com/Samsung Developer Connection website) was an overview of the GearVR Framework, along with sample code and demos. Tom also presented live scripting in both JavaScript and Lua and taught the audience how to use the I/O subsystem, how to control objects in VR with the new 3D Cursor VR input model, and how to integrate a new I/O device. In partnership, these companies have already been integrated into SXR: The Eye Tribe's mobile VR eye tracking solution (Eye Tribe VR), Gestigon's touchless hand visualization and recognition/gesture SDK (Carnival AR/VR Interaction Suite), Manus' revolutionary, immersive, intuitive VR Gloves, and Ximmerse's Virtual Reality Input Solution that enables 6DOF tracking for Mobile VR.","title":"News"},{"location":"news/#july-24-2017-meet-with-the-sxr-development-and-support-teams-at-siggraph","text":"We are hosting a Mobile VR Birds of a Feather Weds Aug 2, 12pm-1pm in Rm 511A Come share your VR creations, inquiries and ideas. Bring your headsets, demo's, and questions. Whether you are getting started or experienced, come network and collaborate with the VR development community.","title":"July 24 2017: Meet with the SXR development and support teams at SIGGRAPH."},{"location":"news/#may-17-2017-upcoming-galaxy-s8-and-s8-support-for-daydream-announced","text":"Support coming this summer, announced at Google I/O: https://www.theverge.com/2017/5/17/1...-s8-lg-2017-io","title":"May 17 2017: Upcoming Galaxy S8 and S8+ support for Daydream announced"},{"location":"news/#apr-18-2017-sxr-sdk-version-32-released","text":"Download: https://github.com/sxrsdk/sxrsdk/releases Release note summary: -64 bit build support added for Daydream and Oculus -Daydream SDK version updated to 1.30.0 -Oculus SDK version updated to 1.50 -Added Gear VR controller support for the Oculus SDK -SXRRenderData.setAlphaBlendFunc allows you to set the alpha blending function -Asset loader now imports vertex colors from 3D models -Render to Texture support was previously used internally only and has now been exposed to users. -Shadow Mapping now allows the application to have independent control over the near and far planes for each light -SXRContext.getNextMainScene has been deprecated. SXRContext.getMainScene must now be called to get the current scene regardless of whether a splash screen exists.","title":"Apr 18 2017: SXR SDK version 3.2 released"},{"location":"news/#mar-26-2017-the-sxr-team-will-be-attending-the-svvr-expo-mar-29-31-in-san-jose-let-us-know-if-youd-like-to-meet-up-and-chat-vr","text":"","title":"Mar 26 2017: The SXR team will be attending the SVVR Expo Mar 29-31 in San Jose - let us know if you'd like to meet up and chat VR."},{"location":"news/#feb-26-2017-new-controller-for-gear-vr-announced-support-in-the-sxr-sdk-coming-soon","text":"Read more at: https://www.engadget.com/2017/02/27/...er-first-look/","title":"Feb 26 2017: New controller for Gear VR announced! Support in the SXR SDK coming soon."},{"location":"news/#feb-14-2017-the-sxr-team-will-be-attending-gdc-log-into-your-samsung-developer-account-and-let-us-know-if-youd-like-to-meet","text":"","title":"Feb 14 2017: The SXR team will be attending GDC. Log into your Samsung Developer Account and let us know if you'd like to meet!"},{"location":"news/#jan-4-2017-at-ces-samsung-proudly-announced-that-over-5-million-gear-vr-headsets-have-been-sold","text":"Read more at: http://venturebeat.com/2017/01/04/sa...bile-headsets/","title":"Jan 4 2017: At CES, Samsung proudly announced that over 5 million Gear VR headsets have been sold!"},{"location":"news/#dec-6-2016-sxr-version-31-released","text":"-New Physics extension using the Bullet library. -Official support for Google Daydream (previously in beta) -Increased support for X3D file format -Builds now available on Maven Central for easy application integration","title":"Dec 6 2016: SXR version 3.1 released."},{"location":"news/#dec-2-4-2016-the-sxr-team-sponsored-and-supported-developers-at-the-vr-hackathon-in-sf","text":"Some cool projects were started in SXR! Read more at: http://vrhackathon.com/","title":"Dec 2-4 2016: The SXR team sponsored and supported developers at the VR Hackathon in SF."},{"location":"news/#aug-25-2016-the-sxr-team-presented-at-svvr-meetup-32","text":"We presented an overview of SXR and partnered with Ximmerse to showcase a live demo of their mobile VR input development kit controllers working with SXR. Read a summary here: https://medium.com/@AlexanderHaque/s...9ac#.ok2727aw9","title":"Aug 25 2016: The SXR team presented at SVVR meetup #32"},{"location":"news/#april-26-2016-sxr-sdk-at-the-samsung-developer-conference-sdc-2016","text":"Tom Flynn's GearVRf session at SDC2016 ( https://www.samsungdevelopers.com/Samsung Developer Connection website) was an overview of the GearVR Framework, along with sample code and demos. Tom also presented live scripting in both JavaScript and Lua and taught the audience how to use the I/O subsystem, how to control objects in VR with the new 3D Cursor VR input model, and how to integrate a new I/O device. In partnership, these companies have already been integrated into SXR: The Eye Tribe's mobile VR eye tracking solution (Eye Tribe VR), Gestigon's touchless hand visualization and recognition/gesture SDK (Carnival AR/VR Interaction Suite), Manus' revolutionary, immersive, intuitive VR Gloves, and Ximmerse's Virtual Reality Input Solution that enables 6DOF tracking for Mobile VR.","title":"April 26 2016: SXR SDK at the Samsung Developer Conference (SDC 2016)"},{"location":"about/certificate/","text":"SXR DCO and signed-off-by process The SXR SDK project uses the signed-off-by language and process used by the Linux kernel, to give us a clear chain of trust for every patch received. SXR Developer s Certificate of Origin 1.0 By making a contribution to this project, I certify that: (a) The contribution was created in whole or in part by me and I have the right to submit it under the open source license indicated in the file; or (b) The contribution is based upon previous work that, to the best of my knowledge, is covered under an appropriate open source license and I have the right under that license to submit that work with modifications, whether created in whole or in part by me, under the same open source license (unless I am permitted to submit under a different license), as indicated in the file; or (c) The contribution was provided directly to me by some other person who certified (a), (b) or (c) and I have not modified it. (d) I understand and agree that this project and the contribution are public and that a record of the contribution (including all personal information I submit with it, including my sign-off) is maintained indefinitely and may be redistributed consistent with this project, under the same open source license. Using the Signed-Off-By Process We have the same requirements for using the signed-off-by process as the Linux kernel. In short, you need to include a signed-off-by tag in every patch: \"Signed-off-by:\" this is a developer's certification that he or she has the right to submit the patch for inclusion into the project. It is an agreement to the Developer's Certificate of Origin (above). Code without a proper signoff cannot be merged into the mainline. You should use your real name and email address in the format below: SXR-DCO-1.0-Signed-off-by: Random J Developer random@developer.example.org","title":"Developer Certificate of Origin"},{"location":"about/certificate/#using-the-signed-off-by-process","text":"We have the same requirements for using the signed-off-by process as the Linux kernel. In short, you need to include a signed-off-by tag in every patch: \"Signed-off-by:\" this is a developer's certification that he or she has the right to submit the patch for inclusion into the project. It is an agreement to the Developer's Certificate of Origin (above). Code without a proper signoff cannot be merged into the mainline. You should use your real name and email address in the format below: SXR-DCO-1.0-Signed-off-by: Random J Developer random@developer.example.org","title":"Using the Signed-Off-By Process"},{"location":"about/contribution/","text":"SXR development process, guidelines, and tips; and getting answers, reporting a bug, and submitting a patch Getting involved with the SXR SDK Project is easy. To contribute to the SXR SDK Project (such as reporting bugs and submitting patches): Follow the GitHub contributor guidelines Add the SXR DCO signoff to each commit message during development. Development Process It is the responsibility of SXR Maintainers and Reviewers to decide whether submitted code should be integrated into the mainline code, returned for revision, or rejected. Individual developers maintain a local copy of the SXR codebase using the git revision control system. Git ensures that all participants are working with a common and up-to-date code base at all times. Each developer works to develop, debug, build, and validate their own code against the current codebase, so that when the time comes to integrate into the mainline Project, their changes apply cleanly and with a minimum amount of merging effort. The SXR SDK Project development process is marked by the following highlights: The feature development process starts with an author discussing a proposed feature with the Maintainers and/or or Reviewers. The Maintainers and Reviewers evaluate the idea, give feedback, and finally approve or reject the proposal. The author shares the proposal with the community via the mailing list. The community provides feedback which can be used by the author to modify their proposal and share it with the community again. The above steps are repeated until the community reaches a consensus according to the Community Guidelines. After a consensus is reached, the author proceeds with the implementation and testing of the feature. After the author is confident their code is ready for integration: The author generates a patch and signs off on their code. The author submits a patch by opening a pull request . The Maintainers and/or Reviewers watch the pull request for the patch, test the code, and accept or reject the patch accordingly. After the code passes code review, the Maintainers and/or Reviewers accept the code (integrated into the main branch), which completes the development process. After a patch has been accepted, it remains the authoring developer's responsibility to maintain the code throughout its lifecycle, and to provide security and feature updates as needed. For more information about GitHub issues, refer to the GitHub issues guidelines . Coding Guidelines When generating you own SXR project code, please follow these guidelines. General: Do not abbreviate variable names. Abbreviations may not be familiar to new and other project members. Code with abbreviations will not be merged. Public classes must start with SXR (for example, when adding a Foo class, the class name should be SXRFoo). Implementation classes should not start with SXR. In Java: Use camel case for names (for example, setBackgroundColor). Set up and use the auto-formatter for Java code in Eclipse (see below). In C++: Use underscore case for names (for example, sxr_foo). Put all JNI interface calls in a separate file with the postfix _jni. For example, put the JNI interfaces for SXRNode in a separate file node_jni.cpp Follow the actual logic in plain C++ .h and .cpp files. For each new C++ file that has a correlative Java SXR class, do not add SXR as a prefix to the file name. For example, for SXRNode.java, the C++ file name would be node.cpp/node.h Set up and use the auto-formatter for C++ code in Eclipse (see below). To set up and use the Java auto-formatter in Eclipse: In Eclipse, set up auto-formatting by following methods: Download the Code formatter profile: Java conventions (all spaces) XML file. Click Window Preferences In the Preferences dialog box: Click Java Code Style Formatter OR Java Code Style Import Java-conventions-all-spaces.xml file In Eclipse, auto-format your code To set up and use the C++ auto-formatter in Eclipse: In Eclipse, set up auto-formatting by following methods: Download the Code formatter profile: K R, spaces only Click Window Preferences In the Preferences dialog box: Click C/C++ Code Style Formatter OR C/C++ Code Style Import K-and-R-C++-spaces-only.xml file In Eclipse, auto-format your code Submit a Patch The following guidelines on the submission process are provided to help you be more effective when submitting code to the SXR SDK Project. When development is complete, a patch set should be submitted via Github pull requests. A review of the patch set will take place. When accepted, the patch set will be integrated into the next build, verified, and tested. It is then the responsibility of the authoring developer to maintain the code throughout its lifecycle. Please submit all patches in public by opening a pull request. Patches sent privately to Maintainers or Reviewers will not be considered. Because the SXR SDK Project is an open source Project, be prepared for feedback and criticism--it happens to everyone. If asked to rework your code, be persistent and resubmit after making changes. Scope the patch Smaller patches are generally easier to understand and test, so please submit changes in the smallest increments possible, within reason. Smaller patches are less likely to have unintended consequences, and if they do, getting to root cause is much easier for you and the Maintainers and Reviewers. Additionally, smaller patches are much more likely to be accepted. Sign your work with the SXR DCO . The sign-off is a simple line at the end of the explanation for the patch, which certifies that you wrote it or otherwise have the right to pass it on as an open-source patch. The rules are pretty simple, and the sign-off is required for a patch to be accepted. Open a Github pull request What if my patch is rejected? It happens all the time, for many reasons, and not necessarily because the code is bad. Take the feedback, adapt your code, and try again. Remember, the ultimate goal is to preserve the quality of the code and maintain the focus of the Project through intensive review. Maintainers typically have to process a lot of submissions, and the time for any individual response is generally limited. If the reason for rejection is unclear, please ask for more information on the mailing list or on the IRC channel. If you have a solid technical reason to disagree with feedback and you feel that reason has been overlooked, take the time to thoroughly explain it in your response. Escalation If you submitted a patch and did not receive a response within 5 business days: Please post another reply in the pull-request. Please include this phrase \"Patch escalation: no response for x days\". This is one of those rare cases where you should top post, to make sure that Maintainers and Reviewers see the escalation text, which cues them to make sure someone responds. Code review Code review can be performed by all the members of the Project (not just Maintainers and Reviewers). Members can review code changes and share their opinion by comments with the following principles: * Discuss code; never discuss the code's author. * Respect and acknowledge contributions, suggestions, and comments. * Listen and be open to all different opinions. * Help each other. Changes are submitted via pull requests and only the Maintainer or Reviewers of the module affected by the code change should approve or reject the pull request. Changes should be reviewed in reasonable amount of time. Maintainers and Reviewers should leave changes open for some time (at least 1 full business day) so others can offer feedback. Review times increase with the complexity of the review. GitHub Development Tips Tips for working on GitHub Fork the GitHub repository and clone it locally. Connect your local repository to the original upstream repository by adding it as a remote. Pull in upstream changes often to stay up-to-date so that when you submit your pull request, merge conflicts will be less likely. For more details, see GitHub fork synching guidelines . Create a branch for your edits. Our usual github workflow: Goto: https://github.com/sxrsdk/sxrsdk/ Find the \u2018fork\u2019 button in the upper right. Fork the SDK into your own repository In your own fork of SXR SDK, click on the \u2018branch\u2019 button and create a new branch Clone your repo onto your local machine. (you\u2019ll notice a convenience \u2018HTTPS clone URL\u2019 thing to the right on the webpage, that\u2019ll give the full URL you need to clone. The URL will look something like: https://github.com/thomasflynn/sxrsdk.git , but with your own github id in the middle there. You\u2019ll need to get the Samsung XR SDK repo as the upstream remote repo for your fork. git remote add parent https://github.com/sxrsdk/sxrsdk/ Switch to the branch you created (git checkout branchname) on your local machine. Make your changes. Git add, git commit. Git push origin branchname:branchname ; - this will push it up to your forked repo on github. On the webpage for your repo, you\u2019ll see a \u2018pull request button\u2019. Click that. You\u2019ll see your commit message and you\u2019ll need to add your DCO (see submitting a patch on sxrsdk.org. also: wiki.sxrsdk.org/bin/view/SXR/SXRDCO Click the green \u2018create pull request\u2019 button at the bottom. If you need to upload a second patchset due to comments on your pull-request Make changes in your branch Git add, git commit, git push origin branchname:branchname Your new changes are now a part of the commit. To rebase: Switch to your master branch: git checkout master Pull the remote master: git pull parent master:master Force-push the update to your master branch: git push \u2013f origin master:master Switch to your branch: git checkout branchname Rebase: git rebase master Git add, git commit, git push -f origin branchname:branchname Get Answers and Report a Bug If you have a question about SXR code, have trouble following documentation, or find a bug, review the current SXR SDK issues in GitHub, and if necessary, create a new issue. Tips on GitHub Issues Check existing SXR SDK issues for the answer to your issue . Duplicating an issue slows you and others. Search through open and closed issues to see if the problem you are running into has already been addressed. If necessary, open a new issue . Clearly describe the issue. What did you expect to happen? What actually happened instead? How can someone else recreate the problem? Link to demos that recreate the problem on things such as JSFiddle or CodePen . Include system details (such as the hardware, library, and operating system you are using and their versions). Paste error output and logs in the issue or in a Gist . When pasting in the issue, wrap code in three backticks: ``` so that it renders nicely.","title":"Contribution"},{"location":"about/contribution/#development-process","text":"It is the responsibility of SXR Maintainers and Reviewers to decide whether submitted code should be integrated into the mainline code, returned for revision, or rejected. Individual developers maintain a local copy of the SXR codebase using the git revision control system. Git ensures that all participants are working with a common and up-to-date code base at all times. Each developer works to develop, debug, build, and validate their own code against the current codebase, so that when the time comes to integrate into the mainline Project, their changes apply cleanly and with a minimum amount of merging effort. The SXR SDK Project development process is marked by the following highlights: The feature development process starts with an author discussing a proposed feature with the Maintainers and/or or Reviewers. The Maintainers and Reviewers evaluate the idea, give feedback, and finally approve or reject the proposal. The author shares the proposal with the community via the mailing list. The community provides feedback which can be used by the author to modify their proposal and share it with the community again. The above steps are repeated until the community reaches a consensus according to the Community Guidelines. After a consensus is reached, the author proceeds with the implementation and testing of the feature. After the author is confident their code is ready for integration: The author generates a patch and signs off on their code. The author submits a patch by opening a pull request . The Maintainers and/or Reviewers watch the pull request for the patch, test the code, and accept or reject the patch accordingly. After the code passes code review, the Maintainers and/or Reviewers accept the code (integrated into the main branch), which completes the development process. After a patch has been accepted, it remains the authoring developer's responsibility to maintain the code throughout its lifecycle, and to provide security and feature updates as needed. For more information about GitHub issues, refer to the GitHub issues guidelines .","title":"Development Process"},{"location":"about/contribution/#coding-guidelines","text":"When generating you own SXR project code, please follow these guidelines. General: Do not abbreviate variable names. Abbreviations may not be familiar to new and other project members. Code with abbreviations will not be merged. Public classes must start with SXR (for example, when adding a Foo class, the class name should be SXRFoo). Implementation classes should not start with SXR. In Java: Use camel case for names (for example, setBackgroundColor). Set up and use the auto-formatter for Java code in Eclipse (see below). In C++: Use underscore case for names (for example, sxr_foo). Put all JNI interface calls in a separate file with the postfix _jni. For example, put the JNI interfaces for SXRNode in a separate file node_jni.cpp Follow the actual logic in plain C++ .h and .cpp files. For each new C++ file that has a correlative Java SXR class, do not add SXR as a prefix to the file name. For example, for SXRNode.java, the C++ file name would be node.cpp/node.h Set up and use the auto-formatter for C++ code in Eclipse (see below). To set up and use the Java auto-formatter in Eclipse: In Eclipse, set up auto-formatting by following methods: Download the Code formatter profile: Java conventions (all spaces) XML file. Click Window Preferences In the Preferences dialog box: Click Java Code Style Formatter OR Java Code Style Import Java-conventions-all-spaces.xml file In Eclipse, auto-format your code To set up and use the C++ auto-formatter in Eclipse: In Eclipse, set up auto-formatting by following methods: Download the Code formatter profile: K R, spaces only Click Window Preferences In the Preferences dialog box: Click C/C++ Code Style Formatter OR C/C++ Code Style Import K-and-R-C++-spaces-only.xml file In Eclipse, auto-format your code","title":"Coding Guidelines"},{"location":"about/contribution/#submit-a-patch","text":"The following guidelines on the submission process are provided to help you be more effective when submitting code to the SXR SDK Project. When development is complete, a patch set should be submitted via Github pull requests. A review of the patch set will take place. When accepted, the patch set will be integrated into the next build, verified, and tested. It is then the responsibility of the authoring developer to maintain the code throughout its lifecycle. Please submit all patches in public by opening a pull request. Patches sent privately to Maintainers or Reviewers will not be considered. Because the SXR SDK Project is an open source Project, be prepared for feedback and criticism--it happens to everyone. If asked to rework your code, be persistent and resubmit after making changes. Scope the patch Smaller patches are generally easier to understand and test, so please submit changes in the smallest increments possible, within reason. Smaller patches are less likely to have unintended consequences, and if they do, getting to root cause is much easier for you and the Maintainers and Reviewers. Additionally, smaller patches are much more likely to be accepted. Sign your work with the SXR DCO . The sign-off is a simple line at the end of the explanation for the patch, which certifies that you wrote it or otherwise have the right to pass it on as an open-source patch. The rules are pretty simple, and the sign-off is required for a patch to be accepted. Open a Github pull request What if my patch is rejected? It happens all the time, for many reasons, and not necessarily because the code is bad. Take the feedback, adapt your code, and try again. Remember, the ultimate goal is to preserve the quality of the code and maintain the focus of the Project through intensive review. Maintainers typically have to process a lot of submissions, and the time for any individual response is generally limited. If the reason for rejection is unclear, please ask for more information on the mailing list or on the IRC channel. If you have a solid technical reason to disagree with feedback and you feel that reason has been overlooked, take the time to thoroughly explain it in your response. Escalation If you submitted a patch and did not receive a response within 5 business days: Please post another reply in the pull-request. Please include this phrase \"Patch escalation: no response for x days\". This is one of those rare cases where you should top post, to make sure that Maintainers and Reviewers see the escalation text, which cues them to make sure someone responds. Code review Code review can be performed by all the members of the Project (not just Maintainers and Reviewers). Members can review code changes and share their opinion by comments with the following principles: * Discuss code; never discuss the code's author. * Respect and acknowledge contributions, suggestions, and comments. * Listen and be open to all different opinions. * Help each other. Changes are submitted via pull requests and only the Maintainer or Reviewers of the module affected by the code change should approve or reject the pull request. Changes should be reviewed in reasonable amount of time. Maintainers and Reviewers should leave changes open for some time (at least 1 full business day) so others can offer feedback. Review times increase with the complexity of the review.","title":"Submit a Patch"},{"location":"about/contribution/#github-development-tips","text":"Tips for working on GitHub Fork the GitHub repository and clone it locally. Connect your local repository to the original upstream repository by adding it as a remote. Pull in upstream changes often to stay up-to-date so that when you submit your pull request, merge conflicts will be less likely. For more details, see GitHub fork synching guidelines . Create a branch for your edits. Our usual github workflow: Goto: https://github.com/sxrsdk/sxrsdk/ Find the \u2018fork\u2019 button in the upper right. Fork the SDK into your own repository In your own fork of SXR SDK, click on the \u2018branch\u2019 button and create a new branch Clone your repo onto your local machine. (you\u2019ll notice a convenience \u2018HTTPS clone URL\u2019 thing to the right on the webpage, that\u2019ll give the full URL you need to clone. The URL will look something like: https://github.com/thomasflynn/sxrsdk.git , but with your own github id in the middle there. You\u2019ll need to get the Samsung XR SDK repo as the upstream remote repo for your fork. git remote add parent https://github.com/sxrsdk/sxrsdk/ Switch to the branch you created (git checkout branchname) on your local machine. Make your changes. Git add, git commit. Git push origin branchname:branchname ; - this will push it up to your forked repo on github. On the webpage for your repo, you\u2019ll see a \u2018pull request button\u2019. Click that. You\u2019ll see your commit message and you\u2019ll need to add your DCO (see submitting a patch on sxrsdk.org. also: wiki.sxrsdk.org/bin/view/SXR/SXRDCO Click the green \u2018create pull request\u2019 button at the bottom. If you need to upload a second patchset due to comments on your pull-request Make changes in your branch Git add, git commit, git push origin branchname:branchname Your new changes are now a part of the commit. To rebase: Switch to your master branch: git checkout master Pull the remote master: git pull parent master:master Force-push the update to your master branch: git push \u2013f origin master:master Switch to your branch: git checkout branchname Rebase: git rebase master Git add, git commit, git push -f origin branchname:branchname","title":"GitHub Development Tips"},{"location":"about/contribution/#get-answers-and-report-a-bug","text":"If you have a question about SXR code, have trouble following documentation, or find a bug, review the current SXR SDK issues in GitHub, and if necessary, create a new issue. Tips on GitHub Issues Check existing SXR SDK issues for the answer to your issue . Duplicating an issue slows you and others. Search through open and closed issues to see if the problem you are running into has already been addressed. If necessary, open a new issue . Clearly describe the issue. What did you expect to happen? What actually happened instead? How can someone else recreate the problem? Link to demos that recreate the problem on things such as JSFiddle or CodePen . Include system details (such as the hardware, library, and operating system you are using and their versions). Paste error output and logs in the issue or in a Gist . When pasting in the issue, wrap code in three backticks: ``` so that it renders nicely.","title":"Get Answers and Report a Bug"},{"location":"about/credits/","text":"We gratefully acknowledge the developers of the following images: SXR Features image Cube And Flowers Pictures image courtesy of njaj at FreeDigitalPhotos.net SXR Features image The Wooden Doll With Light Bulb image courtesy of tigger11th at FreeDigitalPhotos.net SXR Features image Book image courtesy of Boykung at FreeDigitalPhotos.net","title":"Credits"},{"location":"about/license/","text":"SXR SDK License The SXR SDK software license is under the Apache 2.0 license. Open Source Software The following open source software supports SXR SDK: Apache Commons Mathematics Library v3.2 Apache 2.0 Assimp v3.1 Open Asset Import Library Libpng v1.2.45 PNG Reference Library GLM v0.9.6.3 OpenGL Mathematics library Licensed under The Happy Bunny License and MIT License","title":"License"},{"location":"about/license/#sxr-sdk-license","text":"The SXR SDK software license is under the Apache 2.0 license.","title":"SXR SDK License"},{"location":"about/license/#open-source-software","text":"The following open source software supports SXR SDK: Apache Commons Mathematics Library v3.2 Apache 2.0 Assimp v3.1 Open Asset Import Library Libpng v1.2.45 PNG Reference Library GLM v0.9.6.3 OpenGL Mathematics library Licensed under The Happy Bunny License and MIT License","title":"Open Source Software"},{"location":"about/marketing_resource/","text":"SXR SDK is open source by nature and the SXR SDK logos below have been created to capture the freedom that open source allows. Note The SXR SDK logos below are for labeling purposes and should not be used in creating artwork such as banners or promotional material. To download a SXR SDK logo PNG file, right-click file image Save image as... Black Samsung XR logo Black Samsung XR logo with blue 'x' Blue Samsung XR logo with blue 'x' White Samsung XR logo White Samsung XR logo with black 'R' White Samsung XR logo with blue 'x' Black SXR logo Black SXR logo with white 'x' Black SXR logo with blue 'x' White SXR logo with blue 'x' White SXR logo","title":"Marketing Resources"},{"location":"about/privacy_policy/","text":"We respect your privacy and are committed to protecting it. We require that you provide some personal information, to provide SXR SDK Project services to its Members, and to improve the SXR SDK Project. The type of information collected, how it is used, and the information privacy choices you have, are detailed in this policy. Information Collection and Use We collect the information you provide when you register for an account or complete an information request form. We use this information to satisfy your requests for further information, to customize our responses and our future communication with you, and to contact you, regarding development and events in the SXR SDK Project and/or Project areas that you have expressed general interest in. We make every effort to allow you to opt-in and opt-out of receiving SXR SDK Project messages. However, if you are receiving messages from us and cannot find a way to unsubscribe, please contact us at Information Sharing We will not release your personal information to anyone by any method, including selling, renting, or sharing, unless: You grant us permission. We are required to do so by law. We will not share personal identification information data, either for single individuals or groups, with any parties, including those affiliated with the SXR SDK Project, such as members or sponsors. How We Use Cookies The SXR SDK Project website uses cookies. A cookie is a small amount of text data, sent from our webserver to your browser, and stored on your device. The cookie is sent back to the webserver each time the browser connects to this website. We use cookies to personalize the website and to streamline your interaction with the website. It may be possible to configure your browser to refuse cookies, or to ask you to accept each time a cookie is offered. If you choose not to accept cookies, areas of this website may have reduced functionality or performance. Software on our servers or third-party web statics services may store your IP address and other information passed on by your browser (such as browser version, operating system, screen size, language, etc). samsungxr.org and/or third-party services will aggregate this information to provide usage statistics for this website. We use this information to optimize the design, structure, and performance of the Project website. In particular, Google Analytics is used to provide usage statistics. For more information, read the Google Analytics Privacy Policy. Data Security The SXR SDK Project is also committed to the security of your personal information. We train those who work on the SXR SDK Project on this privacy policy. The Project website uses SSL (Secure Sockets Layer) to protect your personal information, by encrypting your information when you send it to the SXR SDK Project. Public Forum Content The SXR SDK Project makes available to its users several communication forums (such as mail lists, blogs, and others). Be aware that any information or messages you share in these forums immediately becomes public information. Exercise caution in determining whether to disclose any of your personal information. The SXR SDK Project is an open source website, intended to encourage creative thinking and free expression; however, the SXR SDK Project reserves the right to act as necessary to preserve the integrity of the website and its forums, including removing any and all posts deemed vulgar or inappropriate. Children's Online Privacy Regarding children under the age of 13, the SXR SDK Project does not knowingly: Accept personal information from them Allow them to become registered members of the SXR SDK Project website Updates to this Privacy Policy We may update this policy. We will contact you if we make any substantial changes in how we use your personal information. This privacy policy was last updated on March 25, 2015. Contact Information If you have any questions about this privacy policy itself, or on how we use personal information in the SXR SDK Project, please contact us at","title":"Privacy Policy"},{"location":"about/privacy_policy/#we-respect-your-privacy-and-are-committed-to-protecting-it","text":"We require that you provide some personal information, to provide SXR SDK Project services to its Members, and to improve the SXR SDK Project. The type of information collected, how it is used, and the information privacy choices you have, are detailed in this policy.","title":"We respect your privacy and are committed to protecting it."},{"location":"about/privacy_policy/#information-collection-and-use","text":"We collect the information you provide when you register for an account or complete an information request form. We use this information to satisfy your requests for further information, to customize our responses and our future communication with you, and to contact you, regarding development and events in the SXR SDK Project and/or Project areas that you have expressed general interest in. We make every effort to allow you to opt-in and opt-out of receiving SXR SDK Project messages. However, if you are receiving messages from us and cannot find a way to unsubscribe, please contact us at","title":"Information Collection and Use"},{"location":"about/privacy_policy/#information-sharing","text":"We will not release your personal information to anyone by any method, including selling, renting, or sharing, unless: You grant us permission. We are required to do so by law. We will not share personal identification information data, either for single individuals or groups, with any parties, including those affiliated with the SXR SDK Project, such as members or sponsors.","title":"Information Sharing"},{"location":"about/privacy_policy/#how-we-use-cookies","text":"The SXR SDK Project website uses cookies. A cookie is a small amount of text data, sent from our webserver to your browser, and stored on your device. The cookie is sent back to the webserver each time the browser connects to this website. We use cookies to personalize the website and to streamline your interaction with the website. It may be possible to configure your browser to refuse cookies, or to ask you to accept each time a cookie is offered. If you choose not to accept cookies, areas of this website may have reduced functionality or performance. Software on our servers or third-party web statics services may store your IP address and other information passed on by your browser (such as browser version, operating system, screen size, language, etc). samsungxr.org and/or third-party services will aggregate this information to provide usage statistics for this website. We use this information to optimize the design, structure, and performance of the Project website. In particular, Google Analytics is used to provide usage statistics. For more information, read the Google Analytics Privacy Policy.","title":"How We Use Cookies"},{"location":"about/privacy_policy/#data-security","text":"The SXR SDK Project is also committed to the security of your personal information. We train those who work on the SXR SDK Project on this privacy policy. The Project website uses SSL (Secure Sockets Layer) to protect your personal information, by encrypting your information when you send it to the SXR SDK Project.","title":"Data Security"},{"location":"about/privacy_policy/#public-forum-content","text":"The SXR SDK Project makes available to its users several communication forums (such as mail lists, blogs, and others). Be aware that any information or messages you share in these forums immediately becomes public information. Exercise caution in determining whether to disclose any of your personal information. The SXR SDK Project is an open source website, intended to encourage creative thinking and free expression; however, the SXR SDK Project reserves the right to act as necessary to preserve the integrity of the website and its forums, including removing any and all posts deemed vulgar or inappropriate.","title":"Public Forum Content"},{"location":"about/privacy_policy/#childrens-online-privacy","text":"Regarding children under the age of 13, the SXR SDK Project does not knowingly: Accept personal information from them Allow them to become registered members of the SXR SDK Project website","title":"Children's Online Privacy"},{"location":"about/privacy_policy/#updates-to-this-privacy-policy","text":"We may update this policy. We will contact you if we make any substantial changes in how we use your personal information. This privacy policy was last updated on March 25, 2015.","title":"Updates to this Privacy Policy"},{"location":"about/privacy_policy/#contact-information","text":"If you have any questions about this privacy policy itself, or on how we use personal information in the SXR SDK Project, please contact us at","title":"Contact Information"},{"location":"about/release_notes/","text":"Release 4.0 VULKAN Support Release 4.0 introduces alpha level support for rendering on Vulkan. Not all of the SXR SDK features are supported on Vulkan yet and the implementation is still slow and unstable. Mobile VR back ends do not yet support Vulkan and there is a high overhead to transfer the image rendered by Vulkan back to OpenGL for display. Vulkan does not support light sources of any kind. It cannot use external textures which means none of the scene objects which exchange textures with Android will work on Vulkan yet. SXR SDK supports authoring custom shaders which will work for both Vulkan and OpenGL. Shader Changes In previous releases, the SXR SDK built-in shaders were implemented by individual C++ classes. in 4.0, the built-in shaders are implemented in terms of SXRShaderTemplate, the same mechanism provided to users for authoring custom shaders. There is a new Java class for each of the built-in shaders. Release 4.0 now has a single shader manager. There is no longer any difference between the post effect shader manager and the material shader manager. The SXRPostEffectShaderManager and SXRMaterialShaderManager classes will most likely be deprecated in the future in favor of SXRShaderManager. The SXRShader object was introduced to make it easier to construct simple custom shaders. Unlike SXRShaderTemplate, only a single native shader is produced and no parameter substitution is done. Additional arguments are now required for custom shaders. In addition to a uniform descriptor, all shaders now require a texture descriptor and a vertex descriptor. These descriptors are used to emit platform-specific shader declarations to facilitate sharing of shaders between OpenGL and Vulkan. New API Description SXRShader describes simple custom shader SXRShaderTemplate(String uniforms, String textures, String vertex, GLSLESVersion) constructor for custom shader getTextureDescriptor() returns shader texture descriptor getVertexDescriptor() returns shader texture descriptor setMaterialDefaults(SXRShaderData) override to set default material value The GLSLESVersion argument indicates the shader language version. If VULKAN is specified, the shader language is level 400. This allows you to author shaders which can work on both Vulkan and OpenGL. The token @MATERIAL_UNIFORMS in shader source is replaced by uniform declarations constructed from the uniform descriptor of your shader class. The token @MATRIX_UNIFORMS is replaced by SXR SDK matrix declarations. Any Vulkan-specific layout specifiers are stripped out if the shader is used on OpenGL. SXRMesh API Changes In earlier releases, the vertices and indices were kept internal to the mesh and could not be shared. In 4.0, we introduce SXRVertexBuffer and SXRIndexBuffer objects which encapsulate the vertex and index buffer and permit them to be shared across meshes. New APIs are provided which allow access to the vertex and index data in terms of Java Direct Buffers. This helps reduce copying of vertex data during asset import. A mesh need not have an index buffer. SXR SDK can display meshes which contain only vertex data. In this case, it is assumed each three successive vertices define a different triangle. New API Description SXRVertexBuffer object which contains vertices of a mesh SXRIndexBuffer object which contains indices of a mesh setVertexBuffer(SXRVertexBuffer) replace vertex buffer used by mesh SXRVertexBuffer getVertexBuffer() get vertex buffer used by mesh setIndexBuffer(SXRIndexBuffer) replace index buffer used by mesh setFloatArray(String name, float[]) update floating point vertex component setFloatVec(String name, FloatBuffer) setFloat(String name, float) setIntArray(String name, int[]) update integer point vertex component setIntVec(String name, InBuffer) setInt(String name, int) setIndices(int[]) set integer (32 bit) indices setIndices(IntBuffer) setTriangles(int[]) setIndices(CharBuffer) set char (16 bit) indices getIndices() get integer indices getTriangles() get char indices createQuad(float w, y) create planar quad createQuad(SXRContext, String desc, float w, h) getBoxBound(float[]) get bounding box We have deprecated the following functions in favor of API simplification. Deprecated Use This Instead setFloatVector setFloatArray getFloatVector getFloatArray setVec2Vector setFloatArray getVec3Vector getFloatArray setVec3Vector setFloatArray getVec3Vector getFloatArray setVec4Vector setFloatArray getVec4Vector getFloatArray getAttributeNames SXRVertexBuffer.getDescriptor SXRTexture Changes The SXRTexture object has been split into two pieces - a texture sampler object and an image data object. SXRTexture now behaves like Future used to in that the image data is loaded in the background and becomes available once the texture is loaded. The different texture classes (SXRBitmapTexture, SXRCubemapTexture, ...) are now derived from SXRImage instead of SXRTexture. These are created by the asset loader and assigned to the texture. (We should probably rename these classes for clarity.) Deprecated Use This Instead Future SXRTexture getFutureId getId New API Description SXRImage contains image data for a texture setImage(SXRImage) set the image data for a texture SXRImage getImage() get the image data for a texture setTexCoord(String attr, String var) set name of texcoord attribute and shader variable String getTexCoordAttr() get name of texture coordinate vertex attribute String getTexCoordShaderVar() get name of texture coordinate shader variable SXRMaterial Changes The SXRPostEffect object has been removed - use SXRMaterial for post effects now. A new base class for supplying data to shaders, SXRShaderData, has been added. SXRMaterial is now derived from SXRShaderData. SXRContext Changes SXRContext.createQuad has been deprecated. SXRMesh.createQuad is the replacement function.","title":"Release Notes"},{"location":"about/release_notes/#release-40","text":"","title":"Release 4.0"},{"location":"about/release_notes/#vulkan-support","text":"Release 4.0 introduces alpha level support for rendering on Vulkan. Not all of the SXR SDK features are supported on Vulkan yet and the implementation is still slow and unstable. Mobile VR back ends do not yet support Vulkan and there is a high overhead to transfer the image rendered by Vulkan back to OpenGL for display. Vulkan does not support light sources of any kind. It cannot use external textures which means none of the scene objects which exchange textures with Android will work on Vulkan yet. SXR SDK supports authoring custom shaders which will work for both Vulkan and OpenGL.","title":"VULKAN Support"},{"location":"about/release_notes/#shader-changes","text":"In previous releases, the SXR SDK built-in shaders were implemented by individual C++ classes. in 4.0, the built-in shaders are implemented in terms of SXRShaderTemplate, the same mechanism provided to users for authoring custom shaders. There is a new Java class for each of the built-in shaders. Release 4.0 now has a single shader manager. There is no longer any difference between the post effect shader manager and the material shader manager. The SXRPostEffectShaderManager and SXRMaterialShaderManager classes will most likely be deprecated in the future in favor of SXRShaderManager. The SXRShader object was introduced to make it easier to construct simple custom shaders. Unlike SXRShaderTemplate, only a single native shader is produced and no parameter substitution is done. Additional arguments are now required for custom shaders. In addition to a uniform descriptor, all shaders now require a texture descriptor and a vertex descriptor. These descriptors are used to emit platform-specific shader declarations to facilitate sharing of shaders between OpenGL and Vulkan. New API Description SXRShader describes simple custom shader SXRShaderTemplate(String uniforms, String textures, String vertex, GLSLESVersion) constructor for custom shader getTextureDescriptor() returns shader texture descriptor getVertexDescriptor() returns shader texture descriptor setMaterialDefaults(SXRShaderData) override to set default material value The GLSLESVersion argument indicates the shader language version. If VULKAN is specified, the shader language is level 400. This allows you to author shaders which can work on both Vulkan and OpenGL. The token @MATERIAL_UNIFORMS in shader source is replaced by uniform declarations constructed from the uniform descriptor of your shader class. The token @MATRIX_UNIFORMS is replaced by SXR SDK matrix declarations. Any Vulkan-specific layout specifiers are stripped out if the shader is used on OpenGL.","title":"Shader Changes"},{"location":"about/release_notes/#sxrmesh-api-changes","text":"In earlier releases, the vertices and indices were kept internal to the mesh and could not be shared. In 4.0, we introduce SXRVertexBuffer and SXRIndexBuffer objects which encapsulate the vertex and index buffer and permit them to be shared across meshes. New APIs are provided which allow access to the vertex and index data in terms of Java Direct Buffers. This helps reduce copying of vertex data during asset import. A mesh need not have an index buffer. SXR SDK can display meshes which contain only vertex data. In this case, it is assumed each three successive vertices define a different triangle. New API Description SXRVertexBuffer object which contains vertices of a mesh SXRIndexBuffer object which contains indices of a mesh setVertexBuffer(SXRVertexBuffer) replace vertex buffer used by mesh SXRVertexBuffer getVertexBuffer() get vertex buffer used by mesh setIndexBuffer(SXRIndexBuffer) replace index buffer used by mesh setFloatArray(String name, float[]) update floating point vertex component setFloatVec(String name, FloatBuffer) setFloat(String name, float) setIntArray(String name, int[]) update integer point vertex component setIntVec(String name, InBuffer) setInt(String name, int) setIndices(int[]) set integer (32 bit) indices setIndices(IntBuffer) setTriangles(int[]) setIndices(CharBuffer) set char (16 bit) indices getIndices() get integer indices getTriangles() get char indices createQuad(float w, y) create planar quad createQuad(SXRContext, String desc, float w, h) getBoxBound(float[]) get bounding box We have deprecated the following functions in favor of API simplification. Deprecated Use This Instead setFloatVector setFloatArray getFloatVector getFloatArray setVec2Vector setFloatArray getVec3Vector getFloatArray setVec3Vector setFloatArray getVec3Vector getFloatArray setVec4Vector setFloatArray getVec4Vector getFloatArray getAttributeNames SXRVertexBuffer.getDescriptor","title":"SXRMesh API Changes"},{"location":"about/release_notes/#sxrtexture-changes","text":"The SXRTexture object has been split into two pieces - a texture sampler object and an image data object. SXRTexture now behaves like Future used to in that the image data is loaded in the background and becomes available once the texture is loaded. The different texture classes (SXRBitmapTexture, SXRCubemapTexture, ...) are now derived from SXRImage instead of SXRTexture. These are created by the asset loader and assigned to the texture. (We should probably rename these classes for clarity.) Deprecated Use This Instead Future SXRTexture getFutureId getId New API Description SXRImage contains image data for a texture setImage(SXRImage) set the image data for a texture SXRImage getImage() get the image data for a texture setTexCoord(String attr, String var) set name of texcoord attribute and shader variable String getTexCoordAttr() get name of texture coordinate vertex attribute String getTexCoordShaderVar() get name of texture coordinate shader variable","title":"SXRTexture Changes"},{"location":"about/release_notes/#sxrmaterial-changes","text":"The SXRPostEffect object has been removed - use SXRMaterial for post effects now. A new base class for supplying data to shaders, SXRShaderData, has been added. SXRMaterial is now derived from SXRShaderData.","title":"SXRMaterial Changes"},{"location":"about/release_notes/#sxrcontext-changes","text":"SXRContext.createQuad has been deprecated. SXRMesh.createQuad is the replacement function.","title":"SXRContext Changes"},{"location":"about/roadmap/","text":"The following features are planned for the SXR SDK Project: Version 3.1 The following items were completed: Hierarchical bounding volume culling Support for Assimp's animations Support for all the different shaders Assimp supports Support for multiple lights Support for shadows State sorting Draw call batching (initial batching completed; additional batching planned for 4.0) DayDream Support AndroidStudio Support Version 3.2 The following updates are planned for release in late Apr/early May 2017: New physics support Batching for all shaders LOD rework DayDream controller support New GearVR controller support Various optimizations Version 4.0 The following updates are planned: Full support for Vulkan Additional draw call batching support","title":"Roadmap"},{"location":"about/terms_of_service/","text":"By using the SXR SDK Project website, you are agreeing to be bound by the following terms and conditions here. Here is the basic idea: Do not violate anyone's intellectual property or post anyone else's copyrighted or confidential material you do not have permission to use. Do not post anything vulgar, inflammatory, pornographic, illegal, etc. Do not post spam. Do not post too many meta-links and tags; too many will not be accepted. If you try to boost your SEO, that is an abuse of the system. Do not post just to sell something. Sure, talk up your project, but do not mention how to buy it every single time. Do not launch into personal attacks. You are not going to agree with everyone, but name-calling will just cause trouble and will be regarded as flaming behavior. Tone down foul language. You can say what you need to say without relying on cursing. In fact, your writing will be regarded as that much more impressive. The SXR SDK Project is providing a framework for discussion and user generated information to expand the knowledge base of SXR SDK-related information. Please note that articles, as well as any other user content on the SXR SDK Project (such as blogs, directory content, forums, comments, etc.), do not reflect the views or endorsements of the SXR SDK Project, or its community members. We recognize there may be inaccurate information reflected in this website; users should understand that something that appears on the SXR SDK Project website does not mean the SXR SDK Project has vetted or endorsed that content. The SXR SDK Project reserves the right to take down anything posted on this website for the above or other reasons. If you do not agree to these terms, do not use this website. Violation of the terms in this document may result in the removal of the content and a warning from website administrators. A second violation will result in the removal of your user account. SXR SDK Project Terms of Use March 20, 2015 Terms and Conditions of Use for the SXR SDK Project website BY ACCESSING, BROWSING OR USING THIS WEBSITE, YOU ACKNOWLEDGE THAT YOU HAVE READ, UNDERSTAND AND AGREE TO BE BOUND BY THESE TERMS AND CONDITIONS. This website is a service made available by the SXR SDK Project. All software, documentation, information, and/or other materials provided on and through this website (\"Content\") may be used solely under the following terms and conditions (\"Terms of Use\"). This website may contain other proprietary notices and copyright information, the terms of which must be observed and followed. The Content on this website may contain technical inaccuracies or typographical errors and may be changed or updated without notice. The SXR SDK Project may also make improvements and/or changes to the Content at any time without notice. The SXR SDK Project and its community members (\"Members\") assume no responsibility regarding the accuracy of the Content. Use of the Content is at the recipient's own risk. The SXR SDK Project and its Members provide no assurances that any reported problems with any Content will be resolved. Intellectual Property Rights Except as otherwise provided, Content on this website, including all materials posted by the SXR SDK Project, is licensed under a Creative Commons Attribution 3.0 License . All logos and trademarks contained on this website are and remain the property of their respective owners. No licenses or other rights in or to such logos and/or trademarks are granted. Except as otherwise expressly stated, by providing the Content, neither the SXR SDK Project nor its Members grant any licenses to any copyrights, patents, or any other intellectual property rights. Users Submissions Users are solely responsible for all materials, whether publicly posted or privately transmitted, that users upload, post, e-mail, transmit, or otherwise make available on our websites (\"User Content\"). Neither the SXR SDK Project nor any of its Members shall be liable for any claims arising out of User Content. You warrant that you have all rights needed to provide User Content in accordance with these terms and all applicable laws or regulations. The SXR SDK Project or other projects that may be hosted by the SXR SDK Project may have license terms or Contributor Agreements that are specific to the project and may require Users to sign an agreement (such as a Contributor Agreement) assigning and/or licensing rights in submissions made to such projects. In all such cases, and to the extent there is a conflict, those license terms or agreements take precedence over these Terms of Use. With respect to any User Content not governed by other project-specific terms or agreements, you agree that the following non-exclusive, irrevocable, royalty-free, worldwide licenses shall apply: Code Submissions User Content in the form of source or object code will be governed by the Apache 2.0 License. All Other Submissions User Content that is not in the form of source or object code, including but not limited to white papers, dissertations, articles or other literary works, Power Point presentations, encyclopedias, anthologies, wikis, blogs, diagrams, drawings, sketches, photos or other images, audio content, video content and audiovisual materials will be governed by the Creative Commons Attribution 3.0. The SXR SDK Project and its Members do not want to receive confidential information from you through this website. Please note that any information or material sent to the SXR SDK Project or the Members will be deemed NOT to be confidential. You are prohibited from posting or transmitting to or from this website any unlawful, threatening, libelous, defamatory, obscene, scandalous, inflammatory, pornographic, or profane material; or any other material that could give rise to any civil or criminal liability under the law. Disclaimers and Limitations of Liability The SXR SDK Project and the Members make no representations whatsoever about any other website that you may access through this website. When you access a non-SXR SDK project website, even one that may contain the SXR SDK Project's name or mark, please understand that it is independent from the SXR SDK Project, and that the SXR SDK Project and its Members have no control over the content on such websites. In addition, a link to a non-SXR SDK project website does not mean that the SXR SDK Project or its Members endorse or accept any responsibility for the content of or the use of such websites. It is up to you to take precautions to ensure that whatever you select for your use is free of such items as viruses, worms, Trojan horses, and other items of a destructive nature. IN NO EVENT WILL THE SXR SDK PROJECT AND/OR ITS MEMBERS BE LIABLE TO YOU (AN INDIVIDUAL OR ENTITY) OR ANY OTHER INDIVIDUAL OR ENTITY FOR ANY DIRECT, INDIRECT, INCIDENTAL, PUNITIVE, SPECIAL, OR CONSEQUENTIAL DAMAGES RELATED TO ANY USE OF THIS WEBSITE, THE CONTENT, OR ON ANY OTHER HYPERLINKED WEBSITE, INCLUDING, WITHOUT LIMITATION, ANY LOST PROFITS, LOST SALES, LOST REVENUE, LOSS OF GOODWILL, BUSINESS INTERRUPTION, LOSS OF PROGRAMS OR OTHER DATA ON YOUR INFORMATION HANDLING SYSTEM OR OTHERWISE, EVEN IF THE SXR SDK PROJECT OR ITS MEMBERS ARE EXPRESSLY ADVISED OR AWARE OF THE POSSIBILITY OF SUCH DAMAGES OR LOSSES. ALL CONTENT IS PROVIDED BY THE SXR SDK PROJECT AND/OR ITS MEMBERS ON AN \"AS IS\" BASIS ONLY. THE SXR SDK PROJECT AND ITS MEMBERS PROVIDE NO REPRESENTATIONS, CONDITIONS AND/OR WARRANTIES, EXPRESS OR IMPLIED, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF FITNESS FOR A PARTICULAR PURPOSE, MERCHANTABILITY AND NONINFRINGEMENT. The SXR SDK Project and its Members reserve the right to investigate complaints or reported violations of these Terms of Use and to take any action they deem appropriate including, without limitation, reporting any suspected unlawful activity to law enforcement officials, regulators, or other third-parties and disclosing any information necessary or appropriate to such persons or entities relating to user profiles, e-mail addresses, usage history, posted materials, IP addresses, and traffic information. The SXR SDK Project and its Members reserve the right to seek all remedies available at law and in equity for violations of these Terms of Use, including but not limited to the right to block access from a particular Internet address or account holder to this website. Privacy COPPA prohibits unfair or deceptive acts or practices in connection with the collection, use, or disclosure of personally identifiable information from and about children under 13 on the Internet. The law requires operators to notify parents and obtain their consent before collecting, using, or disclosing children's personal information. You can learn more about the SXR SDK Project Privacy Policy . Digital Millennium Copyright Act The SXR SDK Project respects the intellectual property of others, and we ask users of our websites to do the same. In accordance with the Digital Millennium Copyright Act (DMCA) and other applicable law, we have adopted a policy of terminating, in appropriate circumstances and at our sole discretion, subscribers or account holders who are deemed to be repeat infringers. We may also at our sole discretion limit access to our website and/or terminate the accounts of any users who infringe any intellectual property rights of others, whether or not there is any repeat infringement. Notice and Procedure for Notifying Designated Agent of Claims of Copyright Infringement If you believe that any material on this website infringes upon any copyright which you own or control, or that any link on this website directs users to another website that contains material that infringes upon any copyright which you own or control, you may file a notification of such infringement with our Designated Agent as set forth below. Notifications of claimed copyright infringement must be sent to the SXR SDK Project Designated Agent for notice of claims of copyright infringement. Our Designated Agent may be reached as follows: Designated Agent: Thomas Flynn Address of Designated Agent: 645 Clyde Avenue, Mountain View CA 94043 Email Address of Designated Agent:","title":"Terms of Service"},{"location":"about/terms_of_service/#sxr-sdk-project-terms-of-use","text":"March 20, 2015 Terms and Conditions of Use for the SXR SDK Project website BY ACCESSING, BROWSING OR USING THIS WEBSITE, YOU ACKNOWLEDGE THAT YOU HAVE READ, UNDERSTAND AND AGREE TO BE BOUND BY THESE TERMS AND CONDITIONS. This website is a service made available by the SXR SDK Project. All software, documentation, information, and/or other materials provided on and through this website (\"Content\") may be used solely under the following terms and conditions (\"Terms of Use\"). This website may contain other proprietary notices and copyright information, the terms of which must be observed and followed. The Content on this website may contain technical inaccuracies or typographical errors and may be changed or updated without notice. The SXR SDK Project may also make improvements and/or changes to the Content at any time without notice. The SXR SDK Project and its community members (\"Members\") assume no responsibility regarding the accuracy of the Content. Use of the Content is at the recipient's own risk. The SXR SDK Project and its Members provide no assurances that any reported problems with any Content will be resolved.","title":"SXR SDK Project Terms of Use"},{"location":"about/terms_of_service/#intellectual-property-rights","text":"Except as otherwise provided, Content on this website, including all materials posted by the SXR SDK Project, is licensed under a Creative Commons Attribution 3.0 License . All logos and trademarks contained on this website are and remain the property of their respective owners. No licenses or other rights in or to such logos and/or trademarks are granted. Except as otherwise expressly stated, by providing the Content, neither the SXR SDK Project nor its Members grant any licenses to any copyrights, patents, or any other intellectual property rights.","title":"Intellectual Property Rights"},{"location":"about/terms_of_service/#users-submissions","text":"Users are solely responsible for all materials, whether publicly posted or privately transmitted, that users upload, post, e-mail, transmit, or otherwise make available on our websites (\"User Content\"). Neither the SXR SDK Project nor any of its Members shall be liable for any claims arising out of User Content. You warrant that you have all rights needed to provide User Content in accordance with these terms and all applicable laws or regulations. The SXR SDK Project or other projects that may be hosted by the SXR SDK Project may have license terms or Contributor Agreements that are specific to the project and may require Users to sign an agreement (such as a Contributor Agreement) assigning and/or licensing rights in submissions made to such projects. In all such cases, and to the extent there is a conflict, those license terms or agreements take precedence over these Terms of Use. With respect to any User Content not governed by other project-specific terms or agreements, you agree that the following non-exclusive, irrevocable, royalty-free, worldwide licenses shall apply: Code Submissions User Content in the form of source or object code will be governed by the Apache 2.0 License. All Other Submissions User Content that is not in the form of source or object code, including but not limited to white papers, dissertations, articles or other literary works, Power Point presentations, encyclopedias, anthologies, wikis, blogs, diagrams, drawings, sketches, photos or other images, audio content, video content and audiovisual materials will be governed by the Creative Commons Attribution 3.0. The SXR SDK Project and its Members do not want to receive confidential information from you through this website. Please note that any information or material sent to the SXR SDK Project or the Members will be deemed NOT to be confidential. You are prohibited from posting or transmitting to or from this website any unlawful, threatening, libelous, defamatory, obscene, scandalous, inflammatory, pornographic, or profane material; or any other material that could give rise to any civil or criminal liability under the law.","title":"Users Submissions"},{"location":"about/terms_of_service/#disclaimers-and-limitations-of-liability","text":"The SXR SDK Project and the Members make no representations whatsoever about any other website that you may access through this website. When you access a non-SXR SDK project website, even one that may contain the SXR SDK Project's name or mark, please understand that it is independent from the SXR SDK Project, and that the SXR SDK Project and its Members have no control over the content on such websites. In addition, a link to a non-SXR SDK project website does not mean that the SXR SDK Project or its Members endorse or accept any responsibility for the content of or the use of such websites. It is up to you to take precautions to ensure that whatever you select for your use is free of such items as viruses, worms, Trojan horses, and other items of a destructive nature. IN NO EVENT WILL THE SXR SDK PROJECT AND/OR ITS MEMBERS BE LIABLE TO YOU (AN INDIVIDUAL OR ENTITY) OR ANY OTHER INDIVIDUAL OR ENTITY FOR ANY DIRECT, INDIRECT, INCIDENTAL, PUNITIVE, SPECIAL, OR CONSEQUENTIAL DAMAGES RELATED TO ANY USE OF THIS WEBSITE, THE CONTENT, OR ON ANY OTHER HYPERLINKED WEBSITE, INCLUDING, WITHOUT LIMITATION, ANY LOST PROFITS, LOST SALES, LOST REVENUE, LOSS OF GOODWILL, BUSINESS INTERRUPTION, LOSS OF PROGRAMS OR OTHER DATA ON YOUR INFORMATION HANDLING SYSTEM OR OTHERWISE, EVEN IF THE SXR SDK PROJECT OR ITS MEMBERS ARE EXPRESSLY ADVISED OR AWARE OF THE POSSIBILITY OF SUCH DAMAGES OR LOSSES. ALL CONTENT IS PROVIDED BY THE SXR SDK PROJECT AND/OR ITS MEMBERS ON AN \"AS IS\" BASIS ONLY. THE SXR SDK PROJECT AND ITS MEMBERS PROVIDE NO REPRESENTATIONS, CONDITIONS AND/OR WARRANTIES, EXPRESS OR IMPLIED, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF FITNESS FOR A PARTICULAR PURPOSE, MERCHANTABILITY AND NONINFRINGEMENT. The SXR SDK Project and its Members reserve the right to investigate complaints or reported violations of these Terms of Use and to take any action they deem appropriate including, without limitation, reporting any suspected unlawful activity to law enforcement officials, regulators, or other third-parties and disclosing any information necessary or appropriate to such persons or entities relating to user profiles, e-mail addresses, usage history, posted materials, IP addresses, and traffic information. The SXR SDK Project and its Members reserve the right to seek all remedies available at law and in equity for violations of these Terms of Use, including but not limited to the right to block access from a particular Internet address or account holder to this website.","title":"Disclaimers and Limitations of Liability"},{"location":"about/terms_of_service/#privacy","text":"COPPA prohibits unfair or deceptive acts or practices in connection with the collection, use, or disclosure of personally identifiable information from and about children under 13 on the Internet. The law requires operators to notify parents and obtain their consent before collecting, using, or disclosing children's personal information. You can learn more about the SXR SDK Project Privacy Policy .","title":"Privacy"},{"location":"about/terms_of_service/#digital-millennium-copyright-act","text":"The SXR SDK Project respects the intellectual property of others, and we ask users of our websites to do the same. In accordance with the Digital Millennium Copyright Act (DMCA) and other applicable law, we have adopted a policy of terminating, in appropriate circumstances and at our sole discretion, subscribers or account holders who are deemed to be repeat infringers. We may also at our sole discretion limit access to our website and/or terminate the accounts of any users who infringe any intellectual property rights of others, whether or not there is any repeat infringement.","title":"Digital Millennium Copyright Act"},{"location":"about/terms_of_service/#notice-and-procedure-for-notifying-designated-agent-of-claims-of-copyright-infringement","text":"If you believe that any material on this website infringes upon any copyright which you own or control, or that any link on this website directs users to another website that contains material that infringes upon any copyright which you own or control, you may file a notification of such infringement with our Designated Agent as set forth below. Notifications of claimed copyright infringement must be sent to the SXR SDK Project Designated Agent for notice of claims of copyright infringement. Our Designated Agent may be reached as follows: Designated Agent: Thomas Flynn Address of Designated Agent: 645 Clyde Avenue, Mountain View CA 94043 Email Address of Designated Agent:","title":"Notice and Procedure for Notifying Designated Agent of Claims of Copyright Infringement"},{"location":"blog/2017_4_17_x3d/","text":"SXR and the X3D file format by Mitch Williams April 17, 2017 You may think creating VR has a steep learning curve; that you need to be an experienced game programmer or Java/C++ expert. However, in addition to a java interface, the SXR SDK supports an XML-based 3D language that along with JavaScript for interactivity (skills in-common with HTML web page designers) makes VR creation simple. The X3D file format is an international standard specifying 3D scenes on the web. It is exported by 3D modeling tools such as 3D Studio Max, supported by many 3D printers, and is now integrated into the SXR SDK. X3D can be thought of as the 3D version of HTML. It uses similar tags with left and right brackets \u2018 \u2019 and \u2018 \u2019. Here is an example X3D file: X3D Scene Transform translation= \u201d0 0 -10\u201d Shape Appearance Material diffuseColor= 1 .5 0 / /Appearance Sphere/ /Shape /Transform /Scene /X3D This produces an orange sphere, 10 units away in front of the camera. You will likely see X3D embedded inside an HTML file. Saving the code below which contains the same X3D code above, and saving it as an .htm file will show the same orange sphere on a web page: html head title My first X3DOM page / title script type = text/javascript src = http://www.x3dom.org/download/x3dom.js / script link rel = stylesheet type = text/css href = http://www.x3dom.org/download/x3dom.css / / head body X3D Scene Transform translation = \u201d0 0 -10 \u201d Shape Appearance Material diffuseColor = 1 .5 0 / / Appearance Sphere / / Shape / Transform / Scene / X3D / body / html The HTML file relies on a JavaScript file, x3dom.js, that parses X3D and displays the 3D scene using WebGL. SXR parses the same X3D file, but uses GearVR\u2019s technology to display the orange sphere in VR. If you have the SXR development environment already set up with Android Studio, and have downloaded SXR\u2019s Demos repository , look for the folder sxr-x3d-demo for other examples plus showing how to insert your .x3d files. Remember that .x3d files will be added to Android Studio\u2019s \u2018assets\u2019 folder. Just change the line of code in the file X3DparserScript.java \u201cString filename = . . . \u201c to your .x3d file. Reviewing the X3D file, \u2018diffuseColor\u2019 is the color of the object (more on that later). Color in 3D is specified as red, green, blue with values between 0 and 1. The Sphere has red = 1, green = .5 and blue = 0, producing orange. The Sphere can be replaced with other primitives: Box, Cone or Cylinder. Rotation is specified as \u201crotation=\u2019x, y, z, angle\u2019\u201d where \u2018angle\u2019 is in radians. Thus a rotation of 90 degrees (1.57 radians) around the z-axis will be: rotation=\u20190 0 1 1.57\u2019. Now is a good time to experiment. Change the diffuseColor, translation or the object itself. This scene contains a red Box on the left rotated around the x-axis 1.2 radians, a green Cone in the center, and a blue Cylinder on the right rotated -.4 radians around the z-axis. X3D Scene Transform DEF= obj1 translation= -3 0 -10 rotation= 1 0 0 1.2 Shape Appearance Material diffuseColor= 1 0 0 / /Appearance Box/ /Shape /Transform Transform DEF= obj2 translation= 0 0 -10 Shape Appearance Material diffuseColor= 0 1 0 / /Appearance Cone/ /Shape /Transform Transform DEF= obj3 translation= 3 0 -10 rotation= 0 0 1 -.4 Shape Appearance Material diffuseColor= 0 0 1 / /Appearance Cylinder/ /Shape /Transform Viewpoint position= 0 0 0 / PointLight/ /Scene /X3D Toward the bottom there is a PointLight and Viewpoint, the light and camera in the scene. VR, just like a Hollywood movie, has \u201cLights, Camera, Action!\u201d Each Transform has a DEFine which assigns names to our Scene Objects as if they were actors in a movie. Feel free to experiment with the color, location and rotation of the primitives, then view them in GearVR. If you have access to a 3D modeling program such as 3D Studio (3DS) Max, Blender or BS Content Studio, you can create your own 3D scenes and display them in GearVR. Blender and BS Content Studio are free and export directly to X3D. 3DS Max exports to VRML, which can be converted to X3D using online tools such as Instant Reality converter . Additional tutorials can be found at https://doc.x3dom.org/tutorials/index.html and http://www.web3d.org/getting-started-x3d .","title":"SXR and the X3D file format"},{"location":"blog/2017_4_17_x3d/#sxr-and-the-x3d-file-format","text":"by Mitch Williams April 17, 2017 You may think creating VR has a steep learning curve; that you need to be an experienced game programmer or Java/C++ expert. However, in addition to a java interface, the SXR SDK supports an XML-based 3D language that along with JavaScript for interactivity (skills in-common with HTML web page designers) makes VR creation simple. The X3D file format is an international standard specifying 3D scenes on the web. It is exported by 3D modeling tools such as 3D Studio Max, supported by many 3D printers, and is now integrated into the SXR SDK. X3D can be thought of as the 3D version of HTML. It uses similar tags with left and right brackets \u2018 \u2019 and \u2018 \u2019. Here is an example X3D file: X3D Scene Transform translation= \u201d0 0 -10\u201d Shape Appearance Material diffuseColor= 1 .5 0 / /Appearance Sphere/ /Shape /Transform /Scene /X3D This produces an orange sphere, 10 units away in front of the camera. You will likely see X3D embedded inside an HTML file. Saving the code below which contains the same X3D code above, and saving it as an .htm file will show the same orange sphere on a web page: html head title My first X3DOM page / title script type = text/javascript src = http://www.x3dom.org/download/x3dom.js / script link rel = stylesheet type = text/css href = http://www.x3dom.org/download/x3dom.css / / head body X3D Scene Transform translation = \u201d0 0 -10 \u201d Shape Appearance Material diffuseColor = 1 .5 0 / / Appearance Sphere / / Shape / Transform / Scene / X3D / body / html The HTML file relies on a JavaScript file, x3dom.js, that parses X3D and displays the 3D scene using WebGL. SXR parses the same X3D file, but uses GearVR\u2019s technology to display the orange sphere in VR. If you have the SXR development environment already set up with Android Studio, and have downloaded SXR\u2019s Demos repository , look for the folder sxr-x3d-demo for other examples plus showing how to insert your .x3d files. Remember that .x3d files will be added to Android Studio\u2019s \u2018assets\u2019 folder. Just change the line of code in the file X3DparserScript.java \u201cString filename = . . . \u201c to your .x3d file. Reviewing the X3D file, \u2018diffuseColor\u2019 is the color of the object (more on that later). Color in 3D is specified as red, green, blue with values between 0 and 1. The Sphere has red = 1, green = .5 and blue = 0, producing orange. The Sphere can be replaced with other primitives: Box, Cone or Cylinder. Rotation is specified as \u201crotation=\u2019x, y, z, angle\u2019\u201d where \u2018angle\u2019 is in radians. Thus a rotation of 90 degrees (1.57 radians) around the z-axis will be: rotation=\u20190 0 1 1.57\u2019. Now is a good time to experiment. Change the diffuseColor, translation or the object itself. This scene contains a red Box on the left rotated around the x-axis 1.2 radians, a green Cone in the center, and a blue Cylinder on the right rotated -.4 radians around the z-axis. X3D Scene Transform DEF= obj1 translation= -3 0 -10 rotation= 1 0 0 1.2 Shape Appearance Material diffuseColor= 1 0 0 / /Appearance Box/ /Shape /Transform Transform DEF= obj2 translation= 0 0 -10 Shape Appearance Material diffuseColor= 0 1 0 / /Appearance Cone/ /Shape /Transform Transform DEF= obj3 translation= 3 0 -10 rotation= 0 0 1 -.4 Shape Appearance Material diffuseColor= 0 0 1 / /Appearance Cylinder/ /Shape /Transform Viewpoint position= 0 0 0 / PointLight/ /Scene /X3D Toward the bottom there is a PointLight and Viewpoint, the light and camera in the scene. VR, just like a Hollywood movie, has \u201cLights, Camera, Action!\u201d Each Transform has a DEFine which assigns names to our Scene Objects as if they were actors in a movie. Feel free to experiment with the color, location and rotation of the primitives, then view them in GearVR. If you have access to a 3D modeling program such as 3D Studio (3DS) Max, Blender or BS Content Studio, you can create your own 3D scenes and display them in GearVR. Blender and BS Content Studio are free and export directly to X3D. 3DS Max exports to VRML, which can be converted to X3D using online tools such as Instant Reality converter . Additional tutorials can be found at https://doc.x3dom.org/tutorials/index.html and http://www.web3d.org/getting-started-x3d .","title":"SXR and the X3D file format"},{"location":"blog/blender_plugin_guide/","text":"Blender Addon SXR SDK Blender Plugin provides a way for the Blender users to preview their creation in Gear VR. Prerequisite Blender Download and build sxrsdk-demos project Installation Download the SXR SDK project from github, and you can find the plugin in SXR/tools/blender_addon folder. Create a zip file of the sxr_exporter folder and import it through the add-ons tab of Blender User Preferences. Usage Open or create a blender project ( sample project ) Enable Import-Export: Export to SXR plugin in User preference Build and run the sxr-remote-scripting from sxrsdk-demos project on a device Switch to Import-Export tab of Blender and Choose the directory to export (default dir is SXRExportWorkspace located on user's home directory) Set Client's IP field to reflect the client's device IP address Click on \"Export\" button and preview the blender project in VR Q A Blender addon report error \"Connect attempt failed\" Make sure the IP address is correct, also make sure the computer and Gear VR device is on the same network","title":"Blender Addon for SXR"},{"location":"blog/blender_plugin_guide/#blender-addon","text":"SXR SDK Blender Plugin provides a way for the Blender users to preview their creation in Gear VR.","title":"Blender Addon"},{"location":"blog/blender_plugin_guide/#prerequisite","text":"Blender Download and build sxrsdk-demos project","title":"Prerequisite"},{"location":"blog/blender_plugin_guide/#installation","text":"Download the SXR SDK project from github, and you can find the plugin in SXR/tools/blender_addon folder. Create a zip file of the sxr_exporter folder and import it through the add-ons tab of Blender User Preferences.","title":"Installation"},{"location":"blog/blender_plugin_guide/#usage","text":"Open or create a blender project ( sample project ) Enable Import-Export: Export to SXR plugin in User preference Build and run the sxr-remote-scripting from sxrsdk-demos project on a device Switch to Import-Export tab of Blender and Choose the directory to export (default dir is SXRExportWorkspace located on user's home directory) Set Client's IP field to reflect the client's device IP address Click on \"Export\" button and preview the blender project in VR","title":"Usage"},{"location":"blog/blender_plugin_guide/#qa","text":"Blender addon report error \"Connect attempt failed\" Make sure the IP address is correct, also make sure the computer and Gear VR device is on the same network","title":"Q&amp;A"},{"location":"overview/supported_devices/","text":"SXR is designed to work with a veriety of Android devices listed below: Manufacturer Model Samsung Note 9 Galaxy S9+ Galaxy S9 Note 8 Galaxy S8 Galaxy S8+ Galaxy S7 Galaxy S7 Edge Note 5 Galaxy S6 Galaxy S6 Edge Galaxy S6+ Gear VR headset Google Daydream headset Daydream-ready phone","title":"Supported Devices"},{"location":"programming_guide/build_instructions/","text":"SXR SDK app requirements, build instructions, building and running, and sample apps In order to build and and run SXR applications (your own or sample apps) in Android Studio, you have two options: (Preferred) Download the latest release of previously built SXR SDK .aar files Optionally, locally build the SXR SDK from the latest source code Prerequisites For BOTH methods, locally building AND using a pre-built framework, the following prerequisites must be met. 1. Install Required SDKs Make sure follow the Getting Started Guide and install all the required SDKs 2. Building SXR SDK You can optionally locally build the SXR SDK from source code using Android Studio. Here are the steps: Add OVR_MOBILE_SDK to gradle.properties and set it to the path to the Oculus Mobile SDK; recommended to use the global gradle.properties $HOMEPATH/.gradle/gradle.properties or ~/.gradle/gradle.properties) . Add ANDROID_NDK_HOME to gradle.properties and set it to the path to the Android NDK installation. Navigate to the SXR SDK and select the folder, and click OK Click Make Project (from the Build menu) 3. Building and Running SXR Applications After you have the SXR SDK, by either locally building or using a pre-built framework, you can now import, build, and run SXR applications (your own or sample apps) in Android Studio. The specific procedure you use depends on whether you locally built the SXR SDK from source code files or used pre-built framework files. When building your own SXR apps from scratch, copy the appropriate device XML file from the SXR SDK to your application's assets folder. SXR provides an xml file for you to use: sxr.xml. Import the SXR application code. Click File - Open ... Navigate to the project folder (for example, sxr-simplesample). Click OK Clean and build the application. Go to the Build menu and click Clean ... Click Make Project (from the Build menu) Run the application. Connect an Android mobile device to your local machine. Select your project in the project explorer Click Run on the toolbar Note You may need to apply to Oculus for a signature file for your device. For application and use details, refer to the online signature generator ( https://dashboard.oculus.com/tools/osig-generator/ ) Generate Javadocs When locally building the SXR SDK, you can optionally generate Javadoc files with details about the SXR API. Optional: To get SXR API reference details by generating SXR Javadoc files in the specified directory: In Android Studio, click Project Generate Javadoc... In the Generate Javadoc window: Javadoc command : (Pathname to the Javadoc executable file) Typically, in the bin directory of the Java directory. Click on the plus-icon to expand the Framework listing . Checkmark src Select Use standard doclet Destination: (Convenient local directory to contain the Javadoc files) Optional Specify VM options: NOTE: You may encounter errors if VM options is not specified. Click Next Click Next VM options: -bootclasspath path to your Android jar file Click Finish","title":"Build Instructions"},{"location":"programming_guide/build_instructions/#prerequisites","text":"For BOTH methods, locally building AND using a pre-built framework, the following prerequisites must be met.","title":"Prerequisites"},{"location":"programming_guide/build_instructions/#1-install-required-sdks","text":"Make sure follow the Getting Started Guide and install all the required SDKs","title":"1. Install Required SDKs"},{"location":"programming_guide/build_instructions/#2-building-sxr-sdk","text":"You can optionally locally build the SXR SDK from source code using Android Studio. Here are the steps: Add OVR_MOBILE_SDK to gradle.properties and set it to the path to the Oculus Mobile SDK; recommended to use the global gradle.properties $HOMEPATH/.gradle/gradle.properties or ~/.gradle/gradle.properties) . Add ANDROID_NDK_HOME to gradle.properties and set it to the path to the Android NDK installation. Navigate to the SXR SDK and select the folder, and click OK Click Make Project (from the Build menu)","title":"2. Building SXR SDK"},{"location":"programming_guide/build_instructions/#3-building-and-running-sxr-applications","text":"After you have the SXR SDK, by either locally building or using a pre-built framework, you can now import, build, and run SXR applications (your own or sample apps) in Android Studio. The specific procedure you use depends on whether you locally built the SXR SDK from source code files or used pre-built framework files. When building your own SXR apps from scratch, copy the appropriate device XML file from the SXR SDK to your application's assets folder. SXR provides an xml file for you to use: sxr.xml. Import the SXR application code. Click File - Open ... Navigate to the project folder (for example, sxr-simplesample). Click OK Clean and build the application. Go to the Build menu and click Clean ... Click Make Project (from the Build menu) Run the application. Connect an Android mobile device to your local machine. Select your project in the project explorer Click Run on the toolbar Note You may need to apply to Oculus for a signature file for your device. For application and use details, refer to the online signature generator ( https://dashboard.oculus.com/tools/osig-generator/ )","title":"3. Building and Running SXR Applications"},{"location":"programming_guide/build_instructions/#generate-javadocs","text":"When locally building the SXR SDK, you can optionally generate Javadoc files with details about the SXR API. Optional: To get SXR API reference details by generating SXR Javadoc files in the specified directory: In Android Studio, click Project Generate Javadoc... In the Generate Javadoc window: Javadoc command : (Pathname to the Javadoc executable file) Typically, in the bin directory of the Java directory. Click on the plus-icon to expand the Framework listing . Checkmark src Select Use standard doclet Destination: (Convenient local directory to contain the Javadoc files) Optional Specify VM options: NOTE: You may encounter errors if VM options is not specified. Click Next Click Next VM options: -bootclasspath path to your Android jar file Click Finish","title":"Generate Javadocs"},{"location":"programming_guide/faq/","text":"1. Is there any example of object following the head tracking, just like a reticle? See sxr-tutorial-lesson2 sample . Examine the BalloonMain.java and the headTracker tracker object it sets up. The key part is adding the object to the main camera rig. 2. I want to implement a scrollable list of item like ListView in Android. How to go about that? Background objects: rendering order N, depth test on Clip object: rendering order N+1, depth test on, alpha blend on, alpha = 0 (completely transparent) List view object: rendering order N+2, depth test on The clip object should be a plane with a hole in it where you want to see the list view. It should be completely transparent. It will be rendered after the background so it will update the depth buffer but the background will show thru completely. This clip object should have a Z value putting it IN FRONT of the list view object even though it will be rendered before that object (because you set the rendering order to a smaller value). The SXR SDK will render objects in ascending rendering order so the background will be rendered first. The clip object will update the depth buffer so that anything drawn BEHIND it will show thru the hole but will be obscured by the transparent clip area (the depth buffer will do the clipping for us). 3. Can i use an emulator during development for testing? Short answer: No. Long answer: It would likely be somewhat painful to do. Oculus only provides 32bit arm libraries. Which means you would need to set up an arm emulator (rather than an x86 one). In that emulator, we would detect the oculus service is not on the system and fall back to daydream. However, in our experience, running an arm emulator is horrifically slow, especially for anything GL related. It's best to stick with a physical phone for development. 4. I am using Windows, trying to build the framework and getting weird errors. Like this one: ...\\sxrsdk\\SXR\\Framework\\framework\\..\\backend_oculus/src/main/jni/util/configuration_helper.cpp:235:1: fatal error: opening dependency file ./obj/local/armeabi-v7a/objs/...\\sxrsdk\\SXR\\Framework\\framework\\..\\backend_oculus/src/main/jni/util/configuration_helper.o.d: No such file or directory Your paths might be too long. Try moving the framework to C:\\ and build again. 5. I want to inflate and show an Android view. Can I do that? Yes. The sxr-renderableview sample shows how to do that. 6. I want to use ExoPlayer instead of MediaPlayer for video playback. Can I do this? Yes. See the sxr-360video sample, which allows you to use either. Set the USE_EXO_PLAYER flag in Minimal360VideoActivity.java. 7. How can I create a mixed VR android app and launching VR Mode later, by clicking a button for example? I need to create an activity visualized in normal mode for settings and later launch a VR mode, showing the \"you need gear vr\" screen if you have not attached it. Unfortunately, this is not supported. Apps get marked as \"vr\" not individual activities. Which means the prompt will show when you try to launch your \"normal\" activity. This is not an SXR limitation. 8. Trying to build a sample but I get the following error: What went wrong : Execution failed for task :app:transformClassesWithDexForDebug . com . android . build . api . transform . TransformException : com . android . ide . common . process . ProcessException : java . util . concurrent . ExecutionException : com . android . dex . DexException : Multiple dex files define Lcom / oculus / systemutils / BuildConfig ; Most likely you still have VrApi.jar and SystemUtils.jar under the framework module (sxrsdk/SXR/Framework/framework/src/main/libs/). Please remove them from there, clean and build. 9. I am using Linux and getting a strange aapt error during the build. Something like java.io.IOException: Cannot run program \"/aapt\": error=2, No such file or directory You might be missing support for executing 32bit binaries and/or libraries aapt depends on. Please run the following: sudo dpkg --add-architecture i386 sudo apt-get update sudo apt-get install libc6:i386 libncurses5:i386 libstdc++6:i386 sudo apt-get install zlib1g:i386 10. Is there support for the Oculus Platform SDK? Yes, the entitlement check is supported. Go to SXR/Extensions/. There is a platformsdk_support module. To build it run ./gradlew -Pplatformsdk_support=true platformsdk_support:assembleDebug . Checkout the javadoc in PlatformEntitlementCheck.java. Have been verified to work with Platform SDK versions 1.6, 1.7 and 1.8. For further information see https://github.com/sxrsdk/sxrsdk/wiki/Entitlement-Check-using-SXR 11. Is there any way to play youtube video from url? Yes. See https://github.com/sxrsdk/sxrsdk/issues/1033#issuecomment-278244683 12. I am trying to use SXR on a Google Pixel phone and I get this exception: 02-15 19:53:15.697 23156-23156/? E/AndroidRuntime: FATAL EXCEPTION: main Process: pl.lynx.daydream.test, PID: 23156 java.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader[DexPathList[[zip file /data/app/pl.lynx.daydream.test-2/base.apk ],nativeLibraryDirectories=[/data/app/pl.lynx.daydream.test-2/lib/arm64, /system/fake-libs64, /data/app/pl.lynx.daydream.test-2/base.apk!/lib/arm64-v8a, /system/lib64, /vendor/lib64]]] couldn t find libsxr.so Daydream has 64bit binaries but SXR only supports 32bit binaries. In your app's gradle file you need to add this: android { // ignore the x86 and arm-v8 files from the google vr libraries packagingOptions { exclude lib/x86/libsxr.so exclude lib/arm64-v8a/libsxr.so } } 13. I used to build the demos from the sxrsdk-demos repo just fine. Suddenly I am getting errors. What happened? The master branch is subject to frequent improvements. The SXR team pushes updated framework snapshots to the maven repo, but due to the gradle's caching you are most likely using outdated snapshot. Please pass the --refresh-dependencies argument to gradlew if you are building from the command line. Or you can just delete the gradle cache via rm -rf ~/.gradle/caches/. Alternatively you could use the 3.1 branch which is stable. After cloning the demos repo, switch to the release_v3.1 branch. 14. I am building an app from scratch. How do I add support for SXR to my app? What are the minimum dependencies? Please see this bare-bones project that can serve as a reference: https://github.com/sxrsdk/sxrsdk-demos/tree/master/template/SXRApplication . 15. My app in the Oculus Store fails to install on Android N devices. I get an UNTRUSTED_APK_ERROR error. Oculus doesn't support APK signature scheme v2 yet. It should be disabled if you plan to submit apps to the Oculus store. Android Studio seems to apply the scheme unconditionally. Build from the command line and include the following section in your gradle file: android { signingConfigs { release { v2SigningEnabled false storeFile file( full-path-to-your-store-file ) storePassword your_store_pwd keyAlias alias keyPassword key_pwd } } defaultConfig { signingConfig signingConfigs.release } } 16. Can you run SXR apps on your phone without a GearVR? Yes, in your phone's Settings- Applications- Application Manager- Gear VR Service- Manage Storage Tab on VR Service Version multiple times until the 'Developer Options' menu appears. Then flick on the 'Developer mode' switch. You may need to do this every time when the phone restarts 17. How to reduce nausea? Maintain a high frame-rate, at least 60 fps. Avoid rapidly turning the camera. Move slowly are carefully when teleporting. 18. How many triangles can I display max for a good VR experience with high frame rate? On a mobile phone such as Galaxy S6/S7, please keep triangle count in the thousands to tens of thousands range if possible, depending on shader complexities. A mobile GPU can display around 100,000 vertices with a simple shader, about half that if using real-time shadow mapping from a single light source. 19. How many separate scene objects can I display for a good VR experience? On OpenGL, each scene object can potentially generate a draw call. On most phones, exceeding 100 draw calls will compromise VR performance. SXR attempts to batch together objects which use the same shader when possible. 20. What are some graphics performance tips? Keep draw calls minimal and relatively cheap pixel shader. A mobile GPU can execute about 100 draw calls per frame. It can display about 100,000 vertices before it becomes difficult to maintain 60fps. Keep in mind shadows from shadow map more or less doubles the number of draw calls and vertices rendered. Use profiler to see if you are really GPU bound. 21. Which phones are compatible with the SXR SDK? Currently, Samsung Galaxy S6, S6 Edge, S6 Edge+, S7, S7 Edge, S7 Edge+, S8, S8+, Note 5 and Note 8.","title":"FAQ"},{"location":"programming_guide/faq/#1-is-there-any-example-of-object-following-the-head-tracking-just-like-a-reticle","text":"See sxr-tutorial-lesson2 sample . Examine the BalloonMain.java and the headTracker tracker object it sets up. The key part is adding the object to the main camera rig.","title":"1. Is there any example of object following the head tracking, just like a reticle?"},{"location":"programming_guide/faq/#2-i-want-to-implement-a-scrollable-list-of-item-like-listview-in-android-how-to-go-about-that","text":"Background objects: rendering order N, depth test on Clip object: rendering order N+1, depth test on, alpha blend on, alpha = 0 (completely transparent) List view object: rendering order N+2, depth test on The clip object should be a plane with a hole in it where you want to see the list view. It should be completely transparent. It will be rendered after the background so it will update the depth buffer but the background will show thru completely. This clip object should have a Z value putting it IN FRONT of the list view object even though it will be rendered before that object (because you set the rendering order to a smaller value). The SXR SDK will render objects in ascending rendering order so the background will be rendered first. The clip object will update the depth buffer so that anything drawn BEHIND it will show thru the hole but will be obscured by the transparent clip area (the depth buffer will do the clipping for us).","title":"2. I want to implement a scrollable list of item like ListView in Android. How to go about that?"},{"location":"programming_guide/faq/#3-can-i-use-an-emulator-during-development-for-testing","text":"Short answer: No. Long answer: It would likely be somewhat painful to do. Oculus only provides 32bit arm libraries. Which means you would need to set up an arm emulator (rather than an x86 one). In that emulator, we would detect the oculus service is not on the system and fall back to daydream. However, in our experience, running an arm emulator is horrifically slow, especially for anything GL related. It's best to stick with a physical phone for development.","title":"3. Can i use an emulator during development for testing?"},{"location":"programming_guide/faq/#4-i-am-using-windows-trying-to-build-the-framework-and-getting-weird-errors-like-this-one","text":"...\\sxrsdk\\SXR\\Framework\\framework\\..\\backend_oculus/src/main/jni/util/configuration_helper.cpp:235:1: fatal error: opening dependency file ./obj/local/armeabi-v7a/objs/...\\sxrsdk\\SXR\\Framework\\framework\\..\\backend_oculus/src/main/jni/util/configuration_helper.o.d: No such file or directory Your paths might be too long. Try moving the framework to C:\\ and build again.","title":"4. I am using Windows, trying to build the framework and getting weird errors. Like this one:"},{"location":"programming_guide/faq/#5-i-want-to-inflate-and-show-an-android-view-can-i-do-that","text":"Yes. The sxr-renderableview sample shows how to do that.","title":"5. I want to inflate and show an Android view. Can I do that?"},{"location":"programming_guide/faq/#6-i-want-to-use-exoplayer-instead-of-mediaplayer-for-video-playback-can-i-do-this","text":"Yes. See the sxr-360video sample, which allows you to use either. Set the USE_EXO_PLAYER flag in Minimal360VideoActivity.java.","title":"6. I want to use ExoPlayer instead of MediaPlayer for video playback. Can I do this?"},{"location":"programming_guide/faq/#7-how-can-i-create-a-mixed-vr-android-app-and-launching-vr-mode-later-by-clicking-a-button-for-example-i-need-to-create-an-activity-visualized-in-normal-mode-for-settings-and-later-launch-a-vr-mode-showing-the-you-need-gear-vr-screen-if-you-have-not-attached-it","text":"Unfortunately, this is not supported. Apps get marked as \"vr\" not individual activities. Which means the prompt will show when you try to launch your \"normal\" activity. This is not an SXR limitation.","title":"7. How can I create a mixed VR android app and launching VR Mode later, by clicking a button for example? I need to create an activity visualized in normal mode for settings and later launch a VR mode, showing the \"you need gear vr\" screen if you have not attached it."},{"location":"programming_guide/faq/#8-trying-to-build-a-sample-but-i-get-the-following-error","text":"What went wrong : Execution failed for task :app:transformClassesWithDexForDebug . com . android . build . api . transform . TransformException : com . android . ide . common . process . ProcessException : java . util . concurrent . ExecutionException : com . android . dex . DexException : Multiple dex files define Lcom / oculus / systemutils / BuildConfig ; Most likely you still have VrApi.jar and SystemUtils.jar under the framework module (sxrsdk/SXR/Framework/framework/src/main/libs/). Please remove them from there, clean and build.","title":"8. Trying to build a sample but I get the following error:"},{"location":"programming_guide/faq/#9-i-am-using-linux-and-getting-a-strange-aapt-error-during-the-build-something-like-javaioioexception-cannot-run-program-aapt-error2-no-such-file-or-directory","text":"You might be missing support for executing 32bit binaries and/or libraries aapt depends on. Please run the following: sudo dpkg --add-architecture i386 sudo apt-get update sudo apt-get install libc6:i386 libncurses5:i386 libstdc++6:i386 sudo apt-get install zlib1g:i386","title":"9. I am using Linux and getting a strange aapt error during the build. Something like java.io.IOException: Cannot run program \"/aapt\": error=2, No such file or directory"},{"location":"programming_guide/faq/#10-is-there-support-for-the-oculus-platform-sdk","text":"Yes, the entitlement check is supported. Go to SXR/Extensions/. There is a platformsdk_support module. To build it run ./gradlew -Pplatformsdk_support=true platformsdk_support:assembleDebug . Checkout the javadoc in PlatformEntitlementCheck.java. Have been verified to work with Platform SDK versions 1.6, 1.7 and 1.8. For further information see https://github.com/sxrsdk/sxrsdk/wiki/Entitlement-Check-using-SXR","title":"10. Is there support for the Oculus Platform SDK?"},{"location":"programming_guide/faq/#11-is-there-any-way-to-play-youtube-video-from-url","text":"Yes. See https://github.com/sxrsdk/sxrsdk/issues/1033#issuecomment-278244683","title":"11. Is there any way to play youtube video from url?"},{"location":"programming_guide/faq/#12-i-am-trying-to-use-sxr-on-a-google-pixel-phone-and-i-get-this-exception","text":"02-15 19:53:15.697 23156-23156/? E/AndroidRuntime: FATAL EXCEPTION: main Process: pl.lynx.daydream.test, PID: 23156 java.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader[DexPathList[[zip file /data/app/pl.lynx.daydream.test-2/base.apk ],nativeLibraryDirectories=[/data/app/pl.lynx.daydream.test-2/lib/arm64, /system/fake-libs64, /data/app/pl.lynx.daydream.test-2/base.apk!/lib/arm64-v8a, /system/lib64, /vendor/lib64]]] couldn t find libsxr.so Daydream has 64bit binaries but SXR only supports 32bit binaries. In your app's gradle file you need to add this: android { // ignore the x86 and arm-v8 files from the google vr libraries packagingOptions { exclude lib/x86/libsxr.so exclude lib/arm64-v8a/libsxr.so } }","title":"12. I am trying to use SXR on a Google Pixel phone and I get this exception:"},{"location":"programming_guide/faq/#13-i-used-to-build-the-demos-from-the-sxrsdk-demos-repo-just-fine-suddenly-i-am-getting-errors-what-happened","text":"The master branch is subject to frequent improvements. The SXR team pushes updated framework snapshots to the maven repo, but due to the gradle's caching you are most likely using outdated snapshot. Please pass the --refresh-dependencies argument to gradlew if you are building from the command line. Or you can just delete the gradle cache via rm -rf ~/.gradle/caches/. Alternatively you could use the 3.1 branch which is stable. After cloning the demos repo, switch to the release_v3.1 branch.","title":"13. I used to build the demos from the sxrsdk-demos repo just fine. Suddenly I am getting errors. What happened?"},{"location":"programming_guide/faq/#14-i-am-building-an-app-from-scratch-how-do-i-add-support-for-sxr-to-my-app-what-are-the-minimum-dependencies","text":"Please see this bare-bones project that can serve as a reference: https://github.com/sxrsdk/sxrsdk-demos/tree/master/template/SXRApplication .","title":"14. I am building an app from scratch. How do I add support for SXR to my app? What are the minimum dependencies?"},{"location":"programming_guide/faq/#15-my-app-in-the-oculus-store-fails-to-install-on-android-n-devices-i-get-an-untrusted_apk_error-error","text":"Oculus doesn't support APK signature scheme v2 yet. It should be disabled if you plan to submit apps to the Oculus store. Android Studio seems to apply the scheme unconditionally. Build from the command line and include the following section in your gradle file: android { signingConfigs { release { v2SigningEnabled false storeFile file( full-path-to-your-store-file ) storePassword your_store_pwd keyAlias alias keyPassword key_pwd } } defaultConfig { signingConfig signingConfigs.release } }","title":"15. My app in the Oculus Store fails to install on Android N devices. I get an UNTRUSTED_APK_ERROR error."},{"location":"programming_guide/faq/#16-can-you-run-sxr-apps-on-your-phone-without-a-gearvr","text":"Yes, in your phone's Settings- Applications- Application Manager- Gear VR Service- Manage Storage Tab on VR Service Version multiple times until the 'Developer Options' menu appears. Then flick on the 'Developer mode' switch. You may need to do this every time when the phone restarts","title":"16. Can you run SXR apps on your phone without a GearVR?"},{"location":"programming_guide/faq/#17-how-to-reduce-nausea","text":"Maintain a high frame-rate, at least 60 fps. Avoid rapidly turning the camera. Move slowly are carefully when teleporting.","title":"17. How to reduce nausea?"},{"location":"programming_guide/faq/#18-how-many-triangles-can-i-display-max-for-a-good-vr-experience-with-high-frame-rate","text":"On a mobile phone such as Galaxy S6/S7, please keep triangle count in the thousands to tens of thousands range if possible, depending on shader complexities. A mobile GPU can display around 100,000 vertices with a simple shader, about half that if using real-time shadow mapping from a single light source.","title":"18. How many triangles can I display max for a good VR experience with high frame rate?"},{"location":"programming_guide/faq/#19-how-many-separate-scene-objects-can-i-display-for-a-good-vr-experience","text":"On OpenGL, each scene object can potentially generate a draw call. On most phones, exceeding 100 draw calls will compromise VR performance. SXR attempts to batch together objects which use the same shader when possible.","title":"19. How many separate scene objects can I display for a good VR experience?"},{"location":"programming_guide/faq/#20-what-are-some-graphics-performance-tips","text":"Keep draw calls minimal and relatively cheap pixel shader. A mobile GPU can execute about 100 draw calls per frame. It can display about 100,000 vertices before it becomes difficult to maintain 60fps. Keep in mind shadows from shadow map more or less doubles the number of draw calls and vertices rendered. Use profiler to see if you are really GPU bound.","title":"20. What are some graphics performance tips?"},{"location":"programming_guide/faq/#21-which-phones-are-compatible-with-the-sxr-sdk","text":"Currently, Samsung Galaxy S6, S6 Edge, S6 Edge+, S7, S7 Edge, S7 Edge+, S8, S8+, Note 5 and Note 8.","title":"21. Which phones are compatible with the SXR SDK?"},{"location":"programming_guide/overview/","text":"SXR SDK Development Overview Introduction to SXR integration and app development SXR provides tools to speed up development of advanced features in high quality VR applications. Available EGL extensions (including dual scan, front buffer, MSAA, OVR multiview and tile rendering) allow the best render quality. The SXR SDK is a native code 3D rendering engine with an Android library interface. You can build non-trivial content using only built-in objects. You can add new objects (such as scene objects with or without shaders) derived from classes or by overriding some methods - SXR takes care of all hardware handholding. You can do just about everything in Java - all source code is published, so you can easily add to or tweak native code. Anatomy of SXR Applications SXR is an SDK which controls how and when your code is executed. Subclassing SXR objects allows you to add your own code. You can also listen to SXR events and provide callbacks that respond to them. A 3D scene is represented as a hierarchy of SXR scene objects. Each visible object has a triangle mesh describing its shape, a material describing its appearance properties and a transformation matrix controlling its position in the 3D world. You do not explicitly call the OpenGL or Vulkan API when using SXR. Instead, the SXR SDK manages all rendering, providing a higher level abstraction for graphics. When constructing an Android application, you subclass the Activity class. Similarly, when constructing an SXR application you subclass SXRActivity, providing initialization code to create a SXRMain to set up the initial 3D scene and handle input events. During initialization, SXRActivity creates a SXRViewManager which does all the heavy lifting. This class is responsible for task scheduling, 3D rendering, animation and asset loading. Thread Management One key constraint of embedded GPU programming is that there is only one GL context. That is, all GPU commands must come from the same thread - the GL thread. The GPU should always be busy; therefore, the graphics thread cannot be the main GUI thread. In the future, SXR will eventually relax this restriction when using the Vulkan API because that graphics interface permits multiple threads to simultaneously submit work. When starting SXR, your Android app creates the GL thread, puts the phone into stereoscopic mode, and supplies a pair of callback methods that run the app's startup and per-frame code on the graphics thread. SXR provides methods for any thread to schedule runnable callbacks to the graphics thread. All these callbacks mean that SXR programming is event-oriented on the graphics thread in just the same way that Android programming is event-oriented on the GUI thread. Running two independent event systems on two independent threads does mean that you have to think about IPC whenever your Android Activity code on the GUI thread interacts with the SXR code on the graphics thread. However, dual-thread operation also creates another huge section of your application that can take advantage of event atomicity. That is, callback events are method calls from a main loop - neither the GUI thread nor the graphics thread ever runs more than one callback at one time, and each callback has to run to completion before any other callback can start on that thread. Your graphics callbacks do not have to write code to keep other graphics callbacks from seeing data structures in a partially updated state. Scene Graph and Scene Objects Your startup code builds a scene graph made up of scene objects, and your per-frame code then manipulates the scene graph in real time. Each scene object has a 4x4 matrix that describes its position, orientation, and zoom relative to its parent. Each scene object can parent other scene objects, so complex objects can be composed of multiple small objects, each with its own shape and appearance, with all changing in synchrony. Each scene object provides methods to change its components using a lazy update pattern, which means that multiple updates per event cost very little more than a single update. You make a scene object visible by adding a surface geometry and a skin. The geometry is a mesh of 3D triangles. SXR provides methods to build simple rectangular quads, and to load more complex meshes from files built by 3D model editors. Each material class contains the shader type, values for all shader parameters, texture, and other uniform mappings. Each shader has two parts: a vertex shader and a fragment shader. The vertex shader is called for each vertex of each visible triangle and can compute triangle-specific values that are passed to the fragment shader, which draws each pixel of each visible triangle. SXR contains standard shaders that provide methods, such as simply sampling a texture (a bitmap image in GPU memory), without applying any lighting effects. You can create custom shaders by supplying vertex and fragment shaders and by declaring names to bind Java values to. The GLSL shader language is very simple and C-like; you can learn a lot by reading a few of the shaders in the sample applications. SXR also supports sharing specially constructed shaders between OpenGL and Vulkan. Scene Graph The scene graph describes the spatial relationship between objects in the scene. Each scene object has a 4x4 transformation matrix to position and orient it locally. The scene objects may be nested so that the transformations of the parent nodes are inherited by the children. This allows objects to be easily positioned and animated relative to one another. Here we see a scene graph for a butterfly with a body and two wings. Each scene object has a position and an orientation. The left and right wings can share the same mesh but it is positioned and oriented differently for each wing. The initial translation on the body is inherited by the wings. The form of your scene graph can have implications for the performance of your application. Typically, having lots of small objects performs poorly compared to several large objects with a similar total vertex count. This is because there is a considerable amount of overhead in rendering a single object. SXR attempts to batch objects together that do not move in order to improve performance. Types of Scene Objects You can have invisible scene objects. These have a location and a set of child objects. This can be useful to move a set of scene objects as a unit preserving their relative geometry. Visible scene objects have a render data component attached which contains the geometry defining the shape of the object and a material describing its appearance. The material contains the data that will be passed to the shader used by the GPU to draw the mesh. In addition to displaying geometry, a scene object can display text, 360 photos, 360 video, normal photos and video, Android application view and internet browser views. Scene Object Class Description SXRSphereNode constructs sphere geometry SXRCubeNode construct cube geometry SXRConeNode constructs cone geometry SXRCylinderNode constructs cylinder geometry SXRTextViewNode displays text SXRVideoNode displays a video SXRWebViewNode displays an internet browser window SXRCameraNode displays video from the phone camera SXRKeyboardNode displays 3D interactive keyboard Scene Construction Example Constructing the initial SXR scene usually involves importing a set of assets and placing them relative to one another. In this example we make a simple butterfly with an ellipsoid for a body and textured planes for wings. SXRContext context ; SXRTexture wingtex = context . getAssetLoader (). loadTexture ( new SXRAndroidResource ( context , R . drawable . wingtex )); SXRNode body = new SXRSphereObject ( context ); SXRNode leftwing = new SXRNode ( context , wingtex ); SXRNode rightwing = new SXRNode ( context , wingtex ); leftwing . getTransform (). setPosition (- 1 , 0 , 0 ); rightwing . getTransform (). setPosition ( 1 , 0 , 0 ); rightwing . getTransform (). setRotationY ( 180 ); Scene Object Components A scene object can have one or more components attached which provide additional capabilities. All scene objects have a SXRTransform component which supplies the 4x4 matrix used to position and orient the object in the scene. Attaching a SXRRenderData component referencing geometry and material properties will cause the geometry to be displayed in the scene. The following components can be attached to a SXRNode: SXRTransform - 4x4 transformation matrix SXRRenderData - geometry with material properties SXRLightBase - illumination source SXRCamera - camera SXRCameraRig - stereoscopic camera rig SXRCollider - collision geometry SXRBehavior - user defined component SXRPicker - pick from this viewpoint SXRBaseSensor - marshal pick events from children SXRRenderTarget - render to texture Each scene object can only have one component of a particular type. For example, you cannot attach two lights or two cameras to a single scene object. Components are retrieved and removed based on their type. When a component is attached to a scene object, it derives its position and orientation from the SXRTransform attached to that scene object. SXRNode function Description SXRComponent getComponent(long type) Get the component of the specified class attached to the owner scene object. void attachComponent(SXRComponent) Attach the given component to the scene object. void detachComponent(SXRComponent) Detach the given component from the scene object. void detachComponenet(long type) Detach the component of the specified type from the scene object. List getAllComponents(long type) Get all components of the given type from the scene object and its children. void forAllComponents(ComponentVisitor visitor, long type) Visit all components of the given type from the scene object and its children.","title":"Overview"},{"location":"programming_guide/overview/#sxr-sdk-development-overview","text":"Introduction to SXR integration and app development SXR provides tools to speed up development of advanced features in high quality VR applications. Available EGL extensions (including dual scan, front buffer, MSAA, OVR multiview and tile rendering) allow the best render quality. The SXR SDK is a native code 3D rendering engine with an Android library interface. You can build non-trivial content using only built-in objects. You can add new objects (such as scene objects with or without shaders) derived from classes or by overriding some methods - SXR takes care of all hardware handholding. You can do just about everything in Java - all source code is published, so you can easily add to or tweak native code.","title":"SXR SDK Development Overview"},{"location":"programming_guide/overview/#anatomy-of-sxr-applications","text":"SXR is an SDK which controls how and when your code is executed. Subclassing SXR objects allows you to add your own code. You can also listen to SXR events and provide callbacks that respond to them. A 3D scene is represented as a hierarchy of SXR scene objects. Each visible object has a triangle mesh describing its shape, a material describing its appearance properties and a transformation matrix controlling its position in the 3D world. You do not explicitly call the OpenGL or Vulkan API when using SXR. Instead, the SXR SDK manages all rendering, providing a higher level abstraction for graphics. When constructing an Android application, you subclass the Activity class. Similarly, when constructing an SXR application you subclass SXRActivity, providing initialization code to create a SXRMain to set up the initial 3D scene and handle input events. During initialization, SXRActivity creates a SXRViewManager which does all the heavy lifting. This class is responsible for task scheduling, 3D rendering, animation and asset loading.","title":"Anatomy of SXR Applications"},{"location":"programming_guide/overview/#thread-management","text":"One key constraint of embedded GPU programming is that there is only one GL context. That is, all GPU commands must come from the same thread - the GL thread. The GPU should always be busy; therefore, the graphics thread cannot be the main GUI thread. In the future, SXR will eventually relax this restriction when using the Vulkan API because that graphics interface permits multiple threads to simultaneously submit work. When starting SXR, your Android app creates the GL thread, puts the phone into stereoscopic mode, and supplies a pair of callback methods that run the app's startup and per-frame code on the graphics thread. SXR provides methods for any thread to schedule runnable callbacks to the graphics thread. All these callbacks mean that SXR programming is event-oriented on the graphics thread in just the same way that Android programming is event-oriented on the GUI thread. Running two independent event systems on two independent threads does mean that you have to think about IPC whenever your Android Activity code on the GUI thread interacts with the SXR code on the graphics thread. However, dual-thread operation also creates another huge section of your application that can take advantage of event atomicity. That is, callback events are method calls from a main loop - neither the GUI thread nor the graphics thread ever runs more than one callback at one time, and each callback has to run to completion before any other callback can start on that thread. Your graphics callbacks do not have to write code to keep other graphics callbacks from seeing data structures in a partially updated state.","title":"Thread Management"},{"location":"programming_guide/overview/#scene-graph-and-scene-objects","text":"Your startup code builds a scene graph made up of scene objects, and your per-frame code then manipulates the scene graph in real time. Each scene object has a 4x4 matrix that describes its position, orientation, and zoom relative to its parent. Each scene object can parent other scene objects, so complex objects can be composed of multiple small objects, each with its own shape and appearance, with all changing in synchrony. Each scene object provides methods to change its components using a lazy update pattern, which means that multiple updates per event cost very little more than a single update. You make a scene object visible by adding a surface geometry and a skin. The geometry is a mesh of 3D triangles. SXR provides methods to build simple rectangular quads, and to load more complex meshes from files built by 3D model editors. Each material class contains the shader type, values for all shader parameters, texture, and other uniform mappings. Each shader has two parts: a vertex shader and a fragment shader. The vertex shader is called for each vertex of each visible triangle and can compute triangle-specific values that are passed to the fragment shader, which draws each pixel of each visible triangle. SXR contains standard shaders that provide methods, such as simply sampling a texture (a bitmap image in GPU memory), without applying any lighting effects. You can create custom shaders by supplying vertex and fragment shaders and by declaring names to bind Java values to. The GLSL shader language is very simple and C-like; you can learn a lot by reading a few of the shaders in the sample applications. SXR also supports sharing specially constructed shaders between OpenGL and Vulkan.","title":"Scene Graph and Scene Objects"},{"location":"programming_guide/overview/#scene-graph","text":"The scene graph describes the spatial relationship between objects in the scene. Each scene object has a 4x4 transformation matrix to position and orient it locally. The scene objects may be nested so that the transformations of the parent nodes are inherited by the children. This allows objects to be easily positioned and animated relative to one another. Here we see a scene graph for a butterfly with a body and two wings. Each scene object has a position and an orientation. The left and right wings can share the same mesh but it is positioned and oriented differently for each wing. The initial translation on the body is inherited by the wings. The form of your scene graph can have implications for the performance of your application. Typically, having lots of small objects performs poorly compared to several large objects with a similar total vertex count. This is because there is a considerable amount of overhead in rendering a single object. SXR attempts to batch objects together that do not move in order to improve performance.","title":"Scene Graph"},{"location":"programming_guide/overview/#types-of-scene-objects","text":"You can have invisible scene objects. These have a location and a set of child objects. This can be useful to move a set of scene objects as a unit preserving their relative geometry. Visible scene objects have a render data component attached which contains the geometry defining the shape of the object and a material describing its appearance. The material contains the data that will be passed to the shader used by the GPU to draw the mesh. In addition to displaying geometry, a scene object can display text, 360 photos, 360 video, normal photos and video, Android application view and internet browser views. Scene Object Class Description SXRSphereNode constructs sphere geometry SXRCubeNode construct cube geometry SXRConeNode constructs cone geometry SXRCylinderNode constructs cylinder geometry SXRTextViewNode displays text SXRVideoNode displays a video SXRWebViewNode displays an internet browser window SXRCameraNode displays video from the phone camera SXRKeyboardNode displays 3D interactive keyboard","title":"Types of Scene Objects"},{"location":"programming_guide/overview/#scene-construction-example","text":"Constructing the initial SXR scene usually involves importing a set of assets and placing them relative to one another. In this example we make a simple butterfly with an ellipsoid for a body and textured planes for wings. SXRContext context ; SXRTexture wingtex = context . getAssetLoader (). loadTexture ( new SXRAndroidResource ( context , R . drawable . wingtex )); SXRNode body = new SXRSphereObject ( context ); SXRNode leftwing = new SXRNode ( context , wingtex ); SXRNode rightwing = new SXRNode ( context , wingtex ); leftwing . getTransform (). setPosition (- 1 , 0 , 0 ); rightwing . getTransform (). setPosition ( 1 , 0 , 0 ); rightwing . getTransform (). setRotationY ( 180 );","title":"Scene Construction Example"},{"location":"programming_guide/overview/#scene-object-components","text":"A scene object can have one or more components attached which provide additional capabilities. All scene objects have a SXRTransform component which supplies the 4x4 matrix used to position and orient the object in the scene. Attaching a SXRRenderData component referencing geometry and material properties will cause the geometry to be displayed in the scene. The following components can be attached to a SXRNode: SXRTransform - 4x4 transformation matrix SXRRenderData - geometry with material properties SXRLightBase - illumination source SXRCamera - camera SXRCameraRig - stereoscopic camera rig SXRCollider - collision geometry SXRBehavior - user defined component SXRPicker - pick from this viewpoint SXRBaseSensor - marshal pick events from children SXRRenderTarget - render to texture Each scene object can only have one component of a particular type. For example, you cannot attach two lights or two cameras to a single scene object. Components are retrieved and removed based on their type. When a component is attached to a scene object, it derives its position and orientation from the SXRTransform attached to that scene object. SXRNode function Description SXRComponent getComponent(long type) Get the component of the specified class attached to the owner scene object. void attachComponent(SXRComponent) Attach the given component to the scene object. void detachComponent(SXRComponent) Detach the given component from the scene object. void detachComponenet(long type) Detach the component of the specified type from the scene object. List getAllComponents(long type) Get all components of the given type from the scene object and its children. void forAllComponents(ComponentVisitor visitor, long type) Visit all components of the given type from the scene object and its children.","title":"Scene Object Components"},{"location":"programming_guide/sample_code/","text":".md-flex a { color: white; } .md-flex a:hover { text-decoration: none; } .md-nav a { color: black; } .md-nav a:hover { text-decoration: none; } .md-footer a { color: white; } .md-footer a:hover { text-decoration: none; } SXR SDK Samples and Demos To get the SXR SDK Samples and Demos, clone the following repository in the same directory as where you did the clone for the framework source code: $ git clone https://github.com/sxrsdk/sxrsdk-demos.git -b release_v3.2 !!!Note You should put both sxrsdk/ and sxrsdk-demos/ in the same directory. Sample SXR Applications Sample SXR applications, available in the SXR SDK, can provide you with valuable insight into writing your own VR applications. A minimal sample showing how to display an equirectangular (360) photo. A minimal sample showing how to display an equirectangular (360) video using either Android's MediaPlayer class or the ExoPlayer class. A simplified version of the sxr-3dcursor sample that shows how to use the 3DCursor plugin. Shows how to use SXR's accessibility classes. For example: InvertedColors, TextToSpeech, and Zoom. Simple sample showing how to use the SXR SDK with the Bullet Physics plugin. Simple sample showing how to use the camera2 api along with renderscript for use with the passthrough camera. Simple example of Spatial Audio using GoogleVR's audio library (previously used cardboard's audio library). A simple sample which can contain as many Stanford bunnies as we want to make it complex A simple sample that demostrates how to use VR controller. A nice demo that shows input from both the gamepad and touchpad to control a character. A simple example to show how to load in a cubemap and use it for the background as well as a reflection on an object. An example showing how to display Android Views inside VR and route events to those views. A simple picking example. A minimal example showing how to receive input from a gamepad. A larger sample that shows a concept of an immersive virtual museum. Uses many features of SXR: picking, TextViews, Video, input, etc. A minimal example showing how an application can be written with Javascript. A sample that shows how to create a virtual keyboard, including voice input, and use it in a simple trivia game. A minimal example showing how an application can be written with Lua. A simple sample that loads in an animated model and starts the animation. A viewer that allows you to select and display models stored in /sdcard/SXRModelViewer2/. You can look at the model from different angles, change lighting, look at it in wireframe, and toggle animations. Uses the libGDX plugin for UI. A simple sample showing how to use multiple lights. A sample showing how to use multiple render passes with the same geometry to show an outline. A sample showing how to use particle system plugin A sample used to test the performance of the SXR SDK The remote scripting sample enables the debug server and sets up a text object with the ipaddress of the phone so we know where to telnet into. Inflates and displays some Android views onto a rotating cube. A sample demostrates the render to texture functionality Shows how create the various scene object types: quad, cube, sphere, cylinder, cone, passthrough camera, text, video. Tap the touchpad to cycle through the objects. A sample that shows a light source with shadowing. A sample demostrates simple physics scene A simple sample that creates a quad and applies a texture to it. A sample that shows both heirarchy and animation. A sample that shows how to use the SXRSwitch node. Samples for Youtube SXR tutorial video A simple augmented reality sample using the Vuforia computer vision library. It looks for a marker and displays a teapot on top of it. You can use either the stone or chips markers. PDFs for the markers are in sxr-vuforia/app/src/main/. A sample for using WidgetViewer component","title":"Sample Code"},{"location":"programming_guide/sample_code/#sxr-sdk-samples-and-demos","text":"To get the SXR SDK Samples and Demos, clone the following repository in the same directory as where you did the clone for the framework source code: $ git clone https://github.com/sxrsdk/sxrsdk-demos.git -b release_v3.2 !!!Note You should put both sxrsdk/ and sxrsdk-demos/ in the same directory.","title":"SXR SDK Samples and Demos"},{"location":"programming_guide/sample_code/#sample-sxr-applications","text":"Sample SXR applications, available in the SXR SDK, can provide you with valuable insight into writing your own VR applications. A minimal sample showing how to display an equirectangular (360) photo. A minimal sample showing how to display an equirectangular (360) video using either Android's MediaPlayer class or the ExoPlayer class. A simplified version of the sxr-3dcursor sample that shows how to use the 3DCursor plugin. Shows how to use SXR's accessibility classes. For example: InvertedColors, TextToSpeech, and Zoom. Simple sample showing how to use the SXR SDK with the Bullet Physics plugin. Simple sample showing how to use the camera2 api along with renderscript for use with the passthrough camera. Simple example of Spatial Audio using GoogleVR's audio library (previously used cardboard's audio library). A simple sample which can contain as many Stanford bunnies as we want to make it complex A simple sample that demostrates how to use VR controller. A nice demo that shows input from both the gamepad and touchpad to control a character. A simple example to show how to load in a cubemap and use it for the background as well as a reflection on an object. An example showing how to display Android Views inside VR and route events to those views. A simple picking example. A minimal example showing how to receive input from a gamepad. A larger sample that shows a concept of an immersive virtual museum. Uses many features of SXR: picking, TextViews, Video, input, etc. A minimal example showing how an application can be written with Javascript. A sample that shows how to create a virtual keyboard, including voice input, and use it in a simple trivia game. A minimal example showing how an application can be written with Lua. A simple sample that loads in an animated model and starts the animation. A viewer that allows you to select and display models stored in /sdcard/SXRModelViewer2/. You can look at the model from different angles, change lighting, look at it in wireframe, and toggle animations. Uses the libGDX plugin for UI. A simple sample showing how to use multiple lights. A sample showing how to use multiple render passes with the same geometry to show an outline. A sample showing how to use particle system plugin A sample used to test the performance of the SXR SDK The remote scripting sample enables the debug server and sets up a text object with the ipaddress of the phone so we know where to telnet into. Inflates and displays some Android views onto a rotating cube. A sample demostrates the render to texture functionality Shows how create the various scene object types: quad, cube, sphere, cylinder, cone, passthrough camera, text, video. Tap the touchpad to cycle through the objects. A sample that shows a light source with shadowing. A sample demostrates simple physics scene A simple sample that creates a quad and applies a texture to it. A sample that shows both heirarchy and animation. A sample that shows how to use the SXRSwitch node. Samples for Youtube SXR tutorial video A simple augmented reality sample using the Vuforia computer vision library. It looks for a marker and displays a teapot on top of it. You can use either the stone or chips markers. PDFs for the markers are in sxr-vuforia/app/src/main/. A sample for using WidgetViewer component","title":"Sample SXR Applications"},{"location":"programming_guide/sxr_settings_file/","text":"Definitions of the SXR XML settings file parameters Before rendering can start, the framework needs to know about the characteristics of the display device. These are specified in the XML settings file passed to SXRActivity.setMain or SXRActivity.setScript when your application is being initialized. vr-app-settings framebufferPixelsHigh Height of the framebuffer framebufferPixelsWide Width of the framebuffer showLoadingIcon Enable / disable loading icon useProtectedFramebuffer Enable / disable use of protected framebuffer useSrgbFramebuffer Enable / disable use of SRGB framebuffer useMultiview Enable / disable OVR multiview extension useControllerTypes Comma separated list of the controller types made available to the application. The list is in priority order with preferred controller last. Supported types are gaze, mouse, gamepad, weartouchpad, controller and external. mono-mode-parms allowPowerSave If enabled, the application will run at 30 fps when power is low. Otherwise, it will show an error message when power is low. resetWindowFullScreen If enabled, the fullscreen flag of the activity window will be on when a VR activity returns from background to foreground. It will help performance since it won't draw a DecorView as background. performance-parms cpuLevel CPU clock level gpuLevel GPU clock level eye-buffer-parms colorFormat Format of the color buffer (default COLOR_8888) COLOR_5551 5 bits R,G,B, 1 bit alpha COLOR_565 5 bits red, 6 bits green, 5 bits blue COLOR_4444 4 bits RGBA COLOR_888 8 bits RGBA COLOR_888_sRGB SRGB color format COLOR_RGBA16F 16 bits float RGBA depthFormat Format of the depth buffer (default DEPTH_24) DEPTH_0 no depth buffer DEPTH_16 16 bit depth buffer DEPTH_24 24 bit depth buffer DEPTH_24_STENCIL_8 32 bit depth buffer fov-y Y field of view in degrees (default 90) resolutionWidth Eye buffer resolution width in pixels (default 1024) resolutionHeight Eye buffer resolution height in pixels (default 1024) resolveDepth True to resolve framebuffer to a texture (default false) multiSamples Number of framebuffer multisamples for anti-aliasing 1 = no multisampling (not recommended) 2 = 2xMSAA recommended setting 4 = 4xMSAA Higher visual quality but lower performance head-model-parms eyeHeight Distance from ground to eye headModelDepth Offset of head center ahead of eyes based on eye height headModelHeight Distance from neck joint to eyes based on eye height interpupillaryDistance Distance between left and right eye","title":"SXR Settings File"},{"location":"programming_guide/video_tutorials/","text":"Below is a set of six lessons that show how to build a simple VR game using the SXR SDK. The sessions are 10 - 20 minutes long and show live demonstrations of SXR programming. The sample code used in all the tutorials can be found here: https://github.com/sxrsdk/sxrsdk-demos Lesson 1: Overview of Tutorials Lesson 2: Application Structure and Scene Graph Lesson 3: Events and Picking Lesson 4: Components Lesson 5: Sound and Text Lesson 6: Working with Assets","title":"Video Tutorials"},{"location":"programming_guide/video_tutorials/#lesson-1-overview-of-tutorials","text":"","title":"Lesson 1: Overview of Tutorials"},{"location":"programming_guide/video_tutorials/#lesson-2-application-structure-and-scene-graph","text":"","title":"Lesson 2: Application Structure and Scene Graph"},{"location":"programming_guide/video_tutorials/#lesson-3-events-and-picking","text":"","title":"Lesson 3: Events and Picking"},{"location":"programming_guide/video_tutorials/#lesson-4-components","text":"","title":"Lesson 4: Components"},{"location":"programming_guide/video_tutorials/#lesson-5-sound-and-text","text":"","title":"Lesson 5: Sound and Text"},{"location":"programming_guide/video_tutorials/#lesson-6-working-with-assets","text":"","title":"Lesson 6: Working with Assets"},{"location":"programming_guide/features/builtin_legacy_shader/","text":"SXR SDK provides a set of built-in shaders for you to use in your applications. Although you can write custom shaders, for many applications these built-in shaders will be all that you need. SXRMaterial.SXRShaderType.Phong The Phong shader implements the phong lighting model for multiple light sources. All of the models imported by the asset loader use the phong shader so they will automatically respond to the light sources in the scene. This shader maps multiple textures onto a mesh illuminated by any light sources in the scene. Although it supports many different uniforms, you will typically only use a few of them. Depending on which uniforms you use and the format of your mesh, SXR SDK will generate a custom native shader optimized for your specific usage. Adding or removing a light source from the scene can cause a new native shader to be recompiled. uniform type description ambientTexture sampler2D ambient texture diffuseTexture sampler2D diffuse texture specularTexture sampler2D specular texture opacityTexture sampler2D opacity texture (alpha channel) normalTexture sampler2D normal texture emissiveTexture sampler2D emissive texture lightmapTexture sampler2D lightmap texture ambient_color vec4 ambient color diffuse_color vec4 diffuse color specular_color vec4 specular color emissive_color vec4 emissive color specular_exponent float specular exponent SXRMaterial.SXRShaderType.PhongLayered This shader performs the same computations as the Phong shader but allows layering of ambient, diffuse, specular, opacity and emissive texture maps. This shader supports up to two textures of each type and blends them at run time. It is primarily used for supporting FBX files with layered textures. Unless your application needs this functionality, the Phong shader is more efficient. The following blend operations are supported: value operation 0 multiply 1 add 2 subtract 3 divice 4 smooth add 5 signed add This table gives the additional uniforms for the Phong Layered shader. It supports all of the uniforms for the Phong shader as well. uniform type description ambientTexture1 sampler2D second ambient texture diffuseTexture1 sampler2D second diffuse texture specularTexture1 sampler2D second specular texture opacityTexture1 sampler2D second opacity texture emissiveTexture1 sampler2D second emissive texture lightmapTexture1 sampler2D second lightmap texture ambient_color vec4 ambient color diffuse_color vec4 diffuse color specular_color vec4 specular color emissive_color vec4 emissive color specular_exponent float specular exponent ambientTexture1_blendop int ambient texture blend operation diffuseTexture1_blendop int diffuse texture blend operation specularTexture1_blendop int specular texture blend operation opacityTexture1_blendop int opacity texture blend operation emissiveTexture1_blendop int emissive texture blend operation lightmapTexture1_blendop int lightmap texture blend operation SXRMaterial.SXRShaderType.UnlitHorizontalStereo Displays a single 2D texture across the framebuffer horizontally for both eyes. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The u_right parameter controls whether it displays on the left half or the right half of the output display. uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_right int 1 = right eye, 0 = left SXRMaterial.SXRShaderType.UnlitVertictalStereo Displays a single 2D texture across the framebuffer vertically for both eyes. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The u_right parameter controls whether it displays on the top half or the bottom half of the output display. uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_right int 1 = right eye, 0 = left SXRMaterial.SXRShaderType.OES Maps an external 2D texture onto the mesh. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The texture supplied as u_ texture must be and OES external texture (type GL_TEXTURE_EXTERNAL_OES, not GL_TEXTURE_2D) as this shader uses samplerExternalOES as opposed to sampler2D. uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_right int description SXRMaterial.SXRShaderType.OESHorizontalStereo Displays a single external 2D texture across the framebuffer vertically for both eyes. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The texture supplied as u_ texture must be and OES external texture (type GL_TEXTURE_EXTERNAL_OES, not GL_TEXTURE_2D) as this shader uses samplerExternalOES as opposed to sampler2D.The u_right parameter controls whether it displays on the left half or the right half of the output display. uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_right int 1 = right eye, 0 = left SXRMaterial.SXRShaderType.OESVerticalStereo Displays a single external 2D texture across the framebuffer vertically for both eyes. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The texture supplied as u_ texture must be and OES external texture (type GL_TEXTURE_EXTERNAL_OES, not GL_TEXTURE_2D) as this shader uses samplerExternalOES as opposed to sampler2D. The u_right parameter controls whether it displays on the top half or the bottom half of the output display. uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_right int 1 = right eye, 0 = left SXRMaterial.SXRShaderType.Cubemap Maps a cubemap texture onto the mesh. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The diffuse texture must be a cube map texture (six different textures for each face of the cube). uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_right int description SXRMaterial.SXRShaderType.CubemapReflection Wraps a cubemap texture around a mesh as a reflection map which varies with the viewpoint. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The diffuse texture must be a cube map texture (six different textures for each face of the cube). uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_view_i mat4atrix view matrix v_viewspace_position vec3 view space position v_viewspace_normal vec3 view space normal SXRMaterial.SXRShaderType.Texture Maps a single 2D texture onto a mesh with light sources. The computed fragment color is the product of the diffuse texture, diffuse color and opacity as illuminated the lights in the scene. It requires the vertex to have positions, normals and texture coordinates. If the scene is not lit, the material and light intensity properties are ignored. SXRPhongShader provides the same functionality and supports multiple layered textures. uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency ambient_color vec4 color reflected by ambient light diffuse_color vec4 color reflected by diffuse light specular_color float exponent for specular reflection specular_exponent vec4 color reflected by specular light ambient_intensity vec4 intensity of ambient light diffuse_intensity vec4 intensity of diffuse light specular_intensity vec4 intensity of specular light SXRMaterial.SXRShaderType.Lightmap Maps a lightmap texture onto a mesh. The computed fragment color is the product of the diffuse texture, diffuse color and opacity as illuminated by a light map. It requires the vertex to have positions, normals and texture coordinates. SXRPhongShader supports light mapping integrated with other surface shading capabilities. uniform type description u_main_texture sampler2D diffuse texture u_lightmap_texture sampler2D light map texture u_lightmap_offset vec2 light map offset u_lightmap_scale vec2 light map scal","title":"Built-In Legacy Shader"},{"location":"programming_guide/features/builtin_legacy_shader/#sxrmaterialsxrshadertypephong","text":"The Phong shader implements the phong lighting model for multiple light sources. All of the models imported by the asset loader use the phong shader so they will automatically respond to the light sources in the scene. This shader maps multiple textures onto a mesh illuminated by any light sources in the scene. Although it supports many different uniforms, you will typically only use a few of them. Depending on which uniforms you use and the format of your mesh, SXR SDK will generate a custom native shader optimized for your specific usage. Adding or removing a light source from the scene can cause a new native shader to be recompiled. uniform type description ambientTexture sampler2D ambient texture diffuseTexture sampler2D diffuse texture specularTexture sampler2D specular texture opacityTexture sampler2D opacity texture (alpha channel) normalTexture sampler2D normal texture emissiveTexture sampler2D emissive texture lightmapTexture sampler2D lightmap texture ambient_color vec4 ambient color diffuse_color vec4 diffuse color specular_color vec4 specular color emissive_color vec4 emissive color specular_exponent float specular exponent","title":"SXRMaterial.SXRShaderType.Phong"},{"location":"programming_guide/features/builtin_legacy_shader/#sxrmaterialsxrshadertypephonglayered","text":"This shader performs the same computations as the Phong shader but allows layering of ambient, diffuse, specular, opacity and emissive texture maps. This shader supports up to two textures of each type and blends them at run time. It is primarily used for supporting FBX files with layered textures. Unless your application needs this functionality, the Phong shader is more efficient. The following blend operations are supported: value operation 0 multiply 1 add 2 subtract 3 divice 4 smooth add 5 signed add This table gives the additional uniforms for the Phong Layered shader. It supports all of the uniforms for the Phong shader as well. uniform type description ambientTexture1 sampler2D second ambient texture diffuseTexture1 sampler2D second diffuse texture specularTexture1 sampler2D second specular texture opacityTexture1 sampler2D second opacity texture emissiveTexture1 sampler2D second emissive texture lightmapTexture1 sampler2D second lightmap texture ambient_color vec4 ambient color diffuse_color vec4 diffuse color specular_color vec4 specular color emissive_color vec4 emissive color specular_exponent float specular exponent ambientTexture1_blendop int ambient texture blend operation diffuseTexture1_blendop int diffuse texture blend operation specularTexture1_blendop int specular texture blend operation opacityTexture1_blendop int opacity texture blend operation emissiveTexture1_blendop int emissive texture blend operation lightmapTexture1_blendop int lightmap texture blend operation","title":"SXRMaterial.SXRShaderType.PhongLayered"},{"location":"programming_guide/features/builtin_legacy_shader/#sxrmaterialsxrshadertypeunlithorizontalstereo","text":"Displays a single 2D texture across the framebuffer horizontally for both eyes. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The u_right parameter controls whether it displays on the left half or the right half of the output display. uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_right int 1 = right eye, 0 = left","title":"SXRMaterial.SXRShaderType.UnlitHorizontalStereo"},{"location":"programming_guide/features/builtin_legacy_shader/#sxrmaterialsxrshadertypeunlitvertictalstereo","text":"Displays a single 2D texture across the framebuffer vertically for both eyes. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The u_right parameter controls whether it displays on the top half or the bottom half of the output display. uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_right int 1 = right eye, 0 = left","title":"SXRMaterial.SXRShaderType.UnlitVertictalStereo"},{"location":"programming_guide/features/builtin_legacy_shader/#sxrmaterialsxrshadertypeoes","text":"Maps an external 2D texture onto the mesh. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The texture supplied as u_ texture must be and OES external texture (type GL_TEXTURE_EXTERNAL_OES, not GL_TEXTURE_2D) as this shader uses samplerExternalOES as opposed to sampler2D. uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_right int description","title":"SXRMaterial.SXRShaderType.OES"},{"location":"programming_guide/features/builtin_legacy_shader/#sxrmaterialsxrshadertypeoeshorizontalstereo","text":"Displays a single external 2D texture across the framebuffer vertically for both eyes. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The texture supplied as u_ texture must be and OES external texture (type GL_TEXTURE_EXTERNAL_OES, not GL_TEXTURE_2D) as this shader uses samplerExternalOES as opposed to sampler2D.The u_right parameter controls whether it displays on the left half or the right half of the output display. uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_right int 1 = right eye, 0 = left","title":"SXRMaterial.SXRShaderType.OESHorizontalStereo"},{"location":"programming_guide/features/builtin_legacy_shader/#sxrmaterialsxrshadertypeoesverticalstereo","text":"Displays a single external 2D texture across the framebuffer vertically for both eyes. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The texture supplied as u_ texture must be and OES external texture (type GL_TEXTURE_EXTERNAL_OES, not GL_TEXTURE_2D) as this shader uses samplerExternalOES as opposed to sampler2D. The u_right parameter controls whether it displays on the top half or the bottom half of the output display. uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_right int 1 = right eye, 0 = left","title":"SXRMaterial.SXRShaderType.OESVerticalStereo"},{"location":"programming_guide/features/builtin_legacy_shader/#sxrmaterialsxrshadertypecubemap","text":"Maps a cubemap texture onto the mesh. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The diffuse texture must be a cube map texture (six different textures for each face of the cube). uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_right int description","title":"SXRMaterial.SXRShaderType.Cubemap"},{"location":"programming_guide/features/builtin_legacy_shader/#sxrmaterialsxrshadertypecubemapreflection","text":"Wraps a cubemap texture around a mesh as a reflection map which varies with the viewpoint. The computed fragment color is the product of the diffuse texture, diffuse color and opacity. It requires the vertex to have positions and texture coordinates. Normals are not required because lights in the scene are not used by this shader. The diffuse texture must be a cube map texture (six different textures for each face of the cube). uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency u_view_i mat4atrix view matrix v_viewspace_position vec3 view space position v_viewspace_normal vec3 view space normal","title":"SXRMaterial.SXRShaderType.CubemapReflection"},{"location":"programming_guide/features/builtin_legacy_shader/#sxrmaterialsxrshadertypetexture","text":"Maps a single 2D texture onto a mesh with light sources. The computed fragment color is the product of the diffuse texture, diffuse color and opacity as illuminated the lights in the scene. It requires the vertex to have positions, normals and texture coordinates. If the scene is not lit, the material and light intensity properties are ignored. SXRPhongShader provides the same functionality and supports multiple layered textures. uniform type description u_texture sampler2D diffuse texture u_color vec3 RGB diffuse color u_opacity float alpha for transparency ambient_color vec4 color reflected by ambient light diffuse_color vec4 color reflected by diffuse light specular_color float exponent for specular reflection specular_exponent vec4 color reflected by specular light ambient_intensity vec4 intensity of ambient light diffuse_intensity vec4 intensity of diffuse light specular_intensity vec4 intensity of specular light","title":"SXRMaterial.SXRShaderType.Texture"},{"location":"programming_guide/features/builtin_legacy_shader/#sxrmaterialsxrshadertypelightmap","text":"Maps a lightmap texture onto a mesh. The computed fragment color is the product of the diffuse texture, diffuse color and opacity as illuminated by a light map. It requires the vertex to have positions, normals and texture coordinates. SXRPhongShader supports light mapping integrated with other surface shading capabilities. uniform type description u_main_texture sampler2D diffuse texture u_lightmap_texture sampler2D light map texture u_lightmap_offset vec2 light map offset u_lightmap_scale vec2 light map scal","title":"SXRMaterial.SXRShaderType.Lightmap"},{"location":"programming_guide/features/lighting/","text":"VR lights, classes, shadows, uniforms, and examples Lights control the illumination of visible scene objects. Depending on the color, intensity and position of the lights, objects may appear lighter, darker or shadowed. The final color of an object depends on both materials and lighting. Together they provide everything the fragment shader needs to compute the final color. The fragment shader combines the contributions of all the lights in the scene to compute illumination per pixel. At this time, the SXR SDK does not support vertex lighting. All lights in the scene are global - they illuminate all the scene objects that have the lighting effect enabled. A light must be attached to a scene object before it can illuminate anything. The scene object determines the position and direction of the light. By default, a light with no transformation points down the positive Z axis towards the viewer. Built-in Light Classes The light's class determines what lighting algorithm is used by the GPU. Three built-in light classes are provided by the SXR SDK which implement the Phong shading model per pixel. These work together with the Phong surface shader class SXRPhongShader. SXRDirectLight: A directional light is infinitely far away and illuminates only from a specific direction. This light has color and direction properties. SXRPointLight: A point light illuminates in all directions from a specific position. This light has color and position properties. SXRSpotLight: A spot light illuminates in a cone radiating from a point. It has color, position and direction. All lights have an enabled uniform which enables or disables the light. The point and spot lights support attenuation factors which control how the light falls off with distance according to this equation: Attenuation = 1 / (attenuation_constant + attenuation_linear * distance + attenuation_quadratic * distance * distance) The light object contains the data used by the fragment shader. It is accessed in terms of key / value pairs where the key is a string containing the name of the uniform and the value is a scalar or vector. The SXR SDK automatically loads these values into the fragment shader uniforms for you. Shadows The SXR SDK can calculate shadow maps for directional and spot lights. You can enable shadow mapping by calling SXRLightBase.setCastShadow with a true parameter. Shadow mapping involves considerable overhead per frame because it renders the scene from the viewpoint of the light to calculate the shadow map. It also uses up more uniform variables. If you disable shadow mapping on all lights, the SXR SDK will free up all resources used for shadow mapping and return to normal performance. Built-in Light Uniforms This table describes the uniforms used by the built-in Phong lighting implementation. uniform name type description enabled int 1 = light is enabled, 0 = disabled world_position vec3 position of light in world space world_direction vec3 orientation of light in world space specular_exponent vec4 color reflected by specular light ambient_intensity vec4 intensity of ambient light diffuse_intensity vec4 intensity of diffuse light specular_intensity vec4 intensity of specular light attenuation_constant float constant attenuation factor attenuation_linear vec4 linear attenuation factor attenuation_quadratic float quadratic attenuation inner_cone_angle float spotlight inner cone angle outer_cone_angle float spotlight outer cone angle Light Construction Example A light is a component that is attached to a scene object which gives it both a position and a direction. An individual light can be enabled and disabled programmatically without causing shader compilation. All other light attributes are implementation specific. This example uses the lights built-into SXR SDK which implement the Phong lighting model. Here we constructs a red spot light. SXRSpotLight createSpotLight ( SXRContext sxrContext ) { SXRSpotLight light = new SXRSpotLight ( sxrContext ); light . setDiffuseIntensity ( 1 , 0 , 0 ); light . setSpecularIntensity ( 1 , 0 , 0 ); light . setInnerCone ( 10 ); light . setOuterCone ( 15 ); return light ; } You need to attach your light to a SXRNode before it can illuminate anything. To enable multiple lighting support the SXRPhongShader template must be selected. You can also turn the lighting effect on and off for a particular mesh. In this example we light a sphere with the spot light created above. SXRLightBase light = createSpotLight ( sxrContext ); SXRNode lightNode = new SXRNode ( sxrContext ); SXRMaterial material = new new SXRMaterial ( sxrContext , SXRMaterial . SXRShaderType . Phong . ID ); SXRNode sphereNode = new SXRSphereNode ( sxrContext , material ); material . setVec4 ( diffuse_color , 1.0f , 0.8f , 0.5f , 1.0f ); material . setVec4 ( specular_color , 1.0 , 1.0 , 1.0 , 1.0f ); material . setFloat ( specular_exponent , 5.0f ); sphereNode . attachComponent ( light ); SXRRenderData rdata = sphereNode . getRenderData (); rdata . enableLight ();","title":"Lighting"},{"location":"programming_guide/features/lighting/#vr-lights-classes-shadows-uniforms-and-examples","text":"Lights control the illumination of visible scene objects. Depending on the color, intensity and position of the lights, objects may appear lighter, darker or shadowed. The final color of an object depends on both materials and lighting. Together they provide everything the fragment shader needs to compute the final color. The fragment shader combines the contributions of all the lights in the scene to compute illumination per pixel. At this time, the SXR SDK does not support vertex lighting. All lights in the scene are global - they illuminate all the scene objects that have the lighting effect enabled. A light must be attached to a scene object before it can illuminate anything. The scene object determines the position and direction of the light. By default, a light with no transformation points down the positive Z axis towards the viewer.","title":"VR lights, classes, shadows, uniforms, and examples"},{"location":"programming_guide/features/lighting/#built-in-light-classes","text":"The light's class determines what lighting algorithm is used by the GPU. Three built-in light classes are provided by the SXR SDK which implement the Phong shading model per pixel. These work together with the Phong surface shader class SXRPhongShader. SXRDirectLight: A directional light is infinitely far away and illuminates only from a specific direction. This light has color and direction properties. SXRPointLight: A point light illuminates in all directions from a specific position. This light has color and position properties. SXRSpotLight: A spot light illuminates in a cone radiating from a point. It has color, position and direction. All lights have an enabled uniform which enables or disables the light. The point and spot lights support attenuation factors which control how the light falls off with distance according to this equation: Attenuation = 1 / (attenuation_constant + attenuation_linear * distance + attenuation_quadratic * distance * distance) The light object contains the data used by the fragment shader. It is accessed in terms of key / value pairs where the key is a string containing the name of the uniform and the value is a scalar or vector. The SXR SDK automatically loads these values into the fragment shader uniforms for you.","title":"Built-in Light Classes"},{"location":"programming_guide/features/lighting/#shadows","text":"The SXR SDK can calculate shadow maps for directional and spot lights. You can enable shadow mapping by calling SXRLightBase.setCastShadow with a true parameter. Shadow mapping involves considerable overhead per frame because it renders the scene from the viewpoint of the light to calculate the shadow map. It also uses up more uniform variables. If you disable shadow mapping on all lights, the SXR SDK will free up all resources used for shadow mapping and return to normal performance.","title":"Shadows"},{"location":"programming_guide/features/lighting/#built-in-light-uniforms","text":"This table describes the uniforms used by the built-in Phong lighting implementation. uniform name type description enabled int 1 = light is enabled, 0 = disabled world_position vec3 position of light in world space world_direction vec3 orientation of light in world space specular_exponent vec4 color reflected by specular light ambient_intensity vec4 intensity of ambient light diffuse_intensity vec4 intensity of diffuse light specular_intensity vec4 intensity of specular light attenuation_constant float constant attenuation factor attenuation_linear vec4 linear attenuation factor attenuation_quadratic float quadratic attenuation inner_cone_angle float spotlight inner cone angle outer_cone_angle float spotlight outer cone angle","title":"Built-in Light Uniforms"},{"location":"programming_guide/features/lighting/#light-construction-example","text":"A light is a component that is attached to a scene object which gives it both a position and a direction. An individual light can be enabled and disabled programmatically without causing shader compilation. All other light attributes are implementation specific. This example uses the lights built-into SXR SDK which implement the Phong lighting model. Here we constructs a red spot light. SXRSpotLight createSpotLight ( SXRContext sxrContext ) { SXRSpotLight light = new SXRSpotLight ( sxrContext ); light . setDiffuseIntensity ( 1 , 0 , 0 ); light . setSpecularIntensity ( 1 , 0 , 0 ); light . setInnerCone ( 10 ); light . setOuterCone ( 15 ); return light ; } You need to attach your light to a SXRNode before it can illuminate anything. To enable multiple lighting support the SXRPhongShader template must be selected. You can also turn the lighting effect on and off for a particular mesh. In this example we light a sphere with the spot light created above. SXRLightBase light = createSpotLight ( sxrContext ); SXRNode lightNode = new SXRNode ( sxrContext ); SXRMaterial material = new new SXRMaterial ( sxrContext , SXRMaterial . SXRShaderType . Phong . ID ); SXRNode sphereNode = new SXRSphereNode ( sxrContext , material ); material . setVec4 ( diffuse_color , 1.0f , 0.8f , 0.5f , 1.0f ); material . setVec4 ( specular_color , 1.0 , 1.0 , 1.0 , 1.0f ); material . setFloat ( specular_exponent , 5.0f ); sphereNode . attachComponent ( light ); SXRRenderData rdata = sphereNode . getRenderData (); rdata . enableLight ();","title":"Light Construction Example"},{"location":"programming_guide/features/loading_assets/","text":"The SXR SDK supports loading of 3D content files both synchronously and asynchronously. Your application may issue a blocking load and wait for the asset or get a callback when the asset loading is finished. The SXR SDK can import .OBJ, .FBX, Collada (.dae) and X3D file formats, as well as all file formats supported by Assimp . The SXR SDK can also read all commonly used bitmap file formats. Loading a 3D Model Loading models is handled by the SXRAssetLoader class which is accessible from the context by calling SXRContext.getAssetLoader(). The asset loader can load models from a variety of places. If you are providing a file name, a prefix on the name indicates the origin of the file: \"sd:\" designates the model on the phone SD card. \"http:\" or \"https:\" designates the model is on the internet. No prefix meaqns the filename is relative to the \"assets\" directory. For more flexibility, you can use the SXRAndroidResource class which lets you import assets from resources in your application or from an already open Android stream. Both models and textures can be loaded from SXRAndroidResource objects. SXRAndroidResource Constructors Volume Type Input source SXRAndroidResource(String path) ResourceType.LINUX_FILESYSTEM SD card SXRAndroidResource(File file) ResourceType.LINUX_FILESYSTEM SD card SXRAndroidResource(SXRContext, int resourceID) ResourceType.ANDROID_RESOURCE res directory SXRAndroidResource(Context, int resourceID) ResourceType.ANDROID_RESOURCE res directory SXRAndroidResource(SXRContext, String path) ResourceType.ANDROID_ASSETS assets directory SXRAndroidResource(SXRContext, URL url) ResourceType.NETWORK internet SXRAndroidResource(SXRContext, InputStream stream) ResourceType.INPUT_STREAM input stream The SXRAssetLoader.loadModel function loads a model from a device and returns as soon as the model geometry has been parsed and accumulated. This model may not have been added to the scene yet. If you pass the current SXRScene as an argument, the asset loader will wait until all of the textures in the model have been loaded and then add it to the scene. If you omit the argument, the model is not added to the scene and you will need to add it in your own code. Model Loading Examples This example shows how to load a model from a URL and another from the application resources. The textures are loaded in the background in another thread. The model will be added to the scene when all of its textures have completed loading. The model returned may not be completely loaded but all of the geometry will be accessible. Usually assets are loaded in the onInit function of your main script. public void onInit ( SXRContext context ) { SXRScene scene = context . getMainScene (); try { String url = https://raw.githubusercontent.com/sxrsdk/sxrsdk-demos/master/sxrjassimpmodelloader/assets/trees/trees9.3ds ; SXRNode model1 = context . getAssetLoader (). loadModel ( url , scene ); model1 . getTransform (). setPosition ( 0.0f , - 4.0f , - 20.0f ); SXRAndroidResource resource = new SXRAndroidResource ( context , R . raw . spaceship ); EnumSet SXRImportSettings settings = SXRImportSettings . getRecommendedSettings (); SXRNode model2 = context . getAssetLoader (). loadModel ( resource , settings , true , scene ); model2 . getTransform (). setPositionZ (- 10.0f ); } catch ( IOException e ) { Log . e ( ERROR , Failed to load model: %s , e ); } } Import Settings The SXRImportSettings object controls how the asset is imported. Depending on what your application is going to do with the model, import settings can help optimize performance. By default, all models are imported in full fidelity - all vertex components, light sources, cameras and textures are included. If you are not using light sources, it is more efficient to omit normals from the meshes and to not import any light sources in the model. Similarly, if you do not plan to animate the model, importing without animation will be faster and will suppress bone indices and bone weights from your meshes, which will cause the SXR SDK to use a more efficient shader. Setting What it does NO_LIGHTING Suppress import of normals and light sources NO_ANIMATION Suppress import of animation (bones, bone indices, bone weights and animation clips) NO_TEXTURING Suppress import of textures and texture coordinates START_ANIMATIONS Automatically start animations CALCULATE_TANGENTS Calculate tangents required for normal mapping JOIN_IDENTICAL_VERTICES* Join vertices when possible TRIANGULATE* Triangulate all meshes (required for SXR) CALCULATE_NORMALS Calculate normals if not present CALCULATE_SMOOTH_NORMALS Calculate and smooth normals LIMIT_BONE_WEIGHT* Limit bone weight to 4 (required for SXR) IMPROVE_VERTEX_CACHE_LOCALITY reorder vertices for cache locality SORTBY_PRIMITIVE_TYPE* Split meshes by primitive type OPTIMIZE_MESHES Combine meshes when possible OPTIMIZE_GRAPH Merge nodes without bones FLIP_UV* Flip UV coordinates Typically you will get the recommended settings (they are starred in the table) and add to them since a few of these settings are required for SXR to function properly. Only indexed triangle meshes are supported and meshes may only have four bones. Asynchronous Loading The asset loader can also asynchronously load geometry and textures. You have the option of providing an asset event handler which will notify your application when textures and geometry are loaded and when the asset and all of its textures have finished loading. In this case, a model is placed in the scene and the asset loader adds the imported scene objects as children. You can also request the asset loader to replace the entire scene. The asynchronous forms of loadModel specify the input asset as a SXRResourceVolume object. This object allows multiple assets to be loaded from a single input stream, such as a ZIP file. You can also subclass SXRResourceVolume to get complete control over the asset loading process. This example waits for a model to be loaded from the assets directory and then centers it before adding it to the scene. SXRScene scene ; SXRNode root = new SXRNode ( context ); SXRResourceVolume volume = new SXRResourceVolume ( context , models/mymodel.fbx ); context . getAssetLoader (). loadModel ( root , volume , new IAssetEvents () { public void onAssetLoaded ( SXRContext context , SXRNode model , String filePath , String errors ); { BoundingVolume bv = model . getBoundingVolume (); Vector3f c = bv . center (); model . getTransform (). setPosition (- c . x , - c . y , - c . z - 1.0f ); } public void onModelLoaded ( SXRContext context , SXRNode model , String filePath ) { } public void onTextureLoaded ( SXRContext context , SXRTexture texture , String filePath ) { } public void onModelError ( SXRContext context , String error , String filePath ) { } public void onTextureError ( SXRContext context , String error , String filePath ) { } }); } Loading Textures Imported 3D assets tyically create bitmap textures but the asset loader can import textures directly in many other formats. You can import cubemaps, compressed cubemaps, floating point textures as well as compressed and uncompressed bitmaps. All textures are loaded asynchronously in a background thread. The asset loader immediately returns a SXRTexture object but the SXRImage providing the data for the texture may not be available yet. The SXR SDK will not render a mesh until all of the textures it requires are loaded. Typically your application does not need to know when textures are loaded but, if this is necessary, the asset loader provides a callback mechanism for this purpose. This example shows how to load a cubemap texture from a ZIP file and apply use it as a skybox. SXRTexture tex = ctx . getAssetLoader (). loadCubemapTexture ( new SXRAndroidResource ( ctx , R . raw . beach )); SXRMaterial cubeMapMtl = new SXRMaterial ( ctx , SXRMaterial . SXRShaderType . Cubemap . ID ); SXRNode skybox = new SXRCubeNode ( ctx , false , cubeMapMtl ); cubeMapMtl . setTexture ( u_texture , tex ); skybox . getTransform (). setScale ( 10 , 10 , 10 ); skybox . setName ( background ); scene . addNode ( skybox );","title":"Loading Assets"},{"location":"programming_guide/features/loading_assets/#loading-a-3d-model","text":"Loading models is handled by the SXRAssetLoader class which is accessible from the context by calling SXRContext.getAssetLoader(). The asset loader can load models from a variety of places. If you are providing a file name, a prefix on the name indicates the origin of the file: \"sd:\" designates the model on the phone SD card. \"http:\" or \"https:\" designates the model is on the internet. No prefix meaqns the filename is relative to the \"assets\" directory. For more flexibility, you can use the SXRAndroidResource class which lets you import assets from resources in your application or from an already open Android stream. Both models and textures can be loaded from SXRAndroidResource objects. SXRAndroidResource Constructors Volume Type Input source SXRAndroidResource(String path) ResourceType.LINUX_FILESYSTEM SD card SXRAndroidResource(File file) ResourceType.LINUX_FILESYSTEM SD card SXRAndroidResource(SXRContext, int resourceID) ResourceType.ANDROID_RESOURCE res directory SXRAndroidResource(Context, int resourceID) ResourceType.ANDROID_RESOURCE res directory SXRAndroidResource(SXRContext, String path) ResourceType.ANDROID_ASSETS assets directory SXRAndroidResource(SXRContext, URL url) ResourceType.NETWORK internet SXRAndroidResource(SXRContext, InputStream stream) ResourceType.INPUT_STREAM input stream The SXRAssetLoader.loadModel function loads a model from a device and returns as soon as the model geometry has been parsed and accumulated. This model may not have been added to the scene yet. If you pass the current SXRScene as an argument, the asset loader will wait until all of the textures in the model have been loaded and then add it to the scene. If you omit the argument, the model is not added to the scene and you will need to add it in your own code.","title":"Loading a 3D Model"},{"location":"programming_guide/features/loading_assets/#model-loading-examples","text":"This example shows how to load a model from a URL and another from the application resources. The textures are loaded in the background in another thread. The model will be added to the scene when all of its textures have completed loading. The model returned may not be completely loaded but all of the geometry will be accessible. Usually assets are loaded in the onInit function of your main script. public void onInit ( SXRContext context ) { SXRScene scene = context . getMainScene (); try { String url = https://raw.githubusercontent.com/sxrsdk/sxrsdk-demos/master/sxrjassimpmodelloader/assets/trees/trees9.3ds ; SXRNode model1 = context . getAssetLoader (). loadModel ( url , scene ); model1 . getTransform (). setPosition ( 0.0f , - 4.0f , - 20.0f ); SXRAndroidResource resource = new SXRAndroidResource ( context , R . raw . spaceship ); EnumSet SXRImportSettings settings = SXRImportSettings . getRecommendedSettings (); SXRNode model2 = context . getAssetLoader (). loadModel ( resource , settings , true , scene ); model2 . getTransform (). setPositionZ (- 10.0f ); } catch ( IOException e ) { Log . e ( ERROR , Failed to load model: %s , e ); } }","title":"Model Loading Examples"},{"location":"programming_guide/features/loading_assets/#import-settings","text":"The SXRImportSettings object controls how the asset is imported. Depending on what your application is going to do with the model, import settings can help optimize performance. By default, all models are imported in full fidelity - all vertex components, light sources, cameras and textures are included. If you are not using light sources, it is more efficient to omit normals from the meshes and to not import any light sources in the model. Similarly, if you do not plan to animate the model, importing without animation will be faster and will suppress bone indices and bone weights from your meshes, which will cause the SXR SDK to use a more efficient shader. Setting What it does NO_LIGHTING Suppress import of normals and light sources NO_ANIMATION Suppress import of animation (bones, bone indices, bone weights and animation clips) NO_TEXTURING Suppress import of textures and texture coordinates START_ANIMATIONS Automatically start animations CALCULATE_TANGENTS Calculate tangents required for normal mapping JOIN_IDENTICAL_VERTICES* Join vertices when possible TRIANGULATE* Triangulate all meshes (required for SXR) CALCULATE_NORMALS Calculate normals if not present CALCULATE_SMOOTH_NORMALS Calculate and smooth normals LIMIT_BONE_WEIGHT* Limit bone weight to 4 (required for SXR) IMPROVE_VERTEX_CACHE_LOCALITY reorder vertices for cache locality SORTBY_PRIMITIVE_TYPE* Split meshes by primitive type OPTIMIZE_MESHES Combine meshes when possible OPTIMIZE_GRAPH Merge nodes without bones FLIP_UV* Flip UV coordinates Typically you will get the recommended settings (they are starred in the table) and add to them since a few of these settings are required for SXR to function properly. Only indexed triangle meshes are supported and meshes may only have four bones.","title":"Import Settings"},{"location":"programming_guide/features/loading_assets/#asynchronous-loading","text":"The asset loader can also asynchronously load geometry and textures. You have the option of providing an asset event handler which will notify your application when textures and geometry are loaded and when the asset and all of its textures have finished loading. In this case, a model is placed in the scene and the asset loader adds the imported scene objects as children. You can also request the asset loader to replace the entire scene. The asynchronous forms of loadModel specify the input asset as a SXRResourceVolume object. This object allows multiple assets to be loaded from a single input stream, such as a ZIP file. You can also subclass SXRResourceVolume to get complete control over the asset loading process. This example waits for a model to be loaded from the assets directory and then centers it before adding it to the scene. SXRScene scene ; SXRNode root = new SXRNode ( context ); SXRResourceVolume volume = new SXRResourceVolume ( context , models/mymodel.fbx ); context . getAssetLoader (). loadModel ( root , volume , new IAssetEvents () { public void onAssetLoaded ( SXRContext context , SXRNode model , String filePath , String errors ); { BoundingVolume bv = model . getBoundingVolume (); Vector3f c = bv . center (); model . getTransform (). setPosition (- c . x , - c . y , - c . z - 1.0f ); } public void onModelLoaded ( SXRContext context , SXRNode model , String filePath ) { } public void onTextureLoaded ( SXRContext context , SXRTexture texture , String filePath ) { } public void onModelError ( SXRContext context , String error , String filePath ) { } public void onTextureError ( SXRContext context , String error , String filePath ) { } }); }","title":"Asynchronous Loading"},{"location":"programming_guide/features/loading_assets/#loading-textures","text":"Imported 3D assets tyically create bitmap textures but the asset loader can import textures directly in many other formats. You can import cubemaps, compressed cubemaps, floating point textures as well as compressed and uncompressed bitmaps. All textures are loaded asynchronously in a background thread. The asset loader immediately returns a SXRTexture object but the SXRImage providing the data for the texture may not be available yet. The SXR SDK will not render a mesh until all of the textures it requires are loaded. Typically your application does not need to know when textures are loaded but, if this is necessary, the asset loader provides a callback mechanism for this purpose. This example shows how to load a cubemap texture from a ZIP file and apply use it as a skybox. SXRTexture tex = ctx . getAssetLoader (). loadCubemapTexture ( new SXRAndroidResource ( ctx , R . raw . beach )); SXRMaterial cubeMapMtl = new SXRMaterial ( ctx , SXRMaterial . SXRShaderType . Cubemap . ID ); SXRNode skybox = new SXRCubeNode ( ctx , false , cubeMapMtl ); cubeMapMtl . setTexture ( u_texture , tex ); skybox . getTransform (). setScale ( 10 , 10 , 10 ); skybox . setName ( background ); scene . addNode ( skybox );","title":"Loading Textures"},{"location":"programming_guide/features/materials/","text":"VR materials, access, and examples A material dictates how a scene object will be colored and textured. The visual appearance of a mesh in the scene is controlled by a fragment shader program in the GPU. The SXR SDK will automatically construct a shader for common use cases but you can also provide your own shader code. The SXRMaterial object encapsulates the fragment shader and all of its associated data. This usually includes one or more texture maps and lighting properties that affect how the surface reacts to lights in the scene. Because you can write custom shaders, you can attach your own custom data to a material that your shader can use in computations. This data can be scalar numbers (float or int), arrays or textures. Each custom data element has a string key used to look up or modify its value. When the object is rendered, these values are passed to the shader program. This picture shows a material with two custom data parameters - a diffuse color with an alpha (4 floats) and an integer enabling transparency. Accessing Shader Uniforms The SXRMaterial object provides access to the fragment shader uniforms by name. Setting the value of a material parameter will set the correspondingly named uniform variable in the fragment shader associated with that material. SXRMaterial has a set of functions that read and write the material parameters based on type. You also use SXRMaterial to bind textures to samplers in the shader. Adding a texture by name to a material binds that texture to the sampler of the same name in the shader. Shader Type SXRMaterial Setter SXRMaterial Getter float setFloat(String name, float v) float getFloat(String name) float2 setVec2(String name, float[] v) float[] getVec2(String name) float3 setVec3(String name, float[] v) float[] getVec3(String name) float4 setVec4(String name, float[] v) float[] getVec4(String name) float[] setFloatArray(String name, float[] v) float[] getFloatVec(String name) int[] setIntArray(String name, int[] v) int[] getIntVec(String name) int setInt(String name, int v) int getInt(String name) mat4 setMat4(String name, float m00, .. float m33) float[] getFloatArray(String name) sampler2D setTexture(String name, SXRTexture t) SXRTexture getTexture(String name) Material Construction Example A material contains all the data required for the specific shader you are going to use. You will set up different parameters for different shaders. The SXR SDK has several SXRDeveloperGuide.LegacyShaders which can render meshes in a variety of ways. All of them use the same SXRMaterial object but with different properties. In this example we construct a SXRMaterial to be used with the phong shader. This shader requires us to provide a diffuse texture as well as material and lighting properties. SXRMaterial createMaterial ( SXRContext sxrContext ) { SXRMaterial material = createMaterial ( sxrContext ); SXRTexture tex = sxrContext . getAssetLoader (). loadTexture ( new SXRAndroidResource ( sxrContext , R . drawable . gearvr_logo )); material . setVec4 ( diffuse_color , 0.5f , 0.5f , 0.5f , 1.0f ); material . setVec4 ( ambient_color , 0.2f , 0.2f , 0.2f , 1.0f ); material . setVec4 ( specular_color , 1.0f , 1.0f , 1.0f , 1.0f ); material . setFloat ( 128.0f ); material . setTexture ( diffuseTexture , tex ); return material ; }","title":"Materials"},{"location":"programming_guide/features/materials/#vr-materials-access-and-examples","text":"A material dictates how a scene object will be colored and textured. The visual appearance of a mesh in the scene is controlled by a fragment shader program in the GPU. The SXR SDK will automatically construct a shader for common use cases but you can also provide your own shader code. The SXRMaterial object encapsulates the fragment shader and all of its associated data. This usually includes one or more texture maps and lighting properties that affect how the surface reacts to lights in the scene. Because you can write custom shaders, you can attach your own custom data to a material that your shader can use in computations. This data can be scalar numbers (float or int), arrays or textures. Each custom data element has a string key used to look up or modify its value. When the object is rendered, these values are passed to the shader program. This picture shows a material with two custom data parameters - a diffuse color with an alpha (4 floats) and an integer enabling transparency.","title":"VR materials, access, and examples"},{"location":"programming_guide/features/materials/#accessing-shader-uniforms","text":"The SXRMaterial object provides access to the fragment shader uniforms by name. Setting the value of a material parameter will set the correspondingly named uniform variable in the fragment shader associated with that material. SXRMaterial has a set of functions that read and write the material parameters based on type. You also use SXRMaterial to bind textures to samplers in the shader. Adding a texture by name to a material binds that texture to the sampler of the same name in the shader. Shader Type SXRMaterial Setter SXRMaterial Getter float setFloat(String name, float v) float getFloat(String name) float2 setVec2(String name, float[] v) float[] getVec2(String name) float3 setVec3(String name, float[] v) float[] getVec3(String name) float4 setVec4(String name, float[] v) float[] getVec4(String name) float[] setFloatArray(String name, float[] v) float[] getFloatVec(String name) int[] setIntArray(String name, int[] v) int[] getIntVec(String name) int setInt(String name, int v) int getInt(String name) mat4 setMat4(String name, float m00, .. float m33) float[] getFloatArray(String name) sampler2D setTexture(String name, SXRTexture t) SXRTexture getTexture(String name)","title":"Accessing Shader Uniforms"},{"location":"programming_guide/features/materials/#material-construction-example","text":"A material contains all the data required for the specific shader you are going to use. You will set up different parameters for different shaders. The SXR SDK has several SXRDeveloperGuide.LegacyShaders which can render meshes in a variety of ways. All of them use the same SXRMaterial object but with different properties. In this example we construct a SXRMaterial to be used with the phong shader. This shader requires us to provide a diffuse texture as well as material and lighting properties. SXRMaterial createMaterial ( SXRContext sxrContext ) { SXRMaterial material = createMaterial ( sxrContext ); SXRTexture tex = sxrContext . getAssetLoader (). loadTexture ( new SXRAndroidResource ( sxrContext , R . drawable . gearvr_logo )); material . setVec4 ( diffuse_color , 0.5f , 0.5f , 0.5f , 1.0f ); material . setVec4 ( ambient_color , 0.2f , 0.2f , 0.2f , 1.0f ); material . setVec4 ( specular_color , 1.0f , 1.0f , 1.0f , 1.0f ); material . setFloat ( 128.0f ); material . setTexture ( diffuseTexture , tex ); return material ; }","title":"Material Construction Example"},{"location":"programming_guide/features/meshes/","text":"VR mesh types, access, and examples Indexed triangle meshes are the only shape definition currently supported by the SXR SDK. Each mesh contains a set of vertices with the 3D locations of the triangle coordinates. Typically these are unique locations to maximize vertex sharing but this is not a requirement. A triangle has three indices designating which vertices are used by that triangle. In addition to positions, a mesh may have normals and texture coordinates as well. These arrays, if present, must follow the same ordering as the vertices. There is only one set of triangle indices to reference the position, normal and texture coordinate. This is unlike some systems which permit multiple index tables. Skinned Meshes Skinned meshes have vertex bone data to indicate which bones affect which vertices in the mesh. A bone is a transform matrix which affects a subset of vertices in the mesh. Each vertex can be influenced by up to four bones. A mesh also contains a list of the bone transforms (SXRBone objects) that influence its vertices. The bone indices in the vertex array reference the bones in this list. The SXR SDK executes skinning on the GPU but it calculates the bone matrices on the CPU. Accessing Mesh Components The vertex shader used to render the mesh determines which vertex components are required. The SXR SDK built-in shaders rely on positions, normals, texture coordinates and bone information. You can write your own shaders which use other vertex components. Each vertex component has a unique name and type. The SXR vertex components are vectors containing between one and four floats. Each component has a function wh|ich can get or set that component for the entire vertex array. SXRMesh provides convenience functions for the built-in types. Reading or writing the vertex array is a high overhead operation and should not be done every frame. The index array describes an indexed triangle list. Each triangle has three consecutive indices in the array designating the vertices from the vertex array that represent that triangle. The index array may either be 16-bit or 32-bit. Attribute Name SXRMesh Setter SXRMesh Getter a_position setVertices(float[]) float[] getVertices() a_normal setNormals(float[]) float[] getNormals() a_texcoord setTexCoords(float[]) float[] getTexCoords() SXRMesh Setter SXRMesh Getter setFloatArray(String name, float[]) float[] getFloatArray(String name) setFloatVec(String name, FloatBuffer) getFloatVec(String name, FloatBuffer) setIntArray(String name, int[]) int[] getIntArray(String name) setIntVec(String name, IntBuffer) getIntVec(String name, IntBuffer) setIndices(int[]) int[] getIndices() setTriangles(char[]) char[] getTriangles() Mesh Construction Example Most of the time your code will obtain meshes by loading asset files. You can also construct or modify meshes programmatically. A mesh may contain positions, normal and texture coordinates. Depending on the shader used to display the mesh, some of these vertex components may not be used. For example, a shader which does not do lighting will typically not need normals. You can omit the normals and texture coordinate arrays if your shader doesn't need them. This function constructs a mesh of two triangles with only positions and normals. (If you try to use a textured shader with this mesh, you will get an error.) SXRMesh createMesh ( SXRContext sxrContext ) { SXRMesh mesh = new SXRMesh ( sxrContext ); float [] vertices = { - 1.0f , 0.0f , 0.0f , 0.0f , 1.0f , 0.0f , 1.0f , 0.0f , 0.0f , 0.0f , - 1.0f , 0.0f }; float [] normals = { 0 , 0 , 1 , 0 , 0 , 1 , 0 , 0 , 1 , 0 , 0 , 1 }; char [] triangles = { 0 , 1 , 2 , 2 , 3 , 0 }; mesh . setVertices ( vertices ); mesh . setNormals ( normals ); mesh . setTriangles ( triangles ); return mesh ; } You need to attach your mesh to a SXRNode before it can be displayed. The SXRRenderData object holds both a mesh and a material. Each visible scene object must have render data. This code adds the newly constructed mesh to the scene. Here we assume the SXRMaterial has already been constructed. SXRMesh mesh = createMesh ( sxrContext ); SXRNode obj = new SXRNode ( sxrContext , mesh ); SXRRenderData rdata = obj . getRenderData (); rdata . setMaterial ( material ); Vertex and Index Buffers The vertices and indices of the mesh are actually kept as separate SXR objects and they can be shared across meshes. SXRVertexBuffer contains a set of vertices that can be used by a mesh. SXRIndexBuffer contains a set of face indices. The layout of the vertices in the vertex buffer is established at construction time and cannot be changed. The vertex descriptor string describes the name and type of each vertex component. The supported types are float, float2, float3, float4, int, int2, int3 and int4 . The default vertex descriptor if none is specified is \"float3 a_position float2 a_texcoord float3 a_normal\" which will work with all of the built-in shaders. The size of the indices in the index buffer is also fixed at construction time. Indices may be either 2 bytes or 4 bytes. In this example, we create two scene objects representing different faces of a cube which share the same vertex array. float [] pos = new float [] { 1 , 1 , 1 , 1 , - 1 , 1 , - 1 , 1 , 1 , - 1 , - 1 , 1 , 1 , 1 , - 1 , 1 , - 1 , - 1 , - 1 , 1 , - 1 , - 1 , - 1 , - 1 ,}; float [] uv = new float [] { 0 , 0 , 0 , 1 , 0 , 1 , 1 , 0 , 0 , 0 , 0 , 1 , 0 , 1 , 1 , 0 }; SXRVertexBuffer cubeVerts = new SXRVertexBuffer ( context , float3 a_position float2 a_texcoord ); SXRIndexBuffer face1Tris = new SXRIndexBuffer ( context , 2 , 6 ); SXRIndexBuffer face2Tris = new SXRIndexBuffer ( context , 2 , 6 ); SXRMesh mesh1 = new SXRMesh ( cubeVerts , face1Tris ); SXRMesh mesh2 = new SXRMesh ( cubeVerts , face2Tris ); cubeVerts . setFloatArray ( a_position , pos ); cubeVerts . setFloatArray ( a_texcoord , uv ); face1Tris . setShortVec ( new char [] { 0 , 1 , 2 , 2 , 1 , 3 }); face2Tris . setShortVec ( new char [] { 4 , 5 , 6 , 6 , 5 , 7 }); SXRNode object1 = new SXRNode ( context , mesh1 ); SXRNode object2 = new SXRNode ( context , mesh2 );","title":"Meshes"},{"location":"programming_guide/features/meshes/#vr-mesh-types-access-and-examples","text":"Indexed triangle meshes are the only shape definition currently supported by the SXR SDK. Each mesh contains a set of vertices with the 3D locations of the triangle coordinates. Typically these are unique locations to maximize vertex sharing but this is not a requirement. A triangle has three indices designating which vertices are used by that triangle. In addition to positions, a mesh may have normals and texture coordinates as well. These arrays, if present, must follow the same ordering as the vertices. There is only one set of triangle indices to reference the position, normal and texture coordinate. This is unlike some systems which permit multiple index tables.","title":"VR mesh types, access, and examples"},{"location":"programming_guide/features/meshes/#skinned-meshes","text":"Skinned meshes have vertex bone data to indicate which bones affect which vertices in the mesh. A bone is a transform matrix which affects a subset of vertices in the mesh. Each vertex can be influenced by up to four bones. A mesh also contains a list of the bone transforms (SXRBone objects) that influence its vertices. The bone indices in the vertex array reference the bones in this list. The SXR SDK executes skinning on the GPU but it calculates the bone matrices on the CPU.","title":"Skinned Meshes"},{"location":"programming_guide/features/meshes/#accessing-mesh-components","text":"The vertex shader used to render the mesh determines which vertex components are required. The SXR SDK built-in shaders rely on positions, normals, texture coordinates and bone information. You can write your own shaders which use other vertex components. Each vertex component has a unique name and type. The SXR vertex components are vectors containing between one and four floats. Each component has a function wh|ich can get or set that component for the entire vertex array. SXRMesh provides convenience functions for the built-in types. Reading or writing the vertex array is a high overhead operation and should not be done every frame. The index array describes an indexed triangle list. Each triangle has three consecutive indices in the array designating the vertices from the vertex array that represent that triangle. The index array may either be 16-bit or 32-bit. Attribute Name SXRMesh Setter SXRMesh Getter a_position setVertices(float[]) float[] getVertices() a_normal setNormals(float[]) float[] getNormals() a_texcoord setTexCoords(float[]) float[] getTexCoords() SXRMesh Setter SXRMesh Getter setFloatArray(String name, float[]) float[] getFloatArray(String name) setFloatVec(String name, FloatBuffer) getFloatVec(String name, FloatBuffer) setIntArray(String name, int[]) int[] getIntArray(String name) setIntVec(String name, IntBuffer) getIntVec(String name, IntBuffer) setIndices(int[]) int[] getIndices() setTriangles(char[]) char[] getTriangles()","title":"Accessing Mesh Components"},{"location":"programming_guide/features/meshes/#mesh-construction-example","text":"Most of the time your code will obtain meshes by loading asset files. You can also construct or modify meshes programmatically. A mesh may contain positions, normal and texture coordinates. Depending on the shader used to display the mesh, some of these vertex components may not be used. For example, a shader which does not do lighting will typically not need normals. You can omit the normals and texture coordinate arrays if your shader doesn't need them. This function constructs a mesh of two triangles with only positions and normals. (If you try to use a textured shader with this mesh, you will get an error.) SXRMesh createMesh ( SXRContext sxrContext ) { SXRMesh mesh = new SXRMesh ( sxrContext ); float [] vertices = { - 1.0f , 0.0f , 0.0f , 0.0f , 1.0f , 0.0f , 1.0f , 0.0f , 0.0f , 0.0f , - 1.0f , 0.0f }; float [] normals = { 0 , 0 , 1 , 0 , 0 , 1 , 0 , 0 , 1 , 0 , 0 , 1 }; char [] triangles = { 0 , 1 , 2 , 2 , 3 , 0 }; mesh . setVertices ( vertices ); mesh . setNormals ( normals ); mesh . setTriangles ( triangles ); return mesh ; } You need to attach your mesh to a SXRNode before it can be displayed. The SXRRenderData object holds both a mesh and a material. Each visible scene object must have render data. This code adds the newly constructed mesh to the scene. Here we assume the SXRMaterial has already been constructed. SXRMesh mesh = createMesh ( sxrContext ); SXRNode obj = new SXRNode ( sxrContext , mesh ); SXRRenderData rdata = obj . getRenderData (); rdata . setMaterial ( material );","title":"Mesh Construction Example"},{"location":"programming_guide/features/meshes/#vertex-and-index-buffers","text":"The vertices and indices of the mesh are actually kept as separate SXR objects and they can be shared across meshes. SXRVertexBuffer contains a set of vertices that can be used by a mesh. SXRIndexBuffer contains a set of face indices. The layout of the vertices in the vertex buffer is established at construction time and cannot be changed. The vertex descriptor string describes the name and type of each vertex component. The supported types are float, float2, float3, float4, int, int2, int3 and int4 . The default vertex descriptor if none is specified is \"float3 a_position float2 a_texcoord float3 a_normal\" which will work with all of the built-in shaders. The size of the indices in the index buffer is also fixed at construction time. Indices may be either 2 bytes or 4 bytes. In this example, we create two scene objects representing different faces of a cube which share the same vertex array. float [] pos = new float [] { 1 , 1 , 1 , 1 , - 1 , 1 , - 1 , 1 , 1 , - 1 , - 1 , 1 , 1 , 1 , - 1 , 1 , - 1 , - 1 , - 1 , 1 , - 1 , - 1 , - 1 , - 1 ,}; float [] uv = new float [] { 0 , 0 , 0 , 1 , 0 , 1 , 1 , 0 , 0 , 0 , 0 , 1 , 0 , 1 , 1 , 0 }; SXRVertexBuffer cubeVerts = new SXRVertexBuffer ( context , float3 a_position float2 a_texcoord ); SXRIndexBuffer face1Tris = new SXRIndexBuffer ( context , 2 , 6 ); SXRIndexBuffer face2Tris = new SXRIndexBuffer ( context , 2 , 6 ); SXRMesh mesh1 = new SXRMesh ( cubeVerts , face1Tris ); SXRMesh mesh2 = new SXRMesh ( cubeVerts , face2Tris ); cubeVerts . setFloatArray ( a_position , pos ); cubeVerts . setFloatArray ( a_texcoord , uv ); face1Tris . setShortVec ( new char [] { 0 , 1 , 2 , 2 , 1 , 3 }); face2Tris . setShortVec ( new char [] { 4 , 5 , 6 , 6 , 5 , 7 }); SXRNode object1 = new SXRNode ( context , mesh1 ); SXRNode object2 = new SXRNode ( context , mesh2 );","title":"Vertex and Index Buffers"},{"location":"programming_guide/features/phong_shader_template/","text":"Phong shader tempates, vertex and fragment shaders, and examples The phong reflectance model is used to calculate how objects reflect light. This model assumes that reflected light is most intense at an angle perpendicular to the light source and falls off in a lobe based on angle from the viewer. The base surface material is assumed to reflect evenly but texture maps can be used to modify the normal per pixel to provide bumps or control reflection per pixel. Instead of implementing an extremely complex single shader to handle all of the many combinations of texture maps, lighting and materials, SXR supports the concept of shader templates. A shader template is a complex shader with a lot of #ifdef statements which allow it to be compiled in different ways depending on what features are required to render an object. SXR will examine your meshes, materials and lights and set the #ifdefs to generate a custom shader for each case. The asset loader uses the phong shader template for all imported assets. This means that, if you import an asset containing new lights, other objects in your scene may be affected and will use different custom shaders that support the newly added lights. Similarly, importing an object that uses lightmapping if it has not been used before in the scene might cause a new shader to be generated. To use the phong shader template programmatically, call SXRRenderData.setShaderTemplate(SXRPhongShader.class). This tells SXR to defer selecting a specific shader until the scene has been composed. After SXRActivity.onInit completes, the shader templates are used to generate and compile the needed shaders. If you import assets while the application is running, the asset loader will take care of binding the shaders. But if you program creatively and add objects to the scene in other ways, you may have to call SXRScene.bindShaders to make sure the proper shaders are generated. The phong model separates light into several different types and allows different colors for each. The components are combined with corresponding material uniforms to independently control illumination for each type. Ambient light reflects uniformly everywhere in the scene and is added to all objects Diffuse light reflects at many angles and is stronger in the direction of the surface normal Specular light reflects towards the viewer Each light type has a corresponding color uniform to define the overall object color and a texture sampler to provide a color at each pixel. Phong Shader Example SXRTexture tex = context . getAssetLoader (). loadTexture ( new SXRAndroidResource ( mSXRContext , R . drawable . sxrlogo )); SXRMaterial material = new SXRMaterial ( context , SXRMaterial . SXRShaderType . Phong . ID ); SXRNode plane = new SXRNode ( context , 10.0f , 4.0f , float3 a_position float2 a_texcoord float3 a_normal , material ); material . setVec4 ( diffuse_color , 0.8f , 0.8f , 0.8f , 1.0f ); material . setVec4 ( ambient_color , 0.3f , 0.3f , 0.3f , 1.0f ); material . setVec4 ( specular_color , 1.0f , 1.0f , 1.0f , 1.0f ); material . setVec4 ( emissive_color , 0.0f , 0.0f , 0.0f , 0.0f ); material . setFloat ( specular_exponent , 10.0f ); material . setTexture ( diffuseTexture , tex ); Vertex Shader The phong vertex shader supports lighting with multiple light sources, normal mapping and skinning with up to 60 bones. Lighting calculations are done per pixel. Phong Shader Vertex Attributes Attribute Type Description a_position vec3 X, Y, Z position in model space a_normal vec3 normal vector in model space a_texcoord vec2 first U, V texture coordinate set a_texcoord1 vec2 second U, V texture coordinate set a_texcoord2 vec2 third U, V texture coordinate set a_texcoord3 vec2 fourth U, V texture coordinate set a_tangent vec3 tangent for normal mapping a_bitangent vec3 bitangent for normal mapping a_bone_weights vec4 weights for 4 bones for skinning a_bone_indices ivec4 bone matrix indices for 4 bones The vertex shader uses one or more matrices calculated each frame by SXR. These matrices are supplied to all shaders so they are available for you to use in your own vertex and fragment shader code. Phong Shader Matrix Uniforms Uniform Type Description u_model mat4 model matrix (model - world) u_view mat4 view matrix (world - camera) u_mvp mat4 model, view, projection (model - screen) u_mv mat4 model, view (model - camera) u_mv_it mat4 inverse transpose of model, view (for lighting) Fragment Shader The fragment shader performs the lighting calculations at each pixel. Shadow mapping is supported for multiple light sources but should be used sparingly because it is computationally expensive. It renders the scene from the viewpoint of each light that casts shadows. Many different types of texture maps are supporting by the phong fragment shader template but usually a scene object only uses one or two. Each texture map contributes differently to the overall color and reacts differently to the lighting in the scene. Phong Texture Maps Sampler Description diffuseTexture Supplies diffuse color per pixel ambientTexture Supplies ambient color per pixel opacityTexture Supplies alpha per pixel specularTexture Supplies specular color per pixel emissiveTexture Supplies emissive color per pixel normalTexture Supplies normal per pixel lightmapTexture Supplies lighting per pixel Materials used with the phong shader template support these uniforms. Each different type of light has its own set of uniforms used to define the light properties. Phong Material Uniforms Uniform Type Description diffuse_color vec4 color reflected by diffuse light, alpha component has overall opacity ambient_color vec4 color reflected by ambient light specular_color vec4 color reflected by specular light (towards viewer) emissive_color vec4 light color emitted by object specular_exponent float specular exponent (shininess) u_lightmap_offset vec2 texture coordinate offset for lightmap texture u_lightmap_scale vec2 texture coordinate scale for lightmap texture","title":"Phong Shader Template"},{"location":"programming_guide/features/phong_shader_template/#phong-shader-tempates-vertex-and-fragment-shaders-and-examples","text":"The phong reflectance model is used to calculate how objects reflect light. This model assumes that reflected light is most intense at an angle perpendicular to the light source and falls off in a lobe based on angle from the viewer. The base surface material is assumed to reflect evenly but texture maps can be used to modify the normal per pixel to provide bumps or control reflection per pixel. Instead of implementing an extremely complex single shader to handle all of the many combinations of texture maps, lighting and materials, SXR supports the concept of shader templates. A shader template is a complex shader with a lot of #ifdef statements which allow it to be compiled in different ways depending on what features are required to render an object. SXR will examine your meshes, materials and lights and set the #ifdefs to generate a custom shader for each case. The asset loader uses the phong shader template for all imported assets. This means that, if you import an asset containing new lights, other objects in your scene may be affected and will use different custom shaders that support the newly added lights. Similarly, importing an object that uses lightmapping if it has not been used before in the scene might cause a new shader to be generated. To use the phong shader template programmatically, call SXRRenderData.setShaderTemplate(SXRPhongShader.class). This tells SXR to defer selecting a specific shader until the scene has been composed. After SXRActivity.onInit completes, the shader templates are used to generate and compile the needed shaders. If you import assets while the application is running, the asset loader will take care of binding the shaders. But if you program creatively and add objects to the scene in other ways, you may have to call SXRScene.bindShaders to make sure the proper shaders are generated. The phong model separates light into several different types and allows different colors for each. The components are combined with corresponding material uniforms to independently control illumination for each type. Ambient light reflects uniformly everywhere in the scene and is added to all objects Diffuse light reflects at many angles and is stronger in the direction of the surface normal Specular light reflects towards the viewer Each light type has a corresponding color uniform to define the overall object color and a texture sampler to provide a color at each pixel.","title":"Phong shader tempates, vertex and fragment shaders, and examples"},{"location":"programming_guide/features/phong_shader_template/#phong-shader-example","text":"SXRTexture tex = context . getAssetLoader (). loadTexture ( new SXRAndroidResource ( mSXRContext , R . drawable . sxrlogo )); SXRMaterial material = new SXRMaterial ( context , SXRMaterial . SXRShaderType . Phong . ID ); SXRNode plane = new SXRNode ( context , 10.0f , 4.0f , float3 a_position float2 a_texcoord float3 a_normal , material ); material . setVec4 ( diffuse_color , 0.8f , 0.8f , 0.8f , 1.0f ); material . setVec4 ( ambient_color , 0.3f , 0.3f , 0.3f , 1.0f ); material . setVec4 ( specular_color , 1.0f , 1.0f , 1.0f , 1.0f ); material . setVec4 ( emissive_color , 0.0f , 0.0f , 0.0f , 0.0f ); material . setFloat ( specular_exponent , 10.0f ); material . setTexture ( diffuseTexture , tex );","title":"Phong Shader Example"},{"location":"programming_guide/features/phong_shader_template/#vertex-shader","text":"The phong vertex shader supports lighting with multiple light sources, normal mapping and skinning with up to 60 bones. Lighting calculations are done per pixel. Phong Shader Vertex Attributes Attribute Type Description a_position vec3 X, Y, Z position in model space a_normal vec3 normal vector in model space a_texcoord vec2 first U, V texture coordinate set a_texcoord1 vec2 second U, V texture coordinate set a_texcoord2 vec2 third U, V texture coordinate set a_texcoord3 vec2 fourth U, V texture coordinate set a_tangent vec3 tangent for normal mapping a_bitangent vec3 bitangent for normal mapping a_bone_weights vec4 weights for 4 bones for skinning a_bone_indices ivec4 bone matrix indices for 4 bones The vertex shader uses one or more matrices calculated each frame by SXR. These matrices are supplied to all shaders so they are available for you to use in your own vertex and fragment shader code. Phong Shader Matrix Uniforms Uniform Type Description u_model mat4 model matrix (model - world) u_view mat4 view matrix (world - camera) u_mvp mat4 model, view, projection (model - screen) u_mv mat4 model, view (model - camera) u_mv_it mat4 inverse transpose of model, view (for lighting)","title":"Vertex Shader"},{"location":"programming_guide/features/phong_shader_template/#fragment-shader","text":"The fragment shader performs the lighting calculations at each pixel. Shadow mapping is supported for multiple light sources but should be used sparingly because it is computationally expensive. It renders the scene from the viewpoint of each light that casts shadows. Many different types of texture maps are supporting by the phong fragment shader template but usually a scene object only uses one or two. Each texture map contributes differently to the overall color and reacts differently to the lighting in the scene. Phong Texture Maps Sampler Description diffuseTexture Supplies diffuse color per pixel ambientTexture Supplies ambient color per pixel opacityTexture Supplies alpha per pixel specularTexture Supplies specular color per pixel emissiveTexture Supplies emissive color per pixel normalTexture Supplies normal per pixel lightmapTexture Supplies lighting per pixel Materials used with the phong shader template support these uniforms. Each different type of light has its own set of uniforms used to define the light properties. Phong Material Uniforms Uniform Type Description diffuse_color vec4 color reflected by diffuse light, alpha component has overall opacity ambient_color vec4 color reflected by ambient light specular_color vec4 color reflected by specular light (towards viewer) emissive_color vec4 light color emitted by object specular_exponent float specular exponent (shininess) u_lightmap_offset vec2 texture coordinate offset for lightmap texture u_lightmap_scale vec2 texture coordinate scale for lightmap texture","title":"Fragment Shader"},{"location":"programming_guide/features/picking/","text":"3D object picking, colliders, and examples For a scene object to be pickable, it must have a collider component attached. The collider typically references collision geometry that is simpler than the scene object's mesh. For example, the collider might be a sphere or an axially aligned bounding box. To pick a 3D object SXR casts a ray from the camera viewpoint in the direction the viewer is looking through the entire scene looking only at the geometry in the colliders. When the ray penetrates the collider geometry, the scene object that owns it is \"picked\". The list of picked objects is sorted based on distance from the camera so it is easy to choose the closest object to the viewer. Types of Colliders SXR provides several types of colliders to use depending on how accurate you want picking to be. SXRSphereCollider is the fastest collision to compute but is the least accurate because it approximates the shape of the scene object as spherical. For meshes that are larger in one dimension than another, the picker might register false positives. SXRBoxCollider approximates the scene object shape as a rectangular box. It is slightly less efficient than the sphere collider but may bound the mesh more tightly. SXRMeshCollider can be used in several ways. You can direct it to use the mesh of the scene object that owns it or you can provide your own collision mesh. You can also request the mesh collider to use the bounding box of the scene object's mesh. This is usually a lot faster and sufficient for a lot of picking needs. It accommodates irregularly shaped objects better than the sphere collider. Picking The picking operation is performed by the SXRPicker class. The picker can operate in two modes. You can call the SXRPicker.pickObjects function directly to get back the list of objects that were picked and information about the collision. You can also attach the picker to a scene object and it will automatically cast a ray from that scene object and generate events indicating what was picked. Procedural Picking To use the picker procedurally you must provide the origin and direction of the pick ray in world coordinates and the SXRScene you want to pick against. The picker returns an array of SXRPickedObject instances that indicate what was picked and where it was hit. The hit position returned will be in the coordinate system of the collider geometry - not in world coordinates. To transform it to world coordinates you must multiply it by the model matrix of the scene object hit. This is not the most efficient method of picking and should only be called once per frame. For mesh colliders, you can enable coordinate picking in the constructor and the picker will provide additional information with the barycentric coordinates, texture coordinates and normal at the hit location. Field Type Description hitObject SXRNode the scene object that was hit hitCollider SXRCollider the collider that was hit hitPosition float[3] X, Y, Z coordinates of where collider was hit hitDistance float distance from camera in world coordinates faceIndex* int index of face hit barycentricCoordinates* float[3] barycentric coordinates of the hit location on the collided face textureCoordinates* float[2] U,V coordinates of the hit location on the mesh normalCoordinates* float[3] normalized surface normal at the hit location Picking Events The most convenient way to use the picker is to attach it to a scene object, typically the owner of the current camera, and respond to the pick events generated when objects are hit. Events are raised each time the picking ray enters or exits an object. You can also observe changes to the list of picked objects as a whole. To handle pick events in your application you provide a class which implements the IPickEvents interface. If you want to handle all pick events from all objects, attach it as a listener to the event receiver for the scene or the picker. (By default, the picker routes all pick events through the scene and to its own listeners.) If you attach the IPickEvents interface to a scene object, only the pick events which affect that scene object are sent. Picking Example This example shows how to use picking events to do selection highlighting. When the pick ray enters an object, its material color is changed to red. When the pick ray exists, the color is changed back to white again. public class PickHandler implements IPickEvents { public void onEnter ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { sceneObj . getRenderData (). getMaterial (). setDiffuseColor ( 1 , 0 , 0 , 1 ); } public void onExit ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { sceneObj . getRenderData (). getMaterial (). setDiffuseColor ( 1 , 1 , 1 , 1 ); } public void onInside ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { } public void onPick ( SXRPicker ) { } public void onNoPick ( SXRPicker ) { } } public void onInit ( SXRContext context ) { SXRScene scene = context . getMainScene (); SXRNode sphere = new SXRSphereNode ( context ); SXRPicker picker = new SXRPicker ( scene , true ); picker . getEventReceiver (). addListener ( new PickHandler ()); scene . getMainCameraRig (). getOwnerObject (). attachComponent ( picker )); sphere . getTransform (). setPositionZ (- 2.0f ); sphere . attachComponent ( new SXRSphereCollider ( context )); scene . addNode ( sphere ); } Touch Events and the Controller The picker can be used with a controller to generate touch events. This lets your application know what is selected by the controller and whether or not the action button is pressed. Every SXRCursorController instance has its own SXRPicker. Your sxr.xml settings file should indicate which controller types your application supports in the \"useControllerType\" setting. SXRInputManager.selectController will select the available controller preferred by your application. To handle touch events in your application you provide a class which implements the ITouchEvents interface and attach it as a listener to the controller. To do this, your application must handle controller selection events with a class that implements ICursorControllerSelected ang register this listener with the input manager. When a controller is selected for your application, the onCursorControllerSelected function is called and you can attach touch event listeners to the controller. Controller Touch Example This example shows how to use touch events to drag an object with the controller. When the user presses the controller button while the pick ray is inside an object, that object is dragged by the controller. public class TouchHandler implements SXREventListeners . TouchEvents { private SXRNode mDragged = null ; public void onTouchStart ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { if ( mDragged == null ) { SXRPicker picker = pickInfo . picker ; SXRController controller = picker . getController (); if ( controller . startDrag ( sceneObj )) { mDragged = sceneObj ; } } } public void onTouchEnd ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { if ( mDragged == sceneObj ) { SXRPicker picker = pickInfo . picker ; SXRController controller = picker . getController (); controller . stopDrag ( sceneObj ); mDragged = null ; } } } public class ControllerSelector implements ICursorControllerSelectListener { public void onCursorControllerSelected ( SXRCursorController newController , SXRCursorController oldController ) { newController . addPickEventListener ( new TouchHandler ()); } }; public void onInit ( SXRContext context ) { SXRScene scene = context . getMainScene (); SXRNode sphere = new SXRSphereNode ( context ); sphere . getTransform (). setPositionZ (- 2.0f ); sphere . attachComponent ( new SXRSphereCollider ( context )); scene . addNode ( sphere ); context . getInputManager (). selectController ( new ControllerSelector ()); }","title":"Picking"},{"location":"programming_guide/features/picking/#3d-object-picking-colliders-and-examples","text":"For a scene object to be pickable, it must have a collider component attached. The collider typically references collision geometry that is simpler than the scene object's mesh. For example, the collider might be a sphere or an axially aligned bounding box. To pick a 3D object SXR casts a ray from the camera viewpoint in the direction the viewer is looking through the entire scene looking only at the geometry in the colliders. When the ray penetrates the collider geometry, the scene object that owns it is \"picked\". The list of picked objects is sorted based on distance from the camera so it is easy to choose the closest object to the viewer.","title":"3D object picking, colliders, and examples"},{"location":"programming_guide/features/picking/#types-of-colliders","text":"SXR provides several types of colliders to use depending on how accurate you want picking to be. SXRSphereCollider is the fastest collision to compute but is the least accurate because it approximates the shape of the scene object as spherical. For meshes that are larger in one dimension than another, the picker might register false positives. SXRBoxCollider approximates the scene object shape as a rectangular box. It is slightly less efficient than the sphere collider but may bound the mesh more tightly. SXRMeshCollider can be used in several ways. You can direct it to use the mesh of the scene object that owns it or you can provide your own collision mesh. You can also request the mesh collider to use the bounding box of the scene object's mesh. This is usually a lot faster and sufficient for a lot of picking needs. It accommodates irregularly shaped objects better than the sphere collider.","title":"Types of Colliders"},{"location":"programming_guide/features/picking/#picking","text":"The picking operation is performed by the SXRPicker class. The picker can operate in two modes. You can call the SXRPicker.pickObjects function directly to get back the list of objects that were picked and information about the collision. You can also attach the picker to a scene object and it will automatically cast a ray from that scene object and generate events indicating what was picked.","title":"Picking"},{"location":"programming_guide/features/picking/#procedural-picking","text":"To use the picker procedurally you must provide the origin and direction of the pick ray in world coordinates and the SXRScene you want to pick against. The picker returns an array of SXRPickedObject instances that indicate what was picked and where it was hit. The hit position returned will be in the coordinate system of the collider geometry - not in world coordinates. To transform it to world coordinates you must multiply it by the model matrix of the scene object hit. This is not the most efficient method of picking and should only be called once per frame. For mesh colliders, you can enable coordinate picking in the constructor and the picker will provide additional information with the barycentric coordinates, texture coordinates and normal at the hit location. Field Type Description hitObject SXRNode the scene object that was hit hitCollider SXRCollider the collider that was hit hitPosition float[3] X, Y, Z coordinates of where collider was hit hitDistance float distance from camera in world coordinates faceIndex* int index of face hit barycentricCoordinates* float[3] barycentric coordinates of the hit location on the collided face textureCoordinates* float[2] U,V coordinates of the hit location on the mesh normalCoordinates* float[3] normalized surface normal at the hit location","title":"Procedural Picking"},{"location":"programming_guide/features/picking/#picking-events","text":"The most convenient way to use the picker is to attach it to a scene object, typically the owner of the current camera, and respond to the pick events generated when objects are hit. Events are raised each time the picking ray enters or exits an object. You can also observe changes to the list of picked objects as a whole. To handle pick events in your application you provide a class which implements the IPickEvents interface. If you want to handle all pick events from all objects, attach it as a listener to the event receiver for the scene or the picker. (By default, the picker routes all pick events through the scene and to its own listeners.) If you attach the IPickEvents interface to a scene object, only the pick events which affect that scene object are sent.","title":"Picking Events"},{"location":"programming_guide/features/picking/#picking-example","text":"This example shows how to use picking events to do selection highlighting. When the pick ray enters an object, its material color is changed to red. When the pick ray exists, the color is changed back to white again. public class PickHandler implements IPickEvents { public void onEnter ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { sceneObj . getRenderData (). getMaterial (). setDiffuseColor ( 1 , 0 , 0 , 1 ); } public void onExit ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { sceneObj . getRenderData (). getMaterial (). setDiffuseColor ( 1 , 1 , 1 , 1 ); } public void onInside ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { } public void onPick ( SXRPicker ) { } public void onNoPick ( SXRPicker ) { } } public void onInit ( SXRContext context ) { SXRScene scene = context . getMainScene (); SXRNode sphere = new SXRSphereNode ( context ); SXRPicker picker = new SXRPicker ( scene , true ); picker . getEventReceiver (). addListener ( new PickHandler ()); scene . getMainCameraRig (). getOwnerObject (). attachComponent ( picker )); sphere . getTransform (). setPositionZ (- 2.0f ); sphere . attachComponent ( new SXRSphereCollider ( context )); scene . addNode ( sphere ); }","title":"Picking Example"},{"location":"programming_guide/features/picking/#touch-events-and-the-controller","text":"The picker can be used with a controller to generate touch events. This lets your application know what is selected by the controller and whether or not the action button is pressed. Every SXRCursorController instance has its own SXRPicker. Your sxr.xml settings file should indicate which controller types your application supports in the \"useControllerType\" setting. SXRInputManager.selectController will select the available controller preferred by your application. To handle touch events in your application you provide a class which implements the ITouchEvents interface and attach it as a listener to the controller. To do this, your application must handle controller selection events with a class that implements ICursorControllerSelected ang register this listener with the input manager. When a controller is selected for your application, the onCursorControllerSelected function is called and you can attach touch event listeners to the controller.","title":"Touch Events and the Controller"},{"location":"programming_guide/features/picking/#controller-touch-example","text":"This example shows how to use touch events to drag an object with the controller. When the user presses the controller button while the pick ray is inside an object, that object is dragged by the controller. public class TouchHandler implements SXREventListeners . TouchEvents { private SXRNode mDragged = null ; public void onTouchStart ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { if ( mDragged == null ) { SXRPicker picker = pickInfo . picker ; SXRController controller = picker . getController (); if ( controller . startDrag ( sceneObj )) { mDragged = sceneObj ; } } } public void onTouchEnd ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { if ( mDragged == sceneObj ) { SXRPicker picker = pickInfo . picker ; SXRController controller = picker . getController (); controller . stopDrag ( sceneObj ); mDragged = null ; } } } public class ControllerSelector implements ICursorControllerSelectListener { public void onCursorControllerSelected ( SXRCursorController newController , SXRCursorController oldController ) { newController . addPickEventListener ( new TouchHandler ()); } }; public void onInit ( SXRContext context ) { SXRScene scene = context . getMainScene (); SXRNode sphere = new SXRSphereNode ( context ); sphere . getTransform (). setPositionZ (- 2.0f ); sphere . attachComponent ( new SXRSphereCollider ( context )); scene . addNode ( sphere ); context . getInputManager (). selectController ( new ControllerSelector ()); }","title":"Controller Touch Example"},{"location":"programming_guide/features/render_data/","text":"The render data component is what makes a scene object visible. It provides both geometry and appearance properties. The geometry is a single SXRMesh object which contains a set of indexed vertices. The appearance is a SXRMaterial object which contains a set of key/value pairs defining the variables to be sent to the shader. The shader is a program that executes on the GPU. During rendering, SXR manages data flow between your application and the GPU, sending the meshes and materials to the GPU as they are needed. This may require SXR to compile and load a shader into the GPU while your application is running. This may happen when you add something to the scene using SXRScene.addNode. The render data component also controls how your mesh is rendered. You can enable or disable lighting, display an object only on one eye and control the order of rendering using its functions. SXRRenderData Function Description enableLighting Enable light sources in the shader disableLighting Disable light sources in the shader setAlphaBlend Enable / disable alpha blending setAlphaToCoverage Enable / disable alpha to coverage setAlphaBlendFunc Set alpha blend functions setCullTest Enable / disable backface culling setCullFace Designate back or front faces for culling setDepthTest Enable / disable depth testing (Z buffer) setDepthMask Enable / disable depth mask setDrawMode Designate triangles, lines or points setRenderMask Designate rendering left, right or both eyes setRenderingOrder Establish rendering order setSampleCoverage Specifies coverage of modification mask setInvertCoverageMask Designates whether modification mask is inverted setOffset Enables /disables polygon fill offset setOffsetFactor Specifies polygon fill offset factor setOffsetUnits Specifies polygon fill offset units setCastShadows Enable / disable shadow casting setMesh Designate the mesh to render setMaterial Specify material properties for shader Render Passes A render pass lets you render the same scene object multiple times with different settings. This is useful to achieve effects like cartoon rendering or adding glow around an object. The benefit of using a render pass as opposed to duplicating the object is that culling, transformation and skinning are only performed once. A render pass encapsulates the material and rendering properties (but not the mesh). This example shows how to implement a multi-sided material using render passes. It uses a red material for the front faces and a blue material for the back faces. SXRNode cube = new SXRCubeNode ( sxrContext ); SXRRenderData rdata = cube . getRenderData (); SXRMaterial red = rdata . getMaterial (); SXRMaterial blue = new SXRMaterial ( sxrContext ); SXRRenderPass pass = new SXRRenderPass ( sxrContext ); red . setDiffuseColor ( 1 , 0 , 0 , 1 ); blue . setDiffuseColor ( 0 , 0 , 1 , 0 ); rdata . setCullFace ( SXRCullFaceEnum . Front ); pass . setMaterial ( blue ); pass . setCullFace ( SXRCullFaceEnum . Back ); rdata . addPass ( pass );","title":"Render Data"},{"location":"programming_guide/features/render_data/#render-passes","text":"A render pass lets you render the same scene object multiple times with different settings. This is useful to achieve effects like cartoon rendering or adding glow around an object. The benefit of using a render pass as opposed to duplicating the object is that culling, transformation and skinning are only performed once. A render pass encapsulates the material and rendering properties (but not the mesh). This example shows how to implement a multi-sided material using render passes. It uses a red material for the front faces and a blue material for the back faces. SXRNode cube = new SXRCubeNode ( sxrContext ); SXRRenderData rdata = cube . getRenderData (); SXRMaterial red = rdata . getMaterial (); SXRMaterial blue = new SXRMaterial ( sxrContext ); SXRRenderPass pass = new SXRRenderPass ( sxrContext ); red . setDiffuseColor ( 1 , 0 , 0 , 1 ); blue . setDiffuseColor ( 0 , 0 , 1 , 0 ); rdata . setCullFace ( SXRCullFaceEnum . Front ); pass . setMaterial ( blue ); pass . setCullFace ( SXRCullFaceEnum . Back ); rdata . addPass ( pass );","title":"Render Passes"},{"location":"programming_guide/features/rendering/","text":"Opaque scene objects are drawn front-to-back, in render order. Transparent objects are drawn back-to-front. The renderer will automatically sort scene object data. The asset loader sets the rendering order based on the characteristics of the asset being imported. SXR detects transparent textures and will automatically change objects marked as GEOMETRY to TRANSPARENT if a transparent texture is used. Transparent objects typically use alpha blending of some type. To enable transparency, you must call SXRRenderData.setAlphaBlend as well as setting the rendering order. Similarly, to use the stencil buffer you usually need to call SXRRenderData.setStencilOp and SXRRenderData.setStencilFunc . SXRRenderingOrder Value Render Order Used For SXRRenderingOrder.STENCIL Stencil rendered to stencil buffer SXRRenderingOrder.BACKGROUND First skybox, background SXRRenderingOrder.GEOMETRY Second opaque objects SXRRenderingOrder.TRANSPARENT Third transparent objects SXRRenderingOrder.OVERLAY Last GUI and HUD overlays, cursors After your startup code has built a scene graph, SXR enters its event loop. On each frame, SXR starts its render pipeline, which consists of four main steps. The first three steps run your Java callbacks on the GL thread. The final step is managed by SXR. SXR executes any Runnable you added to the run-once queue. Queue operations are thread-safe. You can use the SXRContext.runOnGlThread() method from the GUI or background threads in the same way you use Activity.runOnUiThread() from non-GUI threads. The analogy is not exact: runOnGlThread() always enqueues its Runnable, even when called from the GL thread. SXR executes each frame listener you added to the on-frame list. SXR includes animation and periodic engines that use frame listeners to run time-based code on the GL thread, but you may add frame listeners directly. A frame listener is like a Runnable that gets a parameter telling you how long it has been since the last frame. An animation runs every frame until it stops, and morphs a scene object from one state to another. A periodic callback runs a standard Runnable at a specified time (or times) as a runOnGlThread() callback. You can run a sequence of animations either by starting each new animation in the previous animation's optional on-finish callback or by starting each new animation at set times from a periodic callback. SXR runs your onStep() callback, which is the place to process Android or cloud events and make changes to your scene graph. As a rule of thumb, an animation changes a single scene object's properties; onStep() changes the scene graph itself. Of course, you can use onStep() to start an animation that will make a smooth change. SXR renders the scene graph twice, once for each eye. Rendering determines what a camera can see and draws each visible triangle to a buffer in GPU memory. Any post-effects you have registered for an eye are applied the buffer for step 4.a in registration order. (Typically, you will use per-eye registration to run the same effect with different per-eye parameters, but you can run different effects on each eye, perhaps adding different debugging info to each eye.). A post-effect is a shader that is a lot like the shaders that draw scene objects' skins; the big difference is that while a material shader's vertex shader may be quite complex (adding in lighting and reflections), a post-effect is a 2D effect, and all the action is in the fragment shader, which draws each pixel. SXR includes pre-defined post-effect shaders, and it is easy to add your own. One last shader applies barrel distortion to the render buffer, and draws the barrel distortion to the screen. When the user views the screen though a fish-eye lens, the undistorted image will (nearly) fill the field of view. This step is not programmable, except in so far as you provide an XML file with screen size information at start-up time.","title":"Rendering"},{"location":"programming_guide/features/scene_graph/","text":"Setting Up Cameras SXR will create the camera rig by default. Its parameters do not need to be adjusted; however, applications may move the camera rig. The HMD sensor automatically adjusts camera orientation; your app does not need code for this. Camera background color can be set for each eye; however, they are typically the same. Camera background color and post-effect data can be set by the application. Post-effects are applied to each camera. To set the background of the cameras and the position of the camera rig: // set camera background color SXRCameraRig cameraRig = mSXRContext . getMainScene (). getMainCameraRig (); cameraRig . getLeftCamera (). setBackgroundColor ( 0.0f , 0.0f , 0.0f , 1.0f ); cameraRig . getRightCamera (). setBackgroundColor ( 0.0f , 0.0f , 0.0f , 1.0f ); // set up camerarig position (default) cameraRig . getHeadTransform (). setPosition ( 0.0f , 0.0f , 0.0f ); Scene Graph The scene graph - the VR world - is a hierarchical tree of scene objects. Each scene object is a tree node with one parent and one or more child scene objects. Applications must build a scene graph. Your app needs to set up cameraRig for the root scene object of the scene graph, but does not need to set up cameraRig for each lower-level scene object. To create a scene graph at initialization time, get the SXR main scene (the root scene object) from SXRContext. To create the scene graph by getting its root scene object: SXRScene scene = mSXRContext . getMainScene (); Creating the Scene Objects Populate your VR world's scene graph scene object tree by adding scene objects to the root scene object and to other lower-level scene objects. The most common way is to load models using the SXR wrapped Assimp library.Assimp can load many 3D file formats and construct SXR scene object hierarchies from them. The materials, textures and shaders are automatically attached to the appropriate scene object and the model is added to the scene. The asset loader uses the SXRPhongShader class as the shader template for all imported objects. To create a scene object from from a file: // load mesh using assimp SXRNode model = sxrContext . getAssetLoader (). loadModel ( sphere.obj , SXRResourceVolume . VolumeType . ANDROID_ASSETS , sxrScene ); Usually it is more efficient to let the asset loader create the meshes and textures for you. Bu you can also load only a mesh and construct the scene object, material and render data programmatically. To create a scene object with shader-only material via render data: // load mesh object SXRMesh sphereMesh = sxrContext . getAssetLoader (). loadMesh ( sphere.obj ); // get material SXRMaterial sphereMaterial = new SXRMaterial ( sxrContext , mScreenShader . getShaderId ()); // create render data SXRRenderData sphereRenderData = new SXRRenderData ( sxrContext ); // set mesh and material for render data sphereRenderData . setMesh ( sphereMesh ); sphereRenderData . setMaterial ( sphereMaterial ); // create scene object sphereObject = new SXRNode ( sxrContext ); sphereObject . attachRenderData ( sphereRenderData ); Managing Transforms in a Scene Graph After scene objects are added to the scene graph, each scene object can be controlled by transforms. To set the position of a scene object and rotate it about an axis with a pivot point: SXRNode rotator = new SXRNode ( mSXRContext , 2.0f , 1.0f , rotatorTextures . get ( i )); rotator . getTransform (). setPosition ( 0.0f , 0.0f , - 5.0f ); float degree = 360.0f * i / ( rotatorTextures . size () + 1 ); rotator . getTransform (). rotateByAxisWithPivot ( degree , 0.0f , 1.0f , 0.0f , 0.0f , 0.0f , 0.0f );","title":"Scene Graph"},{"location":"programming_guide/features/scene_graph/#setting-up-cameras","text":"SXR will create the camera rig by default. Its parameters do not need to be adjusted; however, applications may move the camera rig. The HMD sensor automatically adjusts camera orientation; your app does not need code for this. Camera background color can be set for each eye; however, they are typically the same. Camera background color and post-effect data can be set by the application. Post-effects are applied to each camera. To set the background of the cameras and the position of the camera rig: // set camera background color SXRCameraRig cameraRig = mSXRContext . getMainScene (). getMainCameraRig (); cameraRig . getLeftCamera (). setBackgroundColor ( 0.0f , 0.0f , 0.0f , 1.0f ); cameraRig . getRightCamera (). setBackgroundColor ( 0.0f , 0.0f , 0.0f , 1.0f ); // set up camerarig position (default) cameraRig . getHeadTransform (). setPosition ( 0.0f , 0.0f , 0.0f );","title":"Setting Up Cameras"},{"location":"programming_guide/features/scene_graph/#scene-graph","text":"The scene graph - the VR world - is a hierarchical tree of scene objects. Each scene object is a tree node with one parent and one or more child scene objects. Applications must build a scene graph. Your app needs to set up cameraRig for the root scene object of the scene graph, but does not need to set up cameraRig for each lower-level scene object. To create a scene graph at initialization time, get the SXR main scene (the root scene object) from SXRContext. To create the scene graph by getting its root scene object: SXRScene scene = mSXRContext . getMainScene ();","title":"Scene Graph"},{"location":"programming_guide/features/scene_graph/#creating-the-scene-objects","text":"Populate your VR world's scene graph scene object tree by adding scene objects to the root scene object and to other lower-level scene objects. The most common way is to load models using the SXR wrapped Assimp library.Assimp can load many 3D file formats and construct SXR scene object hierarchies from them. The materials, textures and shaders are automatically attached to the appropriate scene object and the model is added to the scene. The asset loader uses the SXRPhongShader class as the shader template for all imported objects. To create a scene object from from a file: // load mesh using assimp SXRNode model = sxrContext . getAssetLoader (). loadModel ( sphere.obj , SXRResourceVolume . VolumeType . ANDROID_ASSETS , sxrScene ); Usually it is more efficient to let the asset loader create the meshes and textures for you. Bu you can also load only a mesh and construct the scene object, material and render data programmatically. To create a scene object with shader-only material via render data: // load mesh object SXRMesh sphereMesh = sxrContext . getAssetLoader (). loadMesh ( sphere.obj ); // get material SXRMaterial sphereMaterial = new SXRMaterial ( sxrContext , mScreenShader . getShaderId ()); // create render data SXRRenderData sphereRenderData = new SXRRenderData ( sxrContext ); // set mesh and material for render data sphereRenderData . setMesh ( sphereMesh ); sphereRenderData . setMaterial ( sphereMaterial ); // create scene object sphereObject = new SXRNode ( sxrContext ); sphereObject . attachRenderData ( sphereRenderData );","title":"Creating the Scene Objects"},{"location":"programming_guide/features/scene_graph/#managing-transforms-in-a-scene-graph","text":"After scene objects are added to the scene graph, each scene object can be controlled by transforms. To set the position of a scene object and rotate it about an axis with a pivot point: SXRNode rotator = new SXRNode ( mSXRContext , 2.0f , 1.0f , rotatorTextures . get ( i )); rotator . getTransform (). setPosition ( 0.0f , 0.0f , - 5.0f ); float degree = 360.0f * i / ( rotatorTextures . size () + 1 ); rotator . getTransform (). rotateByAxisWithPivot ( degree , 0.0f , 1.0f , 0.0f , 0.0f , 0.0f , 0.0f );","title":"Managing Transforms in a Scene Graph"},{"location":"tutorials/360_photo_app/","text":"Overview Last time we showed how easy it is to create a simple game scene. This time we're going to create an app for viewing 360 photos. To display a photo in VR you first need to have a 360 photo. Then display the photo inside a sphere. When user looks at the image from inside the sphere, it will create a immersive experience for the them. Create Project Make a copy of template project and copy your oculus signing files to the assets folder Load Image In order to display the image we need to load the image into the memory first. And here is how to do it. download a 360 photo from here place it under \\app\\src\\main\\res\\raw folder load image with the following code SXRTexture texture = sxrContext . getAssetLoader (). loadTexture ( new SXRAndroidResource ( sxrContext , R . raw . photosphere ) ); Note We use loadFutureTexture because we want to load the texture asynchronously. Create Sphere Add the following code to create a sphere and apply the texture we previously loaded SXRSphereNode sphere = new SXRSphereNode ( sxrContext , false , texture ); //Add Sphere to the scene sxrContext . getMainScene (). addNode ( sphere ); Note We specify faceingOut parameter as false, because the player is inside the sphere looking out. You can also specify the stack and slice parameter to make the sphere more smooth.","title":"360 photo app"},{"location":"tutorials/360_photo_app/#overview","text":"Last time we showed how easy it is to create a simple game scene. This time we're going to create an app for viewing 360 photos. To display a photo in VR you first need to have a 360 photo. Then display the photo inside a sphere. When user looks at the image from inside the sphere, it will create a immersive experience for the them.","title":"Overview"},{"location":"tutorials/360_photo_app/#create-project","text":"Make a copy of template project and copy your oculus signing files to the assets folder","title":"Create Project"},{"location":"tutorials/360_photo_app/#load-image","text":"In order to display the image we need to load the image into the memory first. And here is how to do it. download a 360 photo from here place it under \\app\\src\\main\\res\\raw folder load image with the following code SXRTexture texture = sxrContext . getAssetLoader (). loadTexture ( new SXRAndroidResource ( sxrContext , R . raw . photosphere ) ); Note We use loadFutureTexture because we want to load the texture asynchronously.","title":"Load Image"},{"location":"tutorials/360_photo_app/#create-sphere","text":"Add the following code to create a sphere and apply the texture we previously loaded SXRSphereNode sphere = new SXRSphereNode ( sxrContext , false , texture ); //Add Sphere to the scene sxrContext . getMainScene (). addNode ( sphere ); Note We specify faceingOut parameter as false, because the player is inside the sphere looking out. You can also specify the stack and slice parameter to make the sphere more smooth.","title":"Create Sphere"},{"location":"tutorials/play_with_360_video/","text":"Overview Now that you've learned how to use controllers with the SXR SDK. We are going to learn how to play 360 video in VR Create Project Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app. Intro 360 video is the most popular content in VR. However implementing 360 videos is not that straight forward, since currently there are more than 20 different types of VR video types each with different pros and cons. Here we're going to learn how to play the most common type: Monoscopic 360 video Prepare VR video file You can download a monoscopic 360 video here . And copy it to app\\src\\main\\assets folder Note Feel free to use any monoscopic 360 video Create Video Player Create a new class named SXRVideoPlayerObject and replace the default generated code with the following code. This SXRVideoPlayerObject class will create a sphere and apply the video to the sphere as material. package com.example.org.sxrfapplication ; import android.content.res.AssetFileDescriptor ; import android.media.MediaPlayer ; import com.samsungxr.SXRContext ; import com.samsungxr.SXRMesh ; import com.samsungxr.SXRNode ; import com.samsungxr.nodes.SXRSphereNode ; import com.samsungxr.nodes.SXRVideoNode ; import com.samsungxr.nodes.SXRVideoNodePlayer ; import java.io.IOException ; public class SXRVideoPlayerObject extends SXRNode { private final SXRVideoNodePlayer ? mPlayer ; private final MediaPlayer mMediaPlayer ; public SXRVideoPlayerObject ( SXRContext sxrContext ) { super ( sxrContext ); SXRSphereNode sphere = new SXRSphereNode ( sxrContext , 72 , 144 , false ); SXRMesh mesh = sphere . getRenderData (). getMesh (); mMediaPlayer = new MediaPlayer (); mPlayer = SXRVideoNode . makePlayerInstance ( mMediaPlayer ); SXRVideoNode video = new SXRVideoNode ( sxrContext , mesh , mPlayer , SXRVideoNode . SXRVideoType . MONO ); video . getTransform (). setScale ( 100 f , 100 f , 100 f ); addChildObject ( video ); } public void loadVideo ( String fileName ) { final AssetFileDescriptor afd ; try { afd = this . getSXRContext (). getContext (). getAssets (). openFd ( fileName ); mMediaPlayer . setDataSource ( afd . getFileDescriptor (), afd . getStartOffset (), afd . getLength ()); afd . close (); mMediaPlayer . prepare (); } catch ( IOException e ) { e . printStackTrace (); } } public void play () { if ( mMediaPlayer != null ) { mMediaPlayer . start (); } } public void setLooping ( boolean value ) { mMediaPlayer . setLooping ( value ); } public void onPause () { mMediaPlayer . pause (); } public void onResume () { mMediaPlayer . start (); } } Use video player Add the following code to the onInit function of MainScene.java to load and play the video Create mPlayerObject private SXRVideoPlayerObject mPlayerObj = null ; Load and play 360 video mPlayerObj = new SXRVideoPlayerObject ( sxrContext ); mPlayerObj . loadVideo ( videos_s_3.mp4 ); mPlayerObj . setLooping ( true ); mPlayerObj . play (); sxrContext . getMainScene (). addNode ( mPlayerObj ); Add onResume and onPause functions to the MainScene class public void onResume () { if ( mPlayerObj != null ) mPlayerObj . onResume (); } public void onPause () { if ( mPlayerObj != null ) mPlayerObj . onPause (); } Override onResume and onPause functions in the MainActivity @Override protected void onResume () { super . onResume (); main . onResume (); } @Override protected void onPause () { super . onPause (); main . onPause (); } Build and Run Build and run the SXR app, you should be able to watch the 360 video on your device. Source Code Complete Source Code for this sample","title":"Play With 360 Video"},{"location":"tutorials/play_with_360_video/#overview","text":"Now that you've learned how to use controllers with the SXR SDK. We are going to learn how to play 360 video in VR","title":"Overview"},{"location":"tutorials/play_with_360_video/#create-project","text":"Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app.","title":"Create Project"},{"location":"tutorials/play_with_360_video/#intro","text":"360 video is the most popular content in VR. However implementing 360 videos is not that straight forward, since currently there are more than 20 different types of VR video types each with different pros and cons. Here we're going to learn how to play the most common type: Monoscopic 360 video","title":"Intro"},{"location":"tutorials/play_with_360_video/#prepare-vr-video-file","text":"You can download a monoscopic 360 video here . And copy it to app\\src\\main\\assets folder Note Feel free to use any monoscopic 360 video","title":"Prepare VR video file"},{"location":"tutorials/play_with_360_video/#create-video-player","text":"Create a new class named SXRVideoPlayerObject and replace the default generated code with the following code. This SXRVideoPlayerObject class will create a sphere and apply the video to the sphere as material. package com.example.org.sxrfapplication ; import android.content.res.AssetFileDescriptor ; import android.media.MediaPlayer ; import com.samsungxr.SXRContext ; import com.samsungxr.SXRMesh ; import com.samsungxr.SXRNode ; import com.samsungxr.nodes.SXRSphereNode ; import com.samsungxr.nodes.SXRVideoNode ; import com.samsungxr.nodes.SXRVideoNodePlayer ; import java.io.IOException ; public class SXRVideoPlayerObject extends SXRNode { private final SXRVideoNodePlayer ? mPlayer ; private final MediaPlayer mMediaPlayer ; public SXRVideoPlayerObject ( SXRContext sxrContext ) { super ( sxrContext ); SXRSphereNode sphere = new SXRSphereNode ( sxrContext , 72 , 144 , false ); SXRMesh mesh = sphere . getRenderData (). getMesh (); mMediaPlayer = new MediaPlayer (); mPlayer = SXRVideoNode . makePlayerInstance ( mMediaPlayer ); SXRVideoNode video = new SXRVideoNode ( sxrContext , mesh , mPlayer , SXRVideoNode . SXRVideoType . MONO ); video . getTransform (). setScale ( 100 f , 100 f , 100 f ); addChildObject ( video ); } public void loadVideo ( String fileName ) { final AssetFileDescriptor afd ; try { afd = this . getSXRContext (). getContext (). getAssets (). openFd ( fileName ); mMediaPlayer . setDataSource ( afd . getFileDescriptor (), afd . getStartOffset (), afd . getLength ()); afd . close (); mMediaPlayer . prepare (); } catch ( IOException e ) { e . printStackTrace (); } } public void play () { if ( mMediaPlayer != null ) { mMediaPlayer . start (); } } public void setLooping ( boolean value ) { mMediaPlayer . setLooping ( value ); } public void onPause () { mMediaPlayer . pause (); } public void onResume () { mMediaPlayer . start (); } }","title":"Create Video Player"},{"location":"tutorials/play_with_360_video/#use-video-player","text":"Add the following code to the onInit function of MainScene.java to load and play the video Create mPlayerObject private SXRVideoPlayerObject mPlayerObj = null ; Load and play 360 video mPlayerObj = new SXRVideoPlayerObject ( sxrContext ); mPlayerObj . loadVideo ( videos_s_3.mp4 ); mPlayerObj . setLooping ( true ); mPlayerObj . play (); sxrContext . getMainScene (). addNode ( mPlayerObj ); Add onResume and onPause functions to the MainScene class public void onResume () { if ( mPlayerObj != null ) mPlayerObj . onResume (); } public void onPause () { if ( mPlayerObj != null ) mPlayerObj . onPause (); } Override onResume and onPause functions in the MainActivity @Override protected void onResume () { super . onResume (); main . onResume (); } @Override protected void onPause () { super . onPause (); main . onPause (); }","title":"Use video player"},{"location":"tutorials/play_with_360_video/#build-and-run","text":"Build and run the SXR app, you should be able to watch the 360 video on your device.","title":"Build and Run"},{"location":"tutorials/play_with_360_video/#source-code","text":"Complete Source Code for this sample","title":"Source Code"},{"location":"tutorials/play_with_3d_models/","text":"Overview Now that you've learned how to apply the material to the VR app with the SXR SDK, we are going to learn how to play with 3D model. Create Project Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app. Intro Often times when we develop VR applications, we need to show complex 3D models. For example a plane, a castle or even an earth. We're going to learn how to achieve it with the SXR SDK Before we start, we need to have a 3D model file. Here is the 3D T-rex model with texture we're going to use for this tutorial. You can preview them in FBX Review . You can use your own 3D models, just make sure it is one of the following file formats: OBJ FBX Collada(.dae) X3D All formats supported by Assimp How to load 3D models The first step is to place it correctly. Please make sure to copy the files to the following path. Copy trex_mesh.fbx into app/src/main/assets Copy trex_tex_diffuse.png into app/src/main/assets After copying the 3D model files, we can use GVRAssetLoader class to load them, it is accessible from the context by calling GVRContext.getAssetLoader() Using the following code to load the fbx file and texture GVRMesh dinoMesh = gvrContext . getAssetLoader (). loadMesh ( new GVRAndroidResource ( gvrContext , trex_mesh.fbx ) ); GVRTexture dinoTexture = gvrContext . getAssetLoader (). loadTexture ( new GVRAndroidResource ( gvrContext , trex_tex_diffuse.png ) ); Note Loading methods have Future in its API such as loadFutureTexture is deprecated After 3D model and texture both loaded, we can add them to the scene with a scene object GVRNode dinoObj = new GVRNode ( gvrContext , dinoMesh , dinoTexture ); dinoObj . getTransform (). setPosition ( 0 , 0 ,- 10 ); dinoObj . getTransform (). rotateByAxis (- 90 , 1f , 0f , 0f ); gvrContext . getMainScene (). addNode ( dinoObj ); Note We create GVRNode instead of use AssetLoader.loadModel() because loadModel() require fbx files to have correct path to texture file which a lot of 3D modeling software failed to produce. Build and run the app, you should be able to see a T-Rex! Work with 3D modeling tools Fbx is the recommended format for the SXR SDK. Currently, all major 3D modeling tools support exporting to FBX format. Source Code Complete Source Code for this sample","title":"Play With 3D Models"},{"location":"tutorials/play_with_3d_models/#overview","text":"Now that you've learned how to apply the material to the VR app with the SXR SDK, we are going to learn how to play with 3D model.","title":"Overview"},{"location":"tutorials/play_with_3d_models/#create-project","text":"Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app.","title":"Create Project"},{"location":"tutorials/play_with_3d_models/#intro","text":"Often times when we develop VR applications, we need to show complex 3D models. For example a plane, a castle or even an earth. We're going to learn how to achieve it with the SXR SDK Before we start, we need to have a 3D model file. Here is the 3D T-rex model with texture we're going to use for this tutorial. You can preview them in FBX Review . You can use your own 3D models, just make sure it is one of the following file formats: OBJ FBX Collada(.dae) X3D All formats supported by Assimp","title":"Intro"},{"location":"tutorials/play_with_3d_models/#how-to-load-3d-models","text":"The first step is to place it correctly. Please make sure to copy the files to the following path. Copy trex_mesh.fbx into app/src/main/assets Copy trex_tex_diffuse.png into app/src/main/assets After copying the 3D model files, we can use GVRAssetLoader class to load them, it is accessible from the context by calling GVRContext.getAssetLoader() Using the following code to load the fbx file and texture GVRMesh dinoMesh = gvrContext . getAssetLoader (). loadMesh ( new GVRAndroidResource ( gvrContext , trex_mesh.fbx ) ); GVRTexture dinoTexture = gvrContext . getAssetLoader (). loadTexture ( new GVRAndroidResource ( gvrContext , trex_tex_diffuse.png ) ); Note Loading methods have Future in its API such as loadFutureTexture is deprecated After 3D model and texture both loaded, we can add them to the scene with a scene object GVRNode dinoObj = new GVRNode ( gvrContext , dinoMesh , dinoTexture ); dinoObj . getTransform (). setPosition ( 0 , 0 ,- 10 ); dinoObj . getTransform (). rotateByAxis (- 90 , 1f , 0f , 0f ); gvrContext . getMainScene (). addNode ( dinoObj ); Note We create GVRNode instead of use AssetLoader.loadModel() because loadModel() require fbx files to have correct path to texture file which a lot of 3D modeling software failed to produce. Build and run the app, you should be able to see a T-Rex!","title":"How to load 3D models"},{"location":"tutorials/play_with_3d_models/#work-with-3d-modeling-tools","text":"Fbx is the recommended format for the SXR SDK. Currently, all major 3D modeling tools support exporting to FBX format.","title":"Work with 3D modeling tools"},{"location":"tutorials/play_with_3d_models/#source-code","text":"Complete Source Code for this sample","title":"Source Code"},{"location":"tutorials/play_with_animation/","text":"Overview Now that you've learnt how to load 3D model, we are going to learn how to play with animation in VR Create Project Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app. Intro Before we start, we have to obtain a 3D model file with animation. The SXR SDK supports following formats FBX Collada(.dae) And here is one animated 3D model that we are going to use for this tutorial 3D model with animation Texture How to play animations Make sure to copy both files into app/src/main/assets folder You can load the animated model with following code SXRModelNode character = sxrContext . getAssetLoader (). loadModel ( astro_boy.dae ); character . getTransform (). setRotationByAxis ( 45.0f , 0.0f , 1.0f , 0.0f ); character . getTransform (). setScale ( 6 , 6 , 6 ); character . getTransform (). setPosition ( 0.0f , - 0.5f , - 1f ); sxrContext . getMainScene (). addNode ( character ); And play the animation with SXRAnimator , here we make sure the animation in looping forever with the setRepeatCount set to -1 SXRAnimator animator = ( SXRAnimator ) character . getComponent ( SXRAnimator . getComponentType ()); animator . setRepeatCount (- 1 ); animator . setRepeatMode ( SXRRepeatMode . REPEATED ); animator . start (); Work with 3D modeling tools Fbx is the recommended format for the SXR SDK. Currently, all major 3D modeling tools support exporting to FBX format. Source Code Complete Source Code for this sample","title":"Play With Animation"},{"location":"tutorials/play_with_animation/#overview","text":"Now that you've learnt how to load 3D model, we are going to learn how to play with animation in VR","title":"Overview"},{"location":"tutorials/play_with_animation/#create-project","text":"Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app.","title":"Create Project"},{"location":"tutorials/play_with_animation/#intro","text":"Before we start, we have to obtain a 3D model file with animation. The SXR SDK supports following formats FBX Collada(.dae) And here is one animated 3D model that we are going to use for this tutorial 3D model with animation Texture","title":"Intro"},{"location":"tutorials/play_with_animation/#how-to-play-animations","text":"Make sure to copy both files into app/src/main/assets folder You can load the animated model with following code SXRModelNode character = sxrContext . getAssetLoader (). loadModel ( astro_boy.dae ); character . getTransform (). setRotationByAxis ( 45.0f , 0.0f , 1.0f , 0.0f ); character . getTransform (). setScale ( 6 , 6 , 6 ); character . getTransform (). setPosition ( 0.0f , - 0.5f , - 1f ); sxrContext . getMainScene (). addNode ( character ); And play the animation with SXRAnimator , here we make sure the animation in looping forever with the setRepeatCount set to -1 SXRAnimator animator = ( SXRAnimator ) character . getComponent ( SXRAnimator . getComponentType ()); animator . setRepeatCount (- 1 ); animator . setRepeatMode ( SXRRepeatMode . REPEATED ); animator . start ();","title":"How to play animations"},{"location":"tutorials/play_with_animation/#work-with-3d-modeling-tools","text":"Fbx is the recommended format for the SXR SDK. Currently, all major 3D modeling tools support exporting to FBX format.","title":"Work with 3D modeling tools"},{"location":"tutorials/play_with_animation/#source-code","text":"Complete Source Code for this sample","title":"Source Code"},{"location":"tutorials/play_with_billboard/","text":"Overview In VR applications there are some elements that needs to always facing the user, such as text, menus. Here we're going to introduce an easy way to implement it using SXRBillboard component. Note Billboard in 3D graphics term is something always facing the camera. Create Project Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app. Intro Before we start, there is a 3D T-rex model and it's texture we're going to use for this tutorial. How to use Billboard Make sure to copy both files into app/src/main/assets folder You can learn how to load 3D models with following play with 3D models tutorial , here we'll just highlight the code for billboard mTrexObj = sxrContext . getAssetLoader (). loadModel ( trex_mesh.fbx , sxrContext . getMainScene ()); mTrexObj . getTransform (). setPosition ( 4 ,- 6 ,- 8 ); mTrexObj . attachComponent ( new SXRBillboard ( sxrContext , new Vector3f ( 0f , 1f , 0f ))); Note The second parameter of SXRBillboard is the up vector of the billboard, it indicates which direction is up so the billboard will rotate accordingly. Source Code Complete Source Code for this sample","title":"Play With Billboard"},{"location":"tutorials/play_with_billboard/#overview","text":"In VR applications there are some elements that needs to always facing the user, such as text, menus. Here we're going to introduce an easy way to implement it using SXRBillboard component. Note Billboard in 3D graphics term is something always facing the camera.","title":"Overview"},{"location":"tutorials/play_with_billboard/#create-project","text":"Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app.","title":"Create Project"},{"location":"tutorials/play_with_billboard/#intro","text":"Before we start, there is a 3D T-rex model and it's texture we're going to use for this tutorial.","title":"Intro"},{"location":"tutorials/play_with_billboard/#how-to-use-billboard","text":"Make sure to copy both files into app/src/main/assets folder You can learn how to load 3D models with following play with 3D models tutorial , here we'll just highlight the code for billboard mTrexObj = sxrContext . getAssetLoader (). loadModel ( trex_mesh.fbx , sxrContext . getMainScene ()); mTrexObj . getTransform (). setPosition ( 4 ,- 6 ,- 8 ); mTrexObj . attachComponent ( new SXRBillboard ( sxrContext , new Vector3f ( 0f , 1f , 0f ))); Note The second parameter of SXRBillboard is the up vector of the billboard, it indicates which direction is up so the billboard will rotate accordingly.","title":"How to use Billboard"},{"location":"tutorials/play_with_billboard/#source-code","text":"Complete Source Code for this sample","title":"Source Code"},{"location":"tutorials/play_with_component/","text":"Overview The SXR SDK follows component-entity mode, each Node consists of multiple components that control different aspects of the Node such as transformation, rendering, collision detection. When we use functions like getTransform() or getRenderData() , it actually uses getComponent() underneath. In this tutorial, we're going to create our own component for the Node and use it in your app/game. Create Project Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app. Create a new component To create a new component, simply create a new class that extends SXRBehavior . In this case, we create a class called RotateBehavior , simply makes Node to rotate. public class RotateBehavior extends SXRBehavior { private static final long TYPE_Rotate_behavior = newComponentType ( RotateBehavior . class ); float mRotationSpeed = 1.0f ; protected RotateBehavior ( SXRContext sxrContext ) { super ( sxrContext ); mType = TYPE_Rotate_behavior ; } public static long getComponentType (){ return TYPE_Rotate_behavior ;} } Note that we have a static field called TYPE_Rotate_behavior as well as a function getComponentType() . It will be useful when we need to access this component from a Node later. Note If we want to access this component from a Node we can use Node.getComponent(RotateBehavior.getComponentType()) Customize logic SXRBehavior provides couple methods that you can override to customize your behavior. onAttach() will trigger when the component is attached to a Node onDetach will trigger when the component is detached from the Node onDrawFrame will trigger everytime a new frame is drawn In this case, we're going to use onDrawFrame because RotationBehavior will change the rotation of the Node every frame. Override the onDrawFrame as following @Override public void onDrawFrame ( float frameTime ) { super . onDrawFrame ( frameTime ); getOwnerObject (). getTransform (). rotateByAxis ( mRotationSpeed , 0 , 1 , 0 ); } Basically, this means to rotate the object 1 degree on each frame. Use components In order to see our newly created component in action, we need to attach it to a Node . Simply call attachComponent() . To access the component on a Node , use getComponent(RotateBehavior.getComponentType()) Source Code Complete Source Code for this sample","title":"Play With Component"},{"location":"tutorials/play_with_component/#overview","text":"The SXR SDK follows component-entity mode, each Node consists of multiple components that control different aspects of the Node such as transformation, rendering, collision detection. When we use functions like getTransform() or getRenderData() , it actually uses getComponent() underneath. In this tutorial, we're going to create our own component for the Node and use it in your app/game.","title":"Overview"},{"location":"tutorials/play_with_component/#create-project","text":"Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app.","title":"Create Project"},{"location":"tutorials/play_with_component/#create-a-new-component","text":"To create a new component, simply create a new class that extends SXRBehavior . In this case, we create a class called RotateBehavior , simply makes Node to rotate. public class RotateBehavior extends SXRBehavior { private static final long TYPE_Rotate_behavior = newComponentType ( RotateBehavior . class ); float mRotationSpeed = 1.0f ; protected RotateBehavior ( SXRContext sxrContext ) { super ( sxrContext ); mType = TYPE_Rotate_behavior ; } public static long getComponentType (){ return TYPE_Rotate_behavior ;} } Note that we have a static field called TYPE_Rotate_behavior as well as a function getComponentType() . It will be useful when we need to access this component from a Node later. Note If we want to access this component from a Node we can use Node.getComponent(RotateBehavior.getComponentType())","title":"Create a new component"},{"location":"tutorials/play_with_component/#customize-logic","text":"SXRBehavior provides couple methods that you can override to customize your behavior. onAttach() will trigger when the component is attached to a Node onDetach will trigger when the component is detached from the Node onDrawFrame will trigger everytime a new frame is drawn In this case, we're going to use onDrawFrame because RotationBehavior will change the rotation of the Node every frame. Override the onDrawFrame as following @Override public void onDrawFrame ( float frameTime ) { super . onDrawFrame ( frameTime ); getOwnerObject (). getTransform (). rotateByAxis ( mRotationSpeed , 0 , 1 , 0 ); } Basically, this means to rotate the object 1 degree on each frame.","title":"Customize logic"},{"location":"tutorials/play_with_component/#use-components","text":"In order to see our newly created component in action, we need to attach it to a Node . Simply call attachComponent() . To access the component on a Node , use getComponent(RotateBehavior.getComponentType())","title":"Use components"},{"location":"tutorials/play_with_component/#source-code","text":"Complete Source Code for this sample","title":"Source Code"},{"location":"tutorials/play_with_controller/","text":"Overview Now that you've learnt how to use 3D model and animation with the SXR SDK. We are going to learn how to use controllers to make VR app more interactive. Create Project Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app. Intro Being able to interact with in the VR environment helps a lot with the immersion. Currently, there are two ways to interact with VR content GearVR controller Gear VR controller provides 3 degrees of freedom orientation tracking and trackpad control, it's highly recommended for a more immersive VR experience Gaze controller Gaze controller is available by default from GearVR headset, based on the direction of the headset and touch input on the touchpad Note The SXR SDK supports both controllers and GearVR controller have higher priority over gaze controller. It will automatically switch when user turn controller on/off. Using VR Controller For VR controller to work correctly, we need to implement these key elements Cursor Collider PickHandler Controller 1. Create Cursor Cursor indicates the location and object that user is pointing. It's a important way for user to interact with the VR environment. A cursor can be anything, an image, a cube or even something that's animated. Developer can pick anything that fits their needs. In this tutorial we'll use a simple reticle texture as an example. First let's create a quad to display this texture, notice we turn off the depth test and set the rendering order as OVERLAY make it always visible to the user. SXRTexture cursor_texture = sxrContext . getAssetLoader (). loadTexture ( new SXRAndroidResource ( sxrContext , cursor.png )); final SXRNode cursor = new SXRNode ( sxrContext , sxrContext . createQuad ( 1f , 1f ), cursor_texture ); cursor . getRenderData (). setDepthTest ( false ); cursor . getRenderData (). setRenderingOrder ( SXRRenderData . SXRRenderingOrder . OVERLAY ); 2. Collider In order to know which object dose the user picked in the scene, we need to add collider to the Node. There are three types of colliders BoxCollider BoxCollider can detect picking within a bounding box SphereCollider SphereCollider can detect picking within a sphere MeshCollider MeshCollider can detect picking of a complex 3d Model, however it's slower than the previous two. Collider can be added to any Node as a component sceneObject . attachComponent ( new SXRMeshCollider ( getSXRContext (), false )); You can use the following function to create cubes with collider private SXRNode createCube () { SXRMaterial material = new SXRMaterial ( getSXRContext (), SXRMaterial . SXRShaderType . Color . ID ); material . setColor ( Color . GRAY ); SXRCubeNode cube = new SXRCubeNode ( getSXRContext ()); cube . getRenderData (). setMaterial ( material ); cube . attachComponent ( new SXRMeshCollider ( getSXRContext (), false )); return cube ; } 3. PickHandler PickHandler will be triggered once the cursor enter/exit a Node with collider, base on the events developer can implement different feedback for the user PickHandler have 4 major methods, onEnter/onExit/onTouchStart/onTouchEnd Here is an example of how to use each method private ITouchEvents mPickHandler = new SXREventListeners . TouchEvents () { private SXRNode movingObject ; public void onEnter ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { sceneObj . getRenderData (). getMaterial (). setColor ( Color . RED ); } public void onTouchStart ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { if ( movingObject == null ) { sceneObj . getRenderData (). getMaterial (). setColor ( Color . BLUE ); if ( mController . startDrag ( sceneObj )) { movingObject = sceneObj ; } } } public void onTouchEnd ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { sceneObj . getRenderData (). getMaterial (). setColor ( Color . RED ); if ( sceneObj == movingObject ) { mController . stopDrag (); movingObject = null ; } } public void onExit ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { sceneObj . getRenderData (). getMaterial (). setColor ( Color . GRAY ); if ( sceneObj == movingObject ) { mController . stopDrag (); movingObject = null ; } } }; 4. Enable Controller With cursor, collider and pickhandler, let's enable the controller. Everytime a new controller connects to Gear VR it will trigger the onCursorControllerSelected event. It's a great place to initialize the controller Initialize the controller using following code //Initialize controller sxrContext . getInputManager (). selectController ( new SXRInputManager . ICursorControllerSelectListener () { public void onCursorControllerSelected ( SXRCursorController newController , SXRCursorController oldController ) { if ( oldController != null ) { oldController . removePickEventListener ( mPickHandler ); } mController = newController ; newController . addPickEventListener ( mPickHandler ); newController . setCursor ( cursor ); newController . setCursorDepth ( DEPTH ); newController . setCursorControl ( SXRCursorController . CursorControl . PROJECT_CURSOR_ON_SURFACE ); } }); 5. Build Build and run the project, if you have a Gear VR controller, you should be able to see a Gear VR controller in VR that mirrors your move, otherwise you should be able to see a cursor on the center of the screen Source Code Complete Source Code for this sample","title":"Play With Controller"},{"location":"tutorials/play_with_controller/#overview","text":"Now that you've learnt how to use 3D model and animation with the SXR SDK. We are going to learn how to use controllers to make VR app more interactive.","title":"Overview"},{"location":"tutorials/play_with_controller/#create-project","text":"Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app.","title":"Create Project"},{"location":"tutorials/play_with_controller/#intro","text":"Being able to interact with in the VR environment helps a lot with the immersion. Currently, there are two ways to interact with VR content GearVR controller Gear VR controller provides 3 degrees of freedom orientation tracking and trackpad control, it's highly recommended for a more immersive VR experience Gaze controller Gaze controller is available by default from GearVR headset, based on the direction of the headset and touch input on the touchpad Note The SXR SDK supports both controllers and GearVR controller have higher priority over gaze controller. It will automatically switch when user turn controller on/off.","title":"Intro"},{"location":"tutorials/play_with_controller/#using-vr-controller","text":"For VR controller to work correctly, we need to implement these key elements Cursor Collider PickHandler Controller","title":"Using VR Controller"},{"location":"tutorials/play_with_controller/#1-create-cursor","text":"Cursor indicates the location and object that user is pointing. It's a important way for user to interact with the VR environment. A cursor can be anything, an image, a cube or even something that's animated. Developer can pick anything that fits their needs. In this tutorial we'll use a simple reticle texture as an example. First let's create a quad to display this texture, notice we turn off the depth test and set the rendering order as OVERLAY make it always visible to the user. SXRTexture cursor_texture = sxrContext . getAssetLoader (). loadTexture ( new SXRAndroidResource ( sxrContext , cursor.png )); final SXRNode cursor = new SXRNode ( sxrContext , sxrContext . createQuad ( 1f , 1f ), cursor_texture ); cursor . getRenderData (). setDepthTest ( false ); cursor . getRenderData (). setRenderingOrder ( SXRRenderData . SXRRenderingOrder . OVERLAY );","title":"1. Create Cursor"},{"location":"tutorials/play_with_controller/#2-collider","text":"In order to know which object dose the user picked in the scene, we need to add collider to the Node. There are three types of colliders BoxCollider BoxCollider can detect picking within a bounding box SphereCollider SphereCollider can detect picking within a sphere MeshCollider MeshCollider can detect picking of a complex 3d Model, however it's slower than the previous two. Collider can be added to any Node as a component sceneObject . attachComponent ( new SXRMeshCollider ( getSXRContext (), false )); You can use the following function to create cubes with collider private SXRNode createCube () { SXRMaterial material = new SXRMaterial ( getSXRContext (), SXRMaterial . SXRShaderType . Color . ID ); material . setColor ( Color . GRAY ); SXRCubeNode cube = new SXRCubeNode ( getSXRContext ()); cube . getRenderData (). setMaterial ( material ); cube . attachComponent ( new SXRMeshCollider ( getSXRContext (), false )); return cube ; }","title":"2. Collider"},{"location":"tutorials/play_with_controller/#3-pickhandler","text":"PickHandler will be triggered once the cursor enter/exit a Node with collider, base on the events developer can implement different feedback for the user PickHandler have 4 major methods, onEnter/onExit/onTouchStart/onTouchEnd Here is an example of how to use each method private ITouchEvents mPickHandler = new SXREventListeners . TouchEvents () { private SXRNode movingObject ; public void onEnter ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { sceneObj . getRenderData (). getMaterial (). setColor ( Color . RED ); } public void onTouchStart ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { if ( movingObject == null ) { sceneObj . getRenderData (). getMaterial (). setColor ( Color . BLUE ); if ( mController . startDrag ( sceneObj )) { movingObject = sceneObj ; } } } public void onTouchEnd ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { sceneObj . getRenderData (). getMaterial (). setColor ( Color . RED ); if ( sceneObj == movingObject ) { mController . stopDrag (); movingObject = null ; } } public void onExit ( SXRNode sceneObj , SXRPicker . SXRPickedObject pickInfo ) { sceneObj . getRenderData (). getMaterial (). setColor ( Color . GRAY ); if ( sceneObj == movingObject ) { mController . stopDrag (); movingObject = null ; } } };","title":"3. PickHandler"},{"location":"tutorials/play_with_controller/#4-enable-controller","text":"With cursor, collider and pickhandler, let's enable the controller. Everytime a new controller connects to Gear VR it will trigger the onCursorControllerSelected event. It's a great place to initialize the controller Initialize the controller using following code //Initialize controller sxrContext . getInputManager (). selectController ( new SXRInputManager . ICursorControllerSelectListener () { public void onCursorControllerSelected ( SXRCursorController newController , SXRCursorController oldController ) { if ( oldController != null ) { oldController . removePickEventListener ( mPickHandler ); } mController = newController ; newController . addPickEventListener ( mPickHandler ); newController . setCursor ( cursor ); newController . setCursorDepth ( DEPTH ); newController . setCursorControl ( SXRCursorController . CursorControl . PROJECT_CURSOR_ON_SURFACE ); } });","title":"4. Enable Controller"},{"location":"tutorials/play_with_controller/#5-build","text":"Build and run the project, if you have a Gear VR controller, you should be able to see a Gear VR controller in VR that mirrors your move, otherwise you should be able to see a cursor on the center of the screen","title":"5. Build"},{"location":"tutorials/play_with_controller/#source-code","text":"Complete Source Code for this sample","title":"Source Code"},{"location":"tutorials/play_with_material/","text":"Overview Now that you've created your first VR app with the SXR SDK. We are going to learn how to create things that look much better in VR. Create Project Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app. What is a Material In 3D graphics term, a material is a set of textures and shader parameters that can be used to simulate different types of materials in real life. For example with the correct material, you can make your 3D objects looks like bricks. By CaliCoastReplay - Own work, CC BY 4.0 Create Nodes First, let's create one cube and one sphere SXRCubeNode mCube ; SXRSphereNode mSphere ; and initialize them in onInit function //Create Shpere mSphere = new SXRSphereNode ( sxrContext ); mSphere . getTransform (). setPosition ( 1 , 0 , - 3 ); sxrContext . getMainScene (). addNode ( mSphere ); //Create Cube mCube = new SXRCubeNode ( sxrContext ); mCube . getTransform (). setPosition (- 1 , 0 , - 3 ); sxrContext . getMainScene (). addNode ( mCube ); Material with solid color Material with solid color can be used to create simple 3D objects, such as a red ball, a white cube. Let's create a white material with the following code. SXRMaterial flatMaterial ; flatMaterial = new SXRMaterial ( sxrContext ); flatMaterial . setColor ( 1.0f , 1.0f , 1.0f ); Note The SXR SDK uses RGB color model and the range of each color is from 0 to 1. Now that we created the material, let's apply it to the sphere. mSphere . getRenderData (). setMaterial ( flatMaterial ); Build and run your app and see if you can find the red sphere. Material with Texture Solid color objects are good, but what if I want to create things like a wooden box or brick wall? Yes, we can do that with textures, let's learn how to do that. The first step of creating a textured material is to have one texture. Which you can download it here Place the texture under app\\src\\main\\res\\raw folder Sync your project, and you should be able to load the texture using following code SXRTexture texture = sxrContext . getAssetLoader (). loadTexture ( new SXRAndroidResource ( sxrContext , R . raw . crate_wood )); You can create a material with texture using following code. SXRMaterial textureMaterial ; textureMaterial = new SXRMaterial ( sxrContext ); textureMaterial . setMainTexture ( texture ); mCube . getRenderData (). setMaterial ( textureMaterial ); Build and run your app, you should see the wooden crate we just created. Turn on the light We just created a wooden crate, but if you look at it closely, you'll find it's really bright and doesn't feel natural. In this section, we're going to apply lighting to both objects to make it look a lot nicer. First, let's add a light to the scene using following code SXRPointLight pointLight ; pointLight = new SXRPointLight ( sxrContext ); pointLight . setDiffuseIntensity ( 0.9f , 0.7f , 0.7f , 1.0f ); SXRNode lightNode = new SXRNode ( sxrContext ); lightNode . getTransform (). setPosition ( 0 , 0 , 0 ); lightNode . attachLight ( pointLight ); sxrContext . getMainScene (). addNode ( lightNode ); The code snippet will create a light with diffuse color of (0.9, 0.7, 0.7) this will give the scene a red tone. Build and run the app, you should be able to see the lighting on the sphere and crate box, feel free to tweak with the light to make it look better. Make it move Add the following code to the onStep() function to make the cube move. //Rotate the cube along the Y axis mCube . getTransform (). rotateByAxis ( 1 , 0 , 1 , 0 ); Source Code Complete Source Code for this sample","title":"Play With Materials"},{"location":"tutorials/play_with_material/#overview","text":"Now that you've created your first VR app with the SXR SDK. We are going to learn how to create things that look much better in VR.","title":"Overview"},{"location":"tutorials/play_with_material/#create-project","text":"Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app.","title":"Create Project"},{"location":"tutorials/play_with_material/#what-is-a-material","text":"In 3D graphics term, a material is a set of textures and shader parameters that can be used to simulate different types of materials in real life. For example with the correct material, you can make your 3D objects looks like bricks. By CaliCoastReplay - Own work, CC BY 4.0","title":"What is a Material"},{"location":"tutorials/play_with_material/#create-nodes","text":"First, let's create one cube and one sphere SXRCubeNode mCube ; SXRSphereNode mSphere ; and initialize them in onInit function //Create Shpere mSphere = new SXRSphereNode ( sxrContext ); mSphere . getTransform (). setPosition ( 1 , 0 , - 3 ); sxrContext . getMainScene (). addNode ( mSphere ); //Create Cube mCube = new SXRCubeNode ( sxrContext ); mCube . getTransform (). setPosition (- 1 , 0 , - 3 ); sxrContext . getMainScene (). addNode ( mCube );","title":"Create Nodes"},{"location":"tutorials/play_with_material/#material-with-solid-color","text":"Material with solid color can be used to create simple 3D objects, such as a red ball, a white cube. Let's create a white material with the following code. SXRMaterial flatMaterial ; flatMaterial = new SXRMaterial ( sxrContext ); flatMaterial . setColor ( 1.0f , 1.0f , 1.0f ); Note The SXR SDK uses RGB color model and the range of each color is from 0 to 1. Now that we created the material, let's apply it to the sphere. mSphere . getRenderData (). setMaterial ( flatMaterial ); Build and run your app and see if you can find the red sphere.","title":"Material with solid color"},{"location":"tutorials/play_with_material/#material-with-texture","text":"Solid color objects are good, but what if I want to create things like a wooden box or brick wall? Yes, we can do that with textures, let's learn how to do that. The first step of creating a textured material is to have one texture. Which you can download it here Place the texture under app\\src\\main\\res\\raw folder Sync your project, and you should be able to load the texture using following code SXRTexture texture = sxrContext . getAssetLoader (). loadTexture ( new SXRAndroidResource ( sxrContext , R . raw . crate_wood )); You can create a material with texture using following code. SXRMaterial textureMaterial ; textureMaterial = new SXRMaterial ( sxrContext ); textureMaterial . setMainTexture ( texture ); mCube . getRenderData (). setMaterial ( textureMaterial ); Build and run your app, you should see the wooden crate we just created.","title":"Material with Texture"},{"location":"tutorials/play_with_material/#turn-on-the-light","text":"We just created a wooden crate, but if you look at it closely, you'll find it's really bright and doesn't feel natural. In this section, we're going to apply lighting to both objects to make it look a lot nicer. First, let's add a light to the scene using following code SXRPointLight pointLight ; pointLight = new SXRPointLight ( sxrContext ); pointLight . setDiffuseIntensity ( 0.9f , 0.7f , 0.7f , 1.0f ); SXRNode lightNode = new SXRNode ( sxrContext ); lightNode . getTransform (). setPosition ( 0 , 0 , 0 ); lightNode . attachLight ( pointLight ); sxrContext . getMainScene (). addNode ( lightNode ); The code snippet will create a light with diffuse color of (0.9, 0.7, 0.7) this will give the scene a red tone. Build and run the app, you should be able to see the lighting on the sphere and crate box, feel free to tweak with the light to make it look better.","title":"Turn on the light"},{"location":"tutorials/play_with_material/#make-it-move","text":"Add the following code to the onStep() function to make the cube move. //Rotate the cube along the Y axis mCube . getTransform (). rotateByAxis ( 1 , 0 , 1 , 0 );","title":"Make it move"},{"location":"tutorials/play_with_material/#source-code","text":"Complete Source Code for this sample","title":"Source Code"},{"location":"tutorials/simple_sxr_app/","text":"Overview After setting up the SXR SDK, let's create our first SXR app and learn a few very important concepts in the process. Create Project Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app. Project Structure Before we start, let's take a look at some essential parts of an SXR app The template project contains two classes, MainActivity and MainScene MainActivity is the entry point of the app, like android.app.Activity it handles the initialization and life cycle of an SXR app. MainScene is the container of a scene, just like a scene in the movie, it contains things like camera, characters, visual effects etc, it is the place for all your XR content. In the assets folder, there are two files: sxr.xml and oculussig file sxr.xml is where you config various behavior of the SXR SDK, which we'll get into detail in future tutorials oculussig is the Oculus signing file which allows you to deploy debug apps to VR devices, so always make sure this you have a signing file in your project Scene Usually an SXR app/game consists of one or more scenes. The template project already created one Scene called MainScene and it should be the starting point for your SXR project. Note MainScene extends from SXRMain , if you're creating your own entry point class, make sure to extend SXRMain There are two functions in MainScene ; both are important for the scene to work onInit() is called when the scene is being loaded, and can be used to perform actions like object creation, assets loading. onStep() called once per frame, can be used to perform things like animation, AI or user interactions Add object Adding an object to the scene is simple, Just create the object and specify the material and add it to the scene First, let's add a new member variable for the Cube to the MainScene SXRNode mCube Then add the cube to our scene with following code in onInit() function //Create a cube mCube = new SXRCubeNode ( sxrContext ); //Set position of the cube at (0, -2, -3) mCube . getTransform (). setPosition ( 0 , - 2 , - 3 ); //Add cube to the scene sxrContext . getMainScene (). addNode ( mCube ); Build and run the app, you should be able to see a white cube on the screen Note If you're using \"VR developer mode\" without headset the orientation might be different, you might need to turn around to see the cube Make it move Now let's make the cube rotate. Because we want to see the cube rotate continuously, we need to update its rotation every frame. So instead of the onInit() function we need to add the rotation logic into onStep() function Add the following code to the onStep() function //Rotate the cube along the Y axis mCube . getTransform (). rotateByAxis ( 1 , 0 , 1 , 0 ); rotateByAxis() has 4 parameters, the first specifies the rotation angle while the rest 3 defines the rotation axis. By opengl_tutorials , CC-BY-NC-ND Build and run the app, you should be able to see a rotating cube. Now that you have a rotating cube in SXR, feel free to try different things: change its color, make it scale up and down or move it around. Source Code Complete Source Code for this sample","title":"Simple SXR app"},{"location":"tutorials/simple_sxr_app/#overview","text":"After setting up the SXR SDK, let's create our first SXR app and learn a few very important concepts in the process.","title":"Overview"},{"location":"tutorials/simple_sxr_app/#create-project","text":"Create an SXR project by copying the template project Perform the following steps to make sure your project runs correctly (if developing for Gear VR) Copy your Oculus signature file to app/src/main/assets folder. Change the applicationId in build.gradle to a unique name to avoid naming conflict when you test the app later Change the app_name in res/values/strings.xml to avoid confusion when you debug the app.","title":"Create Project"},{"location":"tutorials/simple_sxr_app/#project-structure","text":"Before we start, let's take a look at some essential parts of an SXR app The template project contains two classes, MainActivity and MainScene MainActivity is the entry point of the app, like android.app.Activity it handles the initialization and life cycle of an SXR app. MainScene is the container of a scene, just like a scene in the movie, it contains things like camera, characters, visual effects etc, it is the place for all your XR content. In the assets folder, there are two files: sxr.xml and oculussig file sxr.xml is where you config various behavior of the SXR SDK, which we'll get into detail in future tutorials oculussig is the Oculus signing file which allows you to deploy debug apps to VR devices, so always make sure this you have a signing file in your project","title":"Project Structure"},{"location":"tutorials/simple_sxr_app/#scene","text":"Usually an SXR app/game consists of one or more scenes. The template project already created one Scene called MainScene and it should be the starting point for your SXR project. Note MainScene extends from SXRMain , if you're creating your own entry point class, make sure to extend SXRMain There are two functions in MainScene ; both are important for the scene to work onInit() is called when the scene is being loaded, and can be used to perform actions like object creation, assets loading. onStep() called once per frame, can be used to perform things like animation, AI or user interactions","title":"Scene"},{"location":"tutorials/simple_sxr_app/#add-object","text":"Adding an object to the scene is simple, Just create the object and specify the material and add it to the scene First, let's add a new member variable for the Cube to the MainScene SXRNode mCube Then add the cube to our scene with following code in onInit() function //Create a cube mCube = new SXRCubeNode ( sxrContext ); //Set position of the cube at (0, -2, -3) mCube . getTransform (). setPosition ( 0 , - 2 , - 3 ); //Add cube to the scene sxrContext . getMainScene (). addNode ( mCube ); Build and run the app, you should be able to see a white cube on the screen Note If you're using \"VR developer mode\" without headset the orientation might be different, you might need to turn around to see the cube","title":"Add object"},{"location":"tutorials/simple_sxr_app/#make-it-move","text":"Now let's make the cube rotate. Because we want to see the cube rotate continuously, we need to update its rotation every frame. So instead of the onInit() function we need to add the rotation logic into onStep() function Add the following code to the onStep() function //Rotate the cube along the Y axis mCube . getTransform (). rotateByAxis ( 1 , 0 , 1 , 0 ); rotateByAxis() has 4 parameters, the first specifies the rotation angle while the rest 3 defines the rotation axis. By opengl_tutorials , CC-BY-NC-ND Build and run the app, you should be able to see a rotating cube. Now that you have a rotating cube in SXR, feel free to try different things: change its color, make it scale up and down or move it around.","title":"Make it move"},{"location":"tutorials/simple_sxr_app/#source-code","text":"Complete Source Code for this sample","title":"Source Code"},{"location":"unity/getting_started/","text":"Software Requirements Unity 2017.3.0 or later with Android support SXR Unity Plugin Hardware Requirements A Samsung XR supported devices Import Plugin In Unity select Assets - Import Package - Custom Package Select SXR_UnityPlugin.unitypackage , import everything from the package Prepare your Unity project In order for SXR to track user movement, the first-person camera needs to be converted to a XR Camera In Unity select SXR - Prepare XR Camera Find and select the \"Main Camera\" of your app in Unity's Hierarchy window With your Main Camera selected, click on \"Prepare XR Camera\" in the sub window, this would process the Main Camera and convert it to be compatible with SXR. If the process is successful, you will see a fiew more GameObjects added to the Main Camera as children. Note If you have multiple game scenes, you should perform this on every scene You can tweak the camera settings with SXREventSystem Recommended settings Use Fixed Update - Use the fixed update for camera rendering (uses in more CPU cycles). Use Chromatic Aberration - Correct chromatic aberration (requires more CPU processing time). Use Antialiasing - Enable antialiasing optimized with the SXR plugin. Unity's antialiasing will be overwritten by the plugin. Use Multiple Camera - Currently not supported. AR Camera Mode - The Camera will act as AR camera Build Settings Use the following steps to build a SXR project Switch Platform to Android Make sure Player Settings - Resolution And Presentation - Landscape Left is selected. Turn off Player Settings - XR Settings - Virtual Reality Supported Turn off Player Settings - Other Settings - Multithreaded Rendering Now you're ready to build your SXR app","title":"Getting Started"},{"location":"unity/getting_started/#software-requirements","text":"Unity 2017.3.0 or later with Android support SXR Unity Plugin","title":"Software Requirements"},{"location":"unity/getting_started/#hardware-requirements","text":"A Samsung XR supported devices","title":"Hardware Requirements"},{"location":"unity/getting_started/#import-plugin","text":"In Unity select Assets - Import Package - Custom Package Select SXR_UnityPlugin.unitypackage , import everything from the package","title":"Import Plugin"},{"location":"unity/getting_started/#prepare-your-unity-project","text":"In order for SXR to track user movement, the first-person camera needs to be converted to a XR Camera In Unity select SXR - Prepare XR Camera Find and select the \"Main Camera\" of your app in Unity's Hierarchy window With your Main Camera selected, click on \"Prepare XR Camera\" in the sub window, this would process the Main Camera and convert it to be compatible with SXR. If the process is successful, you will see a fiew more GameObjects added to the Main Camera as children. Note If you have multiple game scenes, you should perform this on every scene You can tweak the camera settings with SXREventSystem Recommended settings Use Fixed Update - Use the fixed update for camera rendering (uses in more CPU cycles). Use Chromatic Aberration - Correct chromatic aberration (requires more CPU processing time). Use Antialiasing - Enable antialiasing optimized with the SXR plugin. Unity's antialiasing will be overwritten by the plugin. Use Multiple Camera - Currently not supported. AR Camera Mode - The Camera will act as AR camera","title":"Prepare your Unity project"},{"location":"unity/getting_started/#build-settings","text":"Use the following steps to build a SXR project Switch Platform to Android Make sure Player Settings - Resolution And Presentation - Landscape Left is selected. Turn off Player Settings - XR Settings - Virtual Reality Supported Turn off Player Settings - Other Settings - Multithreaded Rendering Now you're ready to build your SXR app","title":"Build Settings"}]}